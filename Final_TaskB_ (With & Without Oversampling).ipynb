{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzMw4q9pAljq"
      },
      "source": [
        "# Initial Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPTcl_x5gXDo",
        "outputId": "13a0da70-e593-4c11-8b28-f373be048f23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Qm5ocD-sPOp",
        "outputId": "9250cc79-1fec-41c3-f30f-7ba242d848a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 7.43 s, sys: 1.4 s, total: 8.82 s\n",
            "Wall time: 13.6 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "import os\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import nltk\n",
        "import json\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_auc_score\n",
        "from sklearn.metrics import average_precision_score,roc_auc_score, roc_curve, precision_recall_curve\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import ToktokTokenizer\n",
        "import nltk, string, re, spacy,unicodedata, random\n",
        "from bs4 import BeautifulSoup\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "### Pretrained Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tn3ZdEkqwFuf"
      },
      "source": [
        "# Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "x2mJ2HY_srqA"
      },
      "outputs": [],
      "source": [
        "Atrain = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/case/SubTask-A-train.csv\")\n",
        "Btrain = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/case/SubTask-B-train.csv\")\n",
        "Ctrain = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/case/SubTask-C-train.csv\")\n",
        "\n",
        "Aval_tweet = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/case/SubTask-A-(index,tweet)val.csv')\n",
        "Aval_label = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/case/SubTask-A(index,label)val.csv')\n",
        "\n",
        "Bval_tweet = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/case/SubTask-B(index,tweet)val.csv')\n",
        "Bval_label = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/case/SubTask-B(index,label)val.csv')\n",
        "\n",
        "Cval_tweet = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/case/SubTask-C(index,tweet)val.csv')\n",
        "Cval_label = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/case/SubTask-C(index,label)val.csv')\n",
        "\n",
        "Atest_tweet = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/case/SubTask-A-(index,tweet)test.csv')\n",
        "Btest_tweet = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/case/SubTask-B(index,tweet)test.csv')\n",
        "Ctest_tweet = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/case/SubTask-C(index,tweet)test.csv')\n",
        "\n",
        "Atest_label = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/case/SubTask-A(index,label)test.csv')\n",
        "Btest_label = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/case/SubTask-B(index,label)test.csv')\n",
        "Ctest_label = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/case/SubTask-C(index,label)test.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7PBA8PiYBpG",
        "outputId": "60ebff60-50a1-4df6-9937-8b08f5ae9fe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of training samples train set - task 1: 7284\n",
            "Total number of training samples dev set - task 1: 1561\n",
            "Total number of training samples test set - task 1: 1562\n"
          ]
        }
      ],
      "source": [
        "print(\"Total number of training samples train set - task 1:\", len(Atrain))\n",
        "print(\"Total number of training samples dev set - task 1:\", len(Aval_tweet))\n",
        "print(\"Total number of training samples test set - task 1:\", len(Atest_tweet))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec2kFSBQYBpH",
        "outputId": "5bc6de74-0512-42d9-f81f-ac2ee0b121b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of training samples train set - task 2: 699\n",
            "Total number of training samples dev set - task 2: 150\n",
            "Total number of training samples test set - task 2: 150\n"
          ]
        }
      ],
      "source": [
        "print(\"Total number of training samples train set - task 2:\", len(Btrain))\n",
        "print(\"Total number of training samples dev set - task 2:\", len(Bval_tweet))\n",
        "print(\"Total number of training samples test set - task 2:\", len(Btest_tweet))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jBReuooTYBpI"
      },
      "outputs": [],
      "source": [
        "# print(\"Total number of training samples train set - task 3:\", len(Ctrain))\n",
        "# print(\"Total number of training samples dev set - task 3:\", len(Cval_tweet))\n",
        "# print(\"Total number of training samples test set - task 3:\", len(Ctest_tweet))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vq4axTvl_KdJ",
        "outputId": "334f904b-c94a-45a7-dc24-41c032c2c3c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index                                              tweet  label\n",
              "0  10011  #ClimateCrisis #ClimateAction #GlobalWarming  ...      1\n",
              "1  10014  #ClimateCrisis    #ClimateAction #GlobalWarmin...      1\n",
              "2  10021  Major climate denier Pat Michaels has died.  D...      1\n",
              "3  10028  #Greenwashing #ExtinctionRebellion #ClimateAct...      1\n",
              "4  10034  #ExtinctionRebellion      #ClimateCrisis #Clim...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1c65bd8-5a41-4c88-8776-97227992d929\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10011</td>\n",
              "      <td>#ClimateCrisis #ClimateAction #GlobalWarming  ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10014</td>\n",
              "      <td>#ClimateCrisis    #ClimateAction #GlobalWarmin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10021</td>\n",
              "      <td>Major climate denier Pat Michaels has died.  D...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10028</td>\n",
              "      <td>#Greenwashing #ExtinctionRebellion #ClimateAct...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10034</td>\n",
              "      <td>#ExtinctionRebellion      #ClimateCrisis #Clim...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1c65bd8-5a41-4c88-8776-97227992d929')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e1c65bd8-5a41-4c88-8776-97227992d929 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e1c65bd8-5a41-4c88-8776-97227992d929');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fc0a2902-39b5-4710-837b-20961d35f9f0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fc0a2902-39b5-4710-837b-20961d35f9f0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fc0a2902-39b5-4710-837b-20961d35f9f0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "Btrain.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6F3-6NDnYBpJ",
        "outputId": "337df2ca-17d5-4826-c4b2-0c950bdf4149"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     index                                              tweet  label\n",
              "694  20262  #Renewables #Greenwashing     #ClimateStrike  ...      1\n",
              "695  20293  #FridaysForFuture #ClimateChange #Renewables  ...      1\n",
              "696  20346  #FridaysForFuture #ClimateChange #Renewables #...      1\n",
              "697  20366  #Greenwashing  #Renewables #ClimateStrike #Ext...      1\n",
              "698  20367  #ClimateCrisis #ClimateAction #GlobalWarming  ...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-100f699f-8f9c-4ff7-90c1-eade25cce190\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>694</th>\n",
              "      <td>20262</td>\n",
              "      <td>#Renewables #Greenwashing     #ClimateStrike  ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>20293</td>\n",
              "      <td>#FridaysForFuture #ClimateChange #Renewables  ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>696</th>\n",
              "      <td>20346</td>\n",
              "      <td>#FridaysForFuture #ClimateChange #Renewables #...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>697</th>\n",
              "      <td>20366</td>\n",
              "      <td>#Greenwashing  #Renewables #ClimateStrike #Ext...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>698</th>\n",
              "      <td>20367</td>\n",
              "      <td>#ClimateCrisis #ClimateAction #GlobalWarming  ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-100f699f-8f9c-4ff7-90c1-eade25cce190')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-100f699f-8f9c-4ff7-90c1-eade25cce190 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-100f699f-8f9c-4ff7-90c1-eade25cce190');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9854a1e2-fdd2-4450-83e7-3395c50f997f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9854a1e2-fdd2-4450-83e7-3395c50f997f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9854a1e2-fdd2-4450-83e7-3395c50f997f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "Btrain.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yu-ldG-zYBpJ",
        "outputId": "912c4378-bbe5-4e4f-d63e-d9421355bc60"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index                                              tweet\n",
              "0  10000  british govt/msm sheer hypocrisy!!! â€˜Out of re...\n",
              "1  10004  This #FridaysForFuture on Zoom we will get boo...\n",
              "2  10046  Greenpeace: RT @mnyomb1: The #IPCC report is v...\n",
              "3  10072  @magdaghonem The massacre of trees in Egypt.\\n...\n",
              "4  10102  #FridaysForFuture Week 92\\n\\nTheðŸŒŽis changing t..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-948355de-7acd-4557-8853-410871571964\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>british govt/msm sheer hypocrisy!!! â€˜Out of re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10004</td>\n",
              "      <td>This #FridaysForFuture on Zoom we will get boo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10046</td>\n",
              "      <td>Greenpeace: RT @mnyomb1: The #IPCC report is v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10072</td>\n",
              "      <td>@magdaghonem The massacre of trees in Egypt.\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10102</td>\n",
              "      <td>#FridaysForFuture Week 92\\n\\nTheðŸŒŽis changing t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-948355de-7acd-4557-8853-410871571964')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-948355de-7acd-4557-8853-410871571964 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-948355de-7acd-4557-8853-410871571964');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9374383e-21e6-48ce-8876-4977665586d2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9374383e-21e6-48ce-8876-4977665586d2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9374383e-21e6-48ce-8876-4977665586d2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "Btest_tweet.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "egsDesfGYBpK",
        "outputId": "a6008bae-3872-4e6a-eb43-b67474c8e560"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index                                              tweet\n",
              "0  10134  #ClimateChange  #Greenwashing #Renewables #Cli...\n",
              "1  10165  This can be the result when a workplace does n...\n",
              "2  10209  #dreadlocks is trending in Germany because #fr...\n",
              "3  10356  #FridaysForFuture #ClimateChange #Renewables #...\n",
              "4  10423  @Shevans9104 @paulmurphy_TD You could always g..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3985891e-2060-41fe-bf12-b2369aa7db45\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10134</td>\n",
              "      <td>#ClimateChange  #Greenwashing #Renewables #Cli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10165</td>\n",
              "      <td>This can be the result when a workplace does n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10209</td>\n",
              "      <td>#dreadlocks is trending in Germany because #fr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10356</td>\n",
              "      <td>#FridaysForFuture #ClimateChange #Renewables #...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10423</td>\n",
              "      <td>@Shevans9104 @paulmurphy_TD You could always g...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3985891e-2060-41fe-bf12-b2369aa7db45')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3985891e-2060-41fe-bf12-b2369aa7db45 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3985891e-2060-41fe-bf12-b2369aa7db45');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-26531ca4-c313-4d1c-a64e-174c32ae24e6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-26531ca4-c313-4d1c-a64e-174c32ae24e6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-26531ca4-c313-4d1c-a64e-174c32ae24e6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "Bval_tweet.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "es4J604mYBpL",
        "outputId": "38a66f10-2613-453d-b69e-728e038da4fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index  label\n",
              "0  10134      1\n",
              "1  10165      2\n",
              "2  10209      2\n",
              "3  10356      1\n",
              "4  10423      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-955d4f38-14d7-4040-9404-31fa749c54cf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10134</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10165</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10209</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10356</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10423</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-955d4f38-14d7-4040-9404-31fa749c54cf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-955d4f38-14d7-4040-9404-31fa749c54cf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-955d4f38-14d7-4040-9404-31fa749c54cf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1378ca94-c987-4610-aa2b-9adee052daf6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1378ca94-c987-4610-aa2b-9adee052daf6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1378ca94-c987-4610-aa2b-9adee052daf6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "Bval_label.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8dZShOvfwdf",
        "outputId": "d4e4f173-9f5f-4d14-ee29-75f42cf2d2ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Common Identifiers: {12291, 10761, 11785, 15374, 10766, 10768, 11281, 13330, 10771, 16404, 13867, 16436, 12856, 12356, 10823, 12361, 16464, 13908, 13914, 13409, 10850, 19553, 19045, 11370, 14959, 10866, 16499, 10356, 17524, 17527, 18040, 14969, 14458, 10878, 14466, 15504, 10901, 19098, 16553, 13997, 15024, 19632, 14515, 10423, 12473, 16059, 16064, 14020, 14532, 19656, 19146, 19659, 18637, 13008, 15569, 18129, 16085, 14038, 11479, 15576, 15067, 17628, 19676, 16094, 16096, 12002, 17634, 18151, 18663, 12009, 12522, 18672, 13044, 16120, 15097, 15611, 13563, 11520, 12547, 12036, 12040, 15118, 16142, 16143, 15638, 11546, 13603, 12068, 20261, 10536, 17704, 11052, 11565, 11573, 14136, 15690, 12111, 12113, 14681, 13147, 12636, 20318, 14175, 14182, 15718, 18278, 10601, 11114, 16234, 20340, 15738, 19844, 16775, 18827, 12687, 12691, 19349, 10134, 11164, 16290, 14243, 16296, 20392, 11182, 14257, 20402, 18867, 10165, 18358, 14265, 17849, 17861, 16841, 13777, 11218, 11731, 10715, 14303, 10209, 11234, 11748, 14308, 17385, 12266, 17391, 13808, 16882, 10743, 17400, 17914}\n",
            "There are common identifiers.\n"
          ]
        }
      ],
      "source": [
        "# Get the unique identifiers from both dataframes\n",
        "identifiers_tweet = set(Bval_tweet['index'])\n",
        "identifiers_label = set(Bval_label['index'])\n",
        "\n",
        "# Find common identifiers using intersection\n",
        "common_identifiers = identifiers_tweet.intersection(identifiers_label)\n",
        "\n",
        "# Print common identifiers\n",
        "print(\"Common Identifiers:\", common_identifiers)\n",
        "\n",
        "# Check if there are any common identifiers\n",
        "if common_identifiers:\n",
        "    print(\"There are common identifiers.\")\n",
        "else:\n",
        "    print(\"No common identifiers found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hZrjHv1Bfwdg",
        "outputId": "50959363-e83a-4686-d01c-4b73e9b63bb7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     index                                              tweet  label\n",
              "0    10134  #ClimateChange  #Greenwashing #Renewables #Cli...      1\n",
              "1    10165  This can be the result when a workplace does n...      2\n",
              "2    10209  #dreadlocks is trending in Germany because #fr...      2\n",
              "3    10356  #FridaysForFuture #ClimateChange #Renewables #...      1\n",
              "4    10423  @Shevans9104 @paulmurphy_TD You could always g...      1\n",
              "..     ...                                                ...    ...\n",
              "145  20261  #Renewables  #Greenwashing #ClimateStrike #Ext...      1\n",
              "146  20318  https://t.co/QruGYeQgcp https://t.co/DOk69KYYu...      2\n",
              "147  20340  #ClimateCrisis #GlobalWarming #ClimateChange #...      1\n",
              "148  20392  #Greenwashing #Renewables #ClimateStrike #Exti...      1\n",
              "149  20402  #ExtinctionRebellion     #ClimateCrisis #Clima...      1\n",
              "\n",
              "[150 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fe04abf2-dae6-4ead-9b81-3758dc6a77f9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10134</td>\n",
              "      <td>#ClimateChange  #Greenwashing #Renewables #Cli...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10165</td>\n",
              "      <td>This can be the result when a workplace does n...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10209</td>\n",
              "      <td>#dreadlocks is trending in Germany because #fr...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10356</td>\n",
              "      <td>#FridaysForFuture #ClimateChange #Renewables #...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10423</td>\n",
              "      <td>@Shevans9104 @paulmurphy_TD You could always g...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>20261</td>\n",
              "      <td>#Renewables  #Greenwashing #ClimateStrike #Ext...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>20318</td>\n",
              "      <td>https://t.co/QruGYeQgcp https://t.co/DOk69KYYu...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>20340</td>\n",
              "      <td>#ClimateCrisis #GlobalWarming #ClimateChange #...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>20392</td>\n",
              "      <td>#Greenwashing #Renewables #ClimateStrike #Exti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>20402</td>\n",
              "      <td>#ExtinctionRebellion     #ClimateCrisis #Clima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe04abf2-dae6-4ead-9b81-3758dc6a77f9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fe04abf2-dae6-4ead-9b81-3758dc6a77f9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fe04abf2-dae6-4ead-9b81-3758dc6a77f9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d4715195-a3b8-4ef2-b4a6-5216170cc276\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d4715195-a3b8-4ef2-b4a6-5216170cc276')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d4715195-a3b8-4ef2-b4a6-5216170cc276 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_2082e561-9571-468c-a649-1a01029a9d1a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('Bval')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2082e561-9571-468c-a649-1a01029a9d1a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('Bval');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'identifier' is the common column in both dataframes\n",
        "# Concatenate Aval_tweet and Aval_label along columns (axis=1)\n",
        "Bval = pd.concat([Bval_tweet.set_index('index'), Bval_label.set_index('index')], axis=1)\n",
        "\n",
        "# Drop any rows with NaN values (if any)\n",
        "Bval = Bval.dropna()\n",
        "\n",
        "# Reset the index to make 'identifier' a regular column again\n",
        "Bval.reset_index(inplace=True)\n",
        "\n",
        "# Print the resulting DataFrame\n",
        "Bval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Z-aksh5vQoIS",
        "outputId": "21ebbfd8-f498-4a30-c338-ec0473e24dc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     index                                              tweet  label\n",
              "0    10000  british govt/msm sheer hypocrisy!!! â€˜Out of re...      2\n",
              "1    10004  This #FridaysForFuture on Zoom we will get boo...      2\n",
              "2    10046  Greenpeace: RT @mnyomb1: The #IPCC report is v...      2\n",
              "3    10072  @magdaghonem The massacre of trees in Egypt.\\n...      2\n",
              "4    10102  #FridaysForFuture Week 92\\n\\nTheðŸŒŽis changing t...      3\n",
              "..     ...                                                ...    ...\n",
              "145  19860  #ClimateStrike #ExtinctionRebellion #ClimateAc...      1\n",
              "146  19880  #ClimateStrike  #ExtinctionRebellion #ClimateA...      1\n",
              "147  19973  #FridaysForFuture #ClimateChange #Renewables #...      1\n",
              "148  20363  #ExtinctionRebellion #ClimateCrisis   #Climate...      1\n",
              "149  20391  #ClimateChange #Greenwashing #Renewables  #Cli...      1\n",
              "\n",
              "[150 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca2b289c-2d09-416e-b0a2-2a600e75f39e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>british govt/msm sheer hypocrisy!!! â€˜Out of re...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10004</td>\n",
              "      <td>This #FridaysForFuture on Zoom we will get boo...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10046</td>\n",
              "      <td>Greenpeace: RT @mnyomb1: The #IPCC report is v...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10072</td>\n",
              "      <td>@magdaghonem The massacre of trees in Egypt.\\n...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10102</td>\n",
              "      <td>#FridaysForFuture Week 92\\n\\nTheðŸŒŽis changing t...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>19860</td>\n",
              "      <td>#ClimateStrike #ExtinctionRebellion #ClimateAc...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>19880</td>\n",
              "      <td>#ClimateStrike  #ExtinctionRebellion #ClimateA...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>19973</td>\n",
              "      <td>#FridaysForFuture #ClimateChange #Renewables #...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>20363</td>\n",
              "      <td>#ExtinctionRebellion #ClimateCrisis   #Climate...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>20391</td>\n",
              "      <td>#ClimateChange #Greenwashing #Renewables  #Cli...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca2b289c-2d09-416e-b0a2-2a600e75f39e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ca2b289c-2d09-416e-b0a2-2a600e75f39e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ca2b289c-2d09-416e-b0a2-2a600e75f39e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ecdb95e9-69f2-4cf9-a8ab-0d5340d0e8b5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ecdb95e9-69f2-4cf9-a8ab-0d5340d0e8b5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ecdb95e9-69f2-4cf9-a8ab-0d5340d0e8b5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_63bf9c5b-94d7-4e6c-91c1-4cddf74e111b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('Btest')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_63bf9c5b-94d7-4e6c-91c1-4cddf74e111b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('Btest');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'identifier' is the common column in both dataframes\n",
        "# Concatenate Aval_tweet and Aval_label along columns (axis=1)\n",
        "Btest = pd.concat([Btest_tweet.set_index('index'), Btest_label.set_index('index')], axis=1)\n",
        "\n",
        "# Drop any rows with NaN values (if any)\n",
        "Btest = Btest.dropna()\n",
        "\n",
        "# Reset the index to make 'identifier' a regular column again\n",
        "Btest.reset_index(inplace=True)\n",
        "\n",
        "# Print the resulting DataFrame\n",
        "Btest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRU1aKz253-Q"
      },
      "source": [
        "# Data Set Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfF5fuQgtpMZ",
        "outputId": "7bca5e5e-8901-45e3-df9c-966403d2c494"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    563\n",
            "2    105\n",
            "3     31\n",
            "Name: label, dtype: int64\n",
            "1    120\n",
            "2     23\n",
            "3      7\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(Btrain['label'].value_counts())\n",
        "print(Bval_label['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2DH-h-3IwUdb"
      },
      "outputs": [],
      "source": [
        "train_corpus = Btrain[\"tweet\"].sum()\n",
        "test_corpus = Btest[\"tweet\"].sum()\n",
        "#test_corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9DHSoRN5-0u",
        "outputId": "f3a50291-1716-4fc7-c2f4-01feacecd42e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique words in training data: 2691\n",
            "Number of unique words in test data: 825\n",
            "Number of out-of-vocabulary (OOV) words: 423\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Remove punctuations\n",
        "chars_to_ignore = '[-,\\.:;\\'\"\\!?à¥¤]'\n",
        "\n",
        "train_corpus = re.sub(chars_to_ignore, ' ', train_corpus)\n",
        "train_vocab = set(train_corpus.split())\n",
        "\n",
        "test_corpus = re.sub(chars_to_ignore, ' ', test_corpus)\n",
        "test_vocab = set(test_corpus.split())\n",
        "\n",
        "oov = test_vocab - train_vocab\n",
        "\n",
        "print(\"Number of unique words in training data:\", len(train_vocab))\n",
        "print(\"Number of unique words in test data:\", len(test_vocab))\n",
        "print(\"Number of out-of-vocabulary (OOV) words:\", len(oov))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "B_6WCeew6G33",
        "outputId": "a0711ffd-1aba-495d-9042-f99e8f87aeb2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     index  \\\n",
              "694  20262   \n",
              "695  20293   \n",
              "696  20346   \n",
              "697  20366   \n",
              "698  20367   \n",
              "\n",
              "                                                                                                                                                                                                         tweet  \\\n",
              "694  #Renewables #Greenwashing     #ClimateStrike  #ExtinctionRebellion #ClimateCrisis #ClimateAction #GlobalWarming #FridaysForFuture #ClimateChange          \\n\\nYou've been fooled by Greta Thunberg:         \n",
              "695  #FridaysForFuture #ClimateChange #Renewables  #Greenwashing   #ClimateStrike  #ExtinctionRebellion #ClimateCrisis  #ClimateAction  #GlobalWarming             \\n\\nYou've been fooled by Greta Thunberg:     \n",
              "696  #FridaysForFuture #ClimateChange #Renewables #Greenwashing #ClimateStrike  #ExtinctionRebellion #ClimateCrisis #ClimateAction #GlobalWarming                \\n\\nYou've been fooled by Greta Thunberg:       \n",
              "697  #Greenwashing  #Renewables #ClimateStrike #ExtinctionRebellion #ClimateAction #ClimateCrisis #GlobalWarming  #FridaysForFuture #ClimateChange \\n\\nYou've been fooled by Greta Thunberg:                     \n",
              "698  #ClimateCrisis #ClimateAction #GlobalWarming   #FridaysForFuture   #ClimateChange  #Renewables #Greenwashing   #ExtinctionRebellion   #ClimateStrike            \\n\\nYou've been fooled by Greta Thunberg:   \n",
              "\n",
              "     label  \n",
              "694  1      \n",
              "695  1      \n",
              "696  1      \n",
              "697  1      \n",
              "698  1      "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47120108-02e6-4c1f-ac4d-d53683b333f4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>694</th>\n",
              "      <td>20262</td>\n",
              "      <td>#Renewables #Greenwashing     #ClimateStrike  #ExtinctionRebellion #ClimateCrisis #ClimateAction #GlobalWarming #FridaysForFuture #ClimateChange          \\n\\nYou've been fooled by Greta Thunberg:</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>20293</td>\n",
              "      <td>#FridaysForFuture #ClimateChange #Renewables  #Greenwashing   #ClimateStrike  #ExtinctionRebellion #ClimateCrisis  #ClimateAction  #GlobalWarming             \\n\\nYou've been fooled by Greta Thunberg:</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>696</th>\n",
              "      <td>20346</td>\n",
              "      <td>#FridaysForFuture #ClimateChange #Renewables #Greenwashing #ClimateStrike  #ExtinctionRebellion #ClimateCrisis #ClimateAction #GlobalWarming                \\n\\nYou've been fooled by Greta Thunberg:</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>697</th>\n",
              "      <td>20366</td>\n",
              "      <td>#Greenwashing  #Renewables #ClimateStrike #ExtinctionRebellion #ClimateAction #ClimateCrisis #GlobalWarming  #FridaysForFuture #ClimateChange \\n\\nYou've been fooled by Greta Thunberg:</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>698</th>\n",
              "      <td>20367</td>\n",
              "      <td>#ClimateCrisis #ClimateAction #GlobalWarming   #FridaysForFuture   #ClimateChange  #Renewables #Greenwashing   #ExtinctionRebellion   #ClimateStrike            \\n\\nYou've been fooled by Greta Thunberg:</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47120108-02e6-4c1f-ac4d-d53683b333f4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-47120108-02e6-4c1f-ac4d-d53683b333f4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-47120108-02e6-4c1f-ac4d-d53683b333f4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-36edfd60-dec5-4d3a-b48b-2fd4d725b055\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-36edfd60-dec5-4d3a-b48b-2fd4d725b055')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-36edfd60-dec5-4d3a-b48b-2fd4d725b055 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "filtered_train = Btrain[lambda x: x[\"tweet\"].str.contains(\"[^A-Za-z0-9]\")]\n",
        "\n",
        "with pd.option_context('display.max_colwidth', 0):\n",
        "    display(filtered_train.tail(n=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz3r9WDBYBpO",
        "outputId": "025aa572-398d-4358-9758-8cef30e5db59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(699, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "filtered_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s5oYoJ_YBpO"
      },
      "source": [
        "## Check For Codemixed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Xb-Bzb9sYBpO",
        "outputId": "0f03a642-af05-4c08-9e24-6637215f594f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     index  \\\n",
              "694  20262   \n",
              "695  20293   \n",
              "696  20346   \n",
              "697  20366   \n",
              "698  20367   \n",
              "\n",
              "                                                                                                                                                                                                         tweet  \\\n",
              "694  #Renewables #Greenwashing     #ClimateStrike  #ExtinctionRebellion #ClimateCrisis #ClimateAction #GlobalWarming #FridaysForFuture #ClimateChange          \\n\\nYou've been fooled by Greta Thunberg:         \n",
              "695  #FridaysForFuture #ClimateChange #Renewables  #Greenwashing   #ClimateStrike  #ExtinctionRebellion #ClimateCrisis  #ClimateAction  #GlobalWarming             \\n\\nYou've been fooled by Greta Thunberg:     \n",
              "696  #FridaysForFuture #ClimateChange #Renewables #Greenwashing #ClimateStrike  #ExtinctionRebellion #ClimateCrisis #ClimateAction #GlobalWarming                \\n\\nYou've been fooled by Greta Thunberg:       \n",
              "697  #Greenwashing  #Renewables #ClimateStrike #ExtinctionRebellion #ClimateAction #ClimateCrisis #GlobalWarming  #FridaysForFuture #ClimateChange \\n\\nYou've been fooled by Greta Thunberg:                     \n",
              "698  #ClimateCrisis #ClimateAction #GlobalWarming   #FridaysForFuture   #ClimateChange  #Renewables #Greenwashing   #ExtinctionRebellion   #ClimateStrike            \\n\\nYou've been fooled by Greta Thunberg:   \n",
              "\n",
              "     label  \n",
              "694  1      \n",
              "695  1      \n",
              "696  1      \n",
              "697  1      \n",
              "698  1      "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f39fd46a-76be-4a9a-910d-94aead8a652a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>694</th>\n",
              "      <td>20262</td>\n",
              "      <td>#Renewables #Greenwashing     #ClimateStrike  #ExtinctionRebellion #ClimateCrisis #ClimateAction #GlobalWarming #FridaysForFuture #ClimateChange          \\n\\nYou've been fooled by Greta Thunberg:</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>20293</td>\n",
              "      <td>#FridaysForFuture #ClimateChange #Renewables  #Greenwashing   #ClimateStrike  #ExtinctionRebellion #ClimateCrisis  #ClimateAction  #GlobalWarming             \\n\\nYou've been fooled by Greta Thunberg:</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>696</th>\n",
              "      <td>20346</td>\n",
              "      <td>#FridaysForFuture #ClimateChange #Renewables #Greenwashing #ClimateStrike  #ExtinctionRebellion #ClimateCrisis #ClimateAction #GlobalWarming                \\n\\nYou've been fooled by Greta Thunberg:</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>697</th>\n",
              "      <td>20366</td>\n",
              "      <td>#Greenwashing  #Renewables #ClimateStrike #ExtinctionRebellion #ClimateAction #ClimateCrisis #GlobalWarming  #FridaysForFuture #ClimateChange \\n\\nYou've been fooled by Greta Thunberg:</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>698</th>\n",
              "      <td>20367</td>\n",
              "      <td>#ClimateCrisis #ClimateAction #GlobalWarming   #FridaysForFuture   #ClimateChange  #Renewables #Greenwashing   #ExtinctionRebellion   #ClimateStrike            \\n\\nYou've been fooled by Greta Thunberg:</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f39fd46a-76be-4a9a-910d-94aead8a652a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f39fd46a-76be-4a9a-910d-94aead8a652a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f39fd46a-76be-4a9a-910d-94aead8a652a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c015988f-38a2-4518-84af-ab02a677bef6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c015988f-38a2-4518-84af-ab02a677bef6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c015988f-38a2-4518-84af-ab02a677bef6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "filtered_train = Btrain[Btrain['tweet'].str.contains('[A-Za-z]+') & Btrain['tweet'].str.contains('[^A-Za-z]+')]\n",
        "with pd.option_context('display.max_colwidth', 0):\n",
        "    display(filtered_train.tail(n=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqKOGDtd6UQE",
        "outputId": "c7eccbf8-a7a1-491e-a907-fdac89d1eb7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(699, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "filtered_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkRvGTp4uiKq",
        "outputId": "e83aef5f-5938-43f0-9e5e-e2aeec60da68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL Frequency:\n",
            "https://t.co/16v1D8AO1r    2\n",
            "https://t.co/6UjY9djsCv    1\n",
            "https://t.co/fs4vvNjobH    1\n",
            "https://t.co/u2GhFi1fTI    1\n",
            "https://t.co/TJ4wceonno    1\n",
            "                          ..\n",
            "https://t.co/TlD3upK4KQ    1\n",
            "https://t.co/dgQvZR6ygD    1\n",
            "https://t.co/xPIdUste3F    1\n",
            "https://t.co/u4R7k7ycfQ    1\n",
            "https://t.co/TCihqcLNn9    1\n",
            "Name: URL, Length: 108, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Assuming 'tweet' is the column where you want to find and count similar URLs\n",
        "tweets = Btrain['tweet']\n",
        "\n",
        "# Define a regular expression to extract URLs\n",
        "url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "\n",
        "# Extract URLs from each tweet\n",
        "all_urls = [url_pattern.findall(tweet) for tweet in tweets]\n",
        "\n",
        "# Flatten the list of lists into a single list\n",
        "all_urls_flat = [url for sublist in all_urls for url in sublist]\n",
        "\n",
        "# Create a DataFrame to count the occurrences of each URL\n",
        "url_df = pd.DataFrame(all_urls_flat, columns=['URL'])\n",
        "url_frequency = url_df['URL'].value_counts()\n",
        "\n",
        "# Display the count of occurrences for each unique URL\n",
        "print(\"URL Frequency:\")\n",
        "print(url_frequency)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk0JlKccu8sO",
        "outputId": "6f05f4a9-da02-48ae-919f-ca94b4a5a033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of common URLs: 1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Assuming 'tweet' is the column where you want to find and compare URLs\n",
        "train_tweets = Btrain['tweet']\n",
        "test_tweets = Btest['tweet']\n",
        "\n",
        "# Define a regular expression to extract URLs\n",
        "url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "\n",
        "# Extract URLs from each tweet in train dataset\n",
        "train_urls = [url_pattern.findall(tweet) for tweet in train_tweets]\n",
        "train_urls_flat = [url for sublist in train_urls for url in sublist]\n",
        "\n",
        "# Extract URLs from each tweet in test dataset\n",
        "test_urls = [url_pattern.findall(tweet) for tweet in test_tweets]\n",
        "test_urls_flat = [url for sublist in test_urls for url in sublist]\n",
        "\n",
        "# Find common URLs between train and test datasets\n",
        "common_urls = set(train_urls_flat).intersection(test_urls_flat)\n",
        "\n",
        "# Display common URLs\n",
        "# print(\"Common URLs:\")\n",
        "# print(common_urls)\n",
        "\n",
        "num_common_urls = len(common_urls)\n",
        "print(f\"Number of common URLs: {num_common_urls}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hphD1uHEv9_0"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "vM9H1NMmYBpP"
      },
      "outputs": [],
      "source": [
        "# import re\n",
        "# from collections import Counter\n",
        "\n",
        "# # Assuming Btrain['tweet'] is a pandas Series containing the tweets\n",
        "# all_tokens = []\n",
        "\n",
        "# for tweet in Btrain['tweet']:\n",
        "#     # Find all tokens starting with a hash(#) or at the rate(@) and followed by some number of alphabets or numbers\n",
        "#     matches = re.findall(r'[@#][_a-zA-Z0-9]+', tweet)\n",
        "\n",
        "#     # Extend the list of all tokens with the matches for each tweet\n",
        "#     all_tokens.extend(matches)\n",
        "\n",
        "# # Count the occurrences of each token\n",
        "# token_counts = Counter(all_tokens)\n",
        "\n",
        "# # Display tokens sorted by count\n",
        "# sorted_tokens = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# for token, count in sorted_tokens:\n",
        "#     print(f\"{token}: {count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "OyfV6dRn6eJa"
      },
      "outputs": [],
      "source": [
        "def text_to_word_list(text):\n",
        "    text = text.split()\n",
        "    return text\n",
        "\n",
        "def replace_strings(text):\n",
        "    emoji = re.compile(\"[\"         # this emoj is to remove all emojis\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u\"\\U00010000-\\U0010ffff\"\n",
        "        u\"\\u00C0-\\u017F\"          #latin\n",
        "        u\"\\u2000-\\u206F\"          #generalPunctuations\n",
        "        u\"\\u2640-\\u2642\"\n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\ufe0f\"  # dingbats\n",
        "        u\"\\u3030\" \"]+\", re.UNICODE)\n",
        "\n",
        "    text = text.lower()\n",
        "    url_pattern = r'https?://\\S+|www\\.\\S+'\n",
        "    text = re.sub(url_pattern, ' ', text)\n",
        "\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "    text = re.sub(r'(https|http|www)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', ' ', text, flags=re.MULTILINE)\n",
        "    # emoji removal\n",
        "    text = emoji.sub(r' ',text)\n",
        "    # text = re.sub(r'[@#][_a-zA-Z0-9]+', ' ', text)\n",
        "    text = text.replace('\\n', ' ')\n",
        "    text = text.replace('â€”', ' ')\n",
        "    return text\n",
        "\n",
        "def remove_punctuations(my_str):\n",
        "    # define punctuation\n",
        "    punctuations = '''````Â£|Â¢|Ã‘+-*=à§³à¥¤!/_:.()-[]{};'\"â€œ\\â€™,<>?@#$%^&*~â€˜â€”à¥¥â€â€°ï¿°à§·ï¿°'''\n",
        "    no_punct = \"\"\n",
        "    for char in my_str:\n",
        "        if char not in punctuations:\n",
        "            no_punct = no_punct + char\n",
        "        else :\n",
        "            no_punct = no_punct + \" \"\n",
        "\n",
        "    no_punct = re.sub(r'\\s+', ' ', no_punct)  #replace multiple space with single space\n",
        "\n",
        "    return no_punct\n",
        "\n",
        "def joining(text):\n",
        "    out=' '.join(text)\n",
        "    return out\n",
        "\n",
        "def preprocessing(text):\n",
        "    out=remove_punctuations(replace_strings(text))\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "dGEkuz8_6jOj"
      },
      "outputs": [],
      "source": [
        "Btrain['cleanText'] = Btrain.tweet.apply(lambda x: preprocessing(str(x)))\n",
        "Bval['cleanText'] = Bval.tweet.apply(lambda x: preprocessing(str(x)))\n",
        "Btest['cleanText'] = Btest.tweet.apply(lambda x: preprocessing(str(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gmrqe_L5YBpQ"
      },
      "source": [
        "## Stop Words Removal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysU0A3leciPw",
        "outputId": "bdc5bccf-3b8b-470c-b3f0-b0af19c162f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "nltk.download('all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "insOxDfuYBpQ"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "def remove_stopwords(text):\n",
        "    \"\"\"custom function to remove the stopwords\"\"\"\n",
        "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
        "\n",
        "Btrain[\"cleanText\"] = Btrain[\"cleanText\"].apply(lambda text: remove_stopwords(text))\n",
        "Bval[\"cleanText\"] = Bval[\"cleanText\"].apply(lambda text: remove_stopwords(text))\n",
        "Btest[\"cleanText\"] = Btest[\"cleanText\"].apply(lambda text: remove_stopwords(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TdXDypk1YBpR",
        "outputId": "e42ebae9-2eca-410d-85d7-26936f5e0dc9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index                                              tweet  label  \\\n",
              "0  10011  #ClimateCrisis #ClimateAction #GlobalWarming  ...      1   \n",
              "1  10014  #ClimateCrisis    #ClimateAction #GlobalWarmin...      1   \n",
              "2  10021  Major climate denier Pat Michaels has died.  D...      1   \n",
              "3  10028  #Greenwashing #ExtinctionRebellion #ClimateAct...      1   \n",
              "4  10034  #ExtinctionRebellion      #ClimateCrisis #Clim...      1   \n",
              "5  10036  Gas and nuclear are not green! \\nThe new #EUTa...      2   \n",
              "6  10039  ONLY ONE DAY UNTIL THE #ClimateStrike!!! ðŸ”¥\\n\\n...      2   \n",
              "7  10040  It is time for all U.K. citizens to call out t...      2   \n",
              "8  10068  Week 106. Pakistan is one of the countries lea...      2   \n",
              "9  10085  So now the Palm Oil Industry is trying to rebr...      2   \n",
              "\n",
              "                                           cleanText  \n",
              "0  climatecrisis climateaction globalwarming frid...  \n",
              "1  climatecrisis climateaction globalwarming frid...  \n",
              "2  major climate denier pat michaels died really ...  \n",
              "3  greenwashing extinctionrebellion climateaction...  \n",
              "4  extinctionrebellion climatecrisis climateactio...  \n",
              "5  gas nuclear green new eutaxonomy safeguarding ...  \n",
              "6  one day climatestrike one year ago cop26 left ...  \n",
              "7  time u k citizens call hypocrisy conservative ...  \n",
              "8  week 106 pakistan one countries least responsi...  \n",
              "9  palm oil industry trying rebrand deforestation...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c47ea64c-59d9-4d03-935b-07adc9f3336a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>cleanText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10011</td>\n",
              "      <td>#ClimateCrisis #ClimateAction #GlobalWarming  ...</td>\n",
              "      <td>1</td>\n",
              "      <td>climatecrisis climateaction globalwarming frid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10014</td>\n",
              "      <td>#ClimateCrisis    #ClimateAction #GlobalWarmin...</td>\n",
              "      <td>1</td>\n",
              "      <td>climatecrisis climateaction globalwarming frid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10021</td>\n",
              "      <td>Major climate denier Pat Michaels has died.  D...</td>\n",
              "      <td>1</td>\n",
              "      <td>major climate denier pat michaels died really ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10028</td>\n",
              "      <td>#Greenwashing #ExtinctionRebellion #ClimateAct...</td>\n",
              "      <td>1</td>\n",
              "      <td>greenwashing extinctionrebellion climateaction...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10034</td>\n",
              "      <td>#ExtinctionRebellion      #ClimateCrisis #Clim...</td>\n",
              "      <td>1</td>\n",
              "      <td>extinctionrebellion climatecrisis climateactio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10036</td>\n",
              "      <td>Gas and nuclear are not green! \\nThe new #EUTa...</td>\n",
              "      <td>2</td>\n",
              "      <td>gas nuclear green new eutaxonomy safeguarding ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10039</td>\n",
              "      <td>ONLY ONE DAY UNTIL THE #ClimateStrike!!! ðŸ”¥\\n\\n...</td>\n",
              "      <td>2</td>\n",
              "      <td>one day climatestrike one year ago cop26 left ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10040</td>\n",
              "      <td>It is time for all U.K. citizens to call out t...</td>\n",
              "      <td>2</td>\n",
              "      <td>time u k citizens call hypocrisy conservative ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10068</td>\n",
              "      <td>Week 106. Pakistan is one of the countries lea...</td>\n",
              "      <td>2</td>\n",
              "      <td>week 106 pakistan one countries least responsi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10085</td>\n",
              "      <td>So now the Palm Oil Industry is trying to rebr...</td>\n",
              "      <td>2</td>\n",
              "      <td>palm oil industry trying rebrand deforestation...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c47ea64c-59d9-4d03-935b-07adc9f3336a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c47ea64c-59d9-4d03-935b-07adc9f3336a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c47ea64c-59d9-4d03-935b-07adc9f3336a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7bd2737d-6979-45c5-8231-4f17bb010985\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7bd2737d-6979-45c5-8231-4f17bb010985')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7bd2737d-6979-45c5-8231-4f17bb010985 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "Btrain.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "XSQqQf95YBpR",
        "outputId": "619134fc-8874-4821-921e-4d337c1922df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index                                              tweet  label  \\\n",
              "0  10134  #ClimateChange  #Greenwashing #Renewables #Cli...      1   \n",
              "1  10165  This can be the result when a workplace does n...      2   \n",
              "2  10209  #dreadlocks is trending in Germany because #fr...      2   \n",
              "3  10356  #FridaysForFuture #ClimateChange #Renewables #...      1   \n",
              "4  10423  @Shevans9104 @paulmurphy_TD You could always g...      1   \n",
              "5  10536  #FridaysForFuture #ClimateChange #Greenwashing...      1   \n",
              "6  10601  #ClimateCrisis  #ClimateAction   #GlobalWarmin...      1   \n",
              "7  10715  #ClimateCrisis #ClimateAction #GlobalWarming  ...      1   \n",
              "8  10743  SaBEEne in her natural gracility\\nbelieves she...      1   \n",
              "9  10761  we have to wage war against fossil fuel compan...      2   \n",
              "\n",
              "                                           cleanText  \n",
              "0  climatechange greenwashing renewables climates...  \n",
              "1  result workplace practice austismacceptance gr...  \n",
              "2  dreadlocks trending germany fridaysforfuture w...  \n",
              "3  fridaysforfuture climatechange renewables gree...  \n",
              "4  shevans9104 paulmurphy td could always go outs...  \n",
              "5  fridaysforfuture climatechange greenwashing re...  \n",
              "6  climatecrisis climateaction globalwarming frid...  \n",
              "7  climatecrisis climateaction globalwarming frid...  \n",
              "8  sabeene natural gracility believes model civil...  \n",
              "9  wage war fossil fuel companies earning destruc...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47d2b0cb-247e-48bd-af87-78e849bbf615\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>cleanText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10134</td>\n",
              "      <td>#ClimateChange  #Greenwashing #Renewables #Cli...</td>\n",
              "      <td>1</td>\n",
              "      <td>climatechange greenwashing renewables climates...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10165</td>\n",
              "      <td>This can be the result when a workplace does n...</td>\n",
              "      <td>2</td>\n",
              "      <td>result workplace practice austismacceptance gr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10209</td>\n",
              "      <td>#dreadlocks is trending in Germany because #fr...</td>\n",
              "      <td>2</td>\n",
              "      <td>dreadlocks trending germany fridaysforfuture w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10356</td>\n",
              "      <td>#FridaysForFuture #ClimateChange #Renewables #...</td>\n",
              "      <td>1</td>\n",
              "      <td>fridaysforfuture climatechange renewables gree...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10423</td>\n",
              "      <td>@Shevans9104 @paulmurphy_TD You could always g...</td>\n",
              "      <td>1</td>\n",
              "      <td>shevans9104 paulmurphy td could always go outs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10536</td>\n",
              "      <td>#FridaysForFuture #ClimateChange #Greenwashing...</td>\n",
              "      <td>1</td>\n",
              "      <td>fridaysforfuture climatechange greenwashing re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10601</td>\n",
              "      <td>#ClimateCrisis  #ClimateAction   #GlobalWarmin...</td>\n",
              "      <td>1</td>\n",
              "      <td>climatecrisis climateaction globalwarming frid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10715</td>\n",
              "      <td>#ClimateCrisis #ClimateAction #GlobalWarming  ...</td>\n",
              "      <td>1</td>\n",
              "      <td>climatecrisis climateaction globalwarming frid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10743</td>\n",
              "      <td>SaBEEne in her natural gracility\\nbelieves she...</td>\n",
              "      <td>1</td>\n",
              "      <td>sabeene natural gracility believes model civil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10761</td>\n",
              "      <td>we have to wage war against fossil fuel compan...</td>\n",
              "      <td>2</td>\n",
              "      <td>wage war fossil fuel companies earning destruc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47d2b0cb-247e-48bd-af87-78e849bbf615')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-47d2b0cb-247e-48bd-af87-78e849bbf615 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-47d2b0cb-247e-48bd-af87-78e849bbf615');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-47988c37-7972-497b-a7c1-2ccbed046606\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-47988c37-7972-497b-a7c1-2ccbed046606')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-47988c37-7972-497b-a7c1-2ccbed046606 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "Bval.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTLcsZDOYBpR"
      },
      "source": [
        "## Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "5rxVSj_aYBpS"
      },
      "outputs": [],
      "source": [
        "# from nltk.corpus import wordnet\n",
        "# from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# lemmatizer = WordNetLemmatizer()\n",
        "# wordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n",
        "# def lemmatize_words(text):\n",
        "#     pos_tagged_text = nltk.pos_tag(text.split())\n",
        "#     return \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n",
        "\n",
        "\n",
        "# Btrain[\"cleanText\"] = Btrain[\"cleanText\"].apply(lambda text: lemmatize_words(text))\n",
        "# Bval[\"cleanText\"] = Bval[\"cleanText\"].apply(lambda text: lemmatize_words(text))\n",
        "# Btest[\"cleanText\"] = Btest[\"cleanText\"].apply(lambda text: lemmatize_words(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "5cNzxDSnYBpS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0415b735-0858-4636-ac13-ffa5eccf19cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n",
            "2024-01-17 13:47:21.344753: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-17 13:47:21.344820: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-17 13:47:21.346181: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-17 13:47:22.646684: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "DNSqLxzFYBpT"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "# Load the English language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Function to perform lemmatization using spaCy\n",
        "def lemmatize_with_spacy(text):\n",
        "    # Process the text using spaCy\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Extract lemmatized tokens and join them back into a string\n",
        "    lemmatized_text = \" \".join([token.lemma_ for token in doc])\n",
        "\n",
        "    return lemmatized_text\n",
        "\n",
        "# Apply the lemmatization function to your DataFrame columns\n",
        "Btrain[\"cleanText\"] = Btrain[\"cleanText\"].apply(lemmatize_with_spacy)\n",
        "Bval[\"cleanText\"] = Bval[\"cleanText\"].apply(lemmatize_with_spacy)\n",
        "Btest[\"cleanText\"] = Btest[\"cleanText\"].apply(lemmatize_with_spacy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jvz3PMFcYBpT",
        "outputId": "b3477689-1643-4e0c-c79e-f17c256ace0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index                                              tweet  label  \\\n",
              "0  10011  #ClimateCrisis #ClimateAction #GlobalWarming  ...      1   \n",
              "1  10014  #ClimateCrisis    #ClimateAction #GlobalWarmin...      1   \n",
              "2  10021  Major climate denier Pat Michaels has died.  D...      1   \n",
              "3  10028  #Greenwashing #ExtinctionRebellion #ClimateAct...      1   \n",
              "4  10034  #ExtinctionRebellion      #ClimateCrisis #Clim...      1   \n",
              "5  10036  Gas and nuclear are not green! \\nThe new #EUTa...      2   \n",
              "6  10039  ONLY ONE DAY UNTIL THE #ClimateStrike!!! ðŸ”¥\\n\\n...      2   \n",
              "7  10040  It is time for all U.K. citizens to call out t...      2   \n",
              "8  10068  Week 106. Pakistan is one of the countries lea...      2   \n",
              "9  10085  So now the Palm Oil Industry is trying to rebr...      2   \n",
              "\n",
              "                                           cleanText  \n",
              "0  climatecrisis climateaction globalwarme friday...  \n",
              "1  climatecrisis climateaction globalwarme friday...  \n",
              "2  major climate denier pat michael die really kn...  \n",
              "3  greenwashe extinctionrebellion climateaction c...  \n",
              "4  extinctionrebellion climatecrisis climateactio...  \n",
              "5  gas nuclear green new eutaxonomy safeguard fut...  \n",
              "6  one day climatestrike one year ago cop26 leave...  \n",
              "7  time u k citizen call hypocrisy conservative g...  \n",
              "8  week 106 pakistan one country least responsibl...  \n",
              "9  palm oil industry try rebrand deforestation re...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a3815a7-c06d-47d4-baf1-325b376dbeb1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>cleanText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10011</td>\n",
              "      <td>#ClimateCrisis #ClimateAction #GlobalWarming  ...</td>\n",
              "      <td>1</td>\n",
              "      <td>climatecrisis climateaction globalwarme friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10014</td>\n",
              "      <td>#ClimateCrisis    #ClimateAction #GlobalWarmin...</td>\n",
              "      <td>1</td>\n",
              "      <td>climatecrisis climateaction globalwarme friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10021</td>\n",
              "      <td>Major climate denier Pat Michaels has died.  D...</td>\n",
              "      <td>1</td>\n",
              "      <td>major climate denier pat michael die really kn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10028</td>\n",
              "      <td>#Greenwashing #ExtinctionRebellion #ClimateAct...</td>\n",
              "      <td>1</td>\n",
              "      <td>greenwashe extinctionrebellion climateaction c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10034</td>\n",
              "      <td>#ExtinctionRebellion      #ClimateCrisis #Clim...</td>\n",
              "      <td>1</td>\n",
              "      <td>extinctionrebellion climatecrisis climateactio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10036</td>\n",
              "      <td>Gas and nuclear are not green! \\nThe new #EUTa...</td>\n",
              "      <td>2</td>\n",
              "      <td>gas nuclear green new eutaxonomy safeguard fut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10039</td>\n",
              "      <td>ONLY ONE DAY UNTIL THE #ClimateStrike!!! ðŸ”¥\\n\\n...</td>\n",
              "      <td>2</td>\n",
              "      <td>one day climatestrike one year ago cop26 leave...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10040</td>\n",
              "      <td>It is time for all U.K. citizens to call out t...</td>\n",
              "      <td>2</td>\n",
              "      <td>time u k citizen call hypocrisy conservative g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10068</td>\n",
              "      <td>Week 106. Pakistan is one of the countries lea...</td>\n",
              "      <td>2</td>\n",
              "      <td>week 106 pakistan one country least responsibl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10085</td>\n",
              "      <td>So now the Palm Oil Industry is trying to rebr...</td>\n",
              "      <td>2</td>\n",
              "      <td>palm oil industry try rebrand deforestation re...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a3815a7-c06d-47d4-baf1-325b376dbeb1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9a3815a7-c06d-47d4-baf1-325b376dbeb1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9a3815a7-c06d-47d4-baf1-325b376dbeb1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1f245bda-01d7-40b4-ad10-f39cac467ca8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1f245bda-01d7-40b4-ad10-f39cac467ca8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1f245bda-01d7-40b4-ad10-f39cac467ca8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "Btrain.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "T5nJO6CgYBpT",
        "outputId": "00448557-b633-41bf-a0d1-1fac7b9ecb94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index                                              tweet  label  \\\n",
              "0  10134  #ClimateChange  #Greenwashing #Renewables #Cli...      1   \n",
              "1  10165  This can be the result when a workplace does n...      2   \n",
              "2  10209  #dreadlocks is trending in Germany because #fr...      2   \n",
              "3  10356  #FridaysForFuture #ClimateChange #Renewables #...      1   \n",
              "4  10423  @Shevans9104 @paulmurphy_TD You could always g...      1   \n",
              "5  10536  #FridaysForFuture #ClimateChange #Greenwashing...      1   \n",
              "6  10601  #ClimateCrisis  #ClimateAction   #GlobalWarmin...      1   \n",
              "7  10715  #ClimateCrisis #ClimateAction #GlobalWarming  ...      1   \n",
              "8  10743  SaBEEne in her natural gracility\\nbelieves she...      1   \n",
              "9  10761  we have to wage war against fossil fuel compan...      2   \n",
              "\n",
              "                                           cleanText  \n",
              "0  climatechange greenwashing renewable climatest...  \n",
              "1  result workplace practice austismacceptance gr...  \n",
              "2  dreadlock trend germany fridaysforfuture want ...  \n",
              "3  fridaysforfuture climatechange renewable green...  \n",
              "4  shevans9104 paulmurphy td could always go outs...  \n",
              "5  fridaysforfuture climatechange greenwashing re...  \n",
              "6  climatecrisis climateaction globalwarme friday...  \n",
              "7  climatecrisis climateaction globalwarme friday...  \n",
              "8  sabeene natural gracility believe model civili...  \n",
              "9  wage war fossil fuel company earn destruction ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-143c6c0a-bbbe-4490-8f5a-3856f7476b12\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>cleanText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10134</td>\n",
              "      <td>#ClimateChange  #Greenwashing #Renewables #Cli...</td>\n",
              "      <td>1</td>\n",
              "      <td>climatechange greenwashing renewable climatest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10165</td>\n",
              "      <td>This can be the result when a workplace does n...</td>\n",
              "      <td>2</td>\n",
              "      <td>result workplace practice austismacceptance gr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10209</td>\n",
              "      <td>#dreadlocks is trending in Germany because #fr...</td>\n",
              "      <td>2</td>\n",
              "      <td>dreadlock trend germany fridaysforfuture want ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10356</td>\n",
              "      <td>#FridaysForFuture #ClimateChange #Renewables #...</td>\n",
              "      <td>1</td>\n",
              "      <td>fridaysforfuture climatechange renewable green...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10423</td>\n",
              "      <td>@Shevans9104 @paulmurphy_TD You could always g...</td>\n",
              "      <td>1</td>\n",
              "      <td>shevans9104 paulmurphy td could always go outs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10536</td>\n",
              "      <td>#FridaysForFuture #ClimateChange #Greenwashing...</td>\n",
              "      <td>1</td>\n",
              "      <td>fridaysforfuture climatechange greenwashing re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10601</td>\n",
              "      <td>#ClimateCrisis  #ClimateAction   #GlobalWarmin...</td>\n",
              "      <td>1</td>\n",
              "      <td>climatecrisis climateaction globalwarme friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10715</td>\n",
              "      <td>#ClimateCrisis #ClimateAction #GlobalWarming  ...</td>\n",
              "      <td>1</td>\n",
              "      <td>climatecrisis climateaction globalwarme friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10743</td>\n",
              "      <td>SaBEEne in her natural gracility\\nbelieves she...</td>\n",
              "      <td>1</td>\n",
              "      <td>sabeene natural gracility believe model civili...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10761</td>\n",
              "      <td>we have to wage war against fossil fuel compan...</td>\n",
              "      <td>2</td>\n",
              "      <td>wage war fossil fuel company earn destruction ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-143c6c0a-bbbe-4490-8f5a-3856f7476b12')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-143c6c0a-bbbe-4490-8f5a-3856f7476b12 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-143c6c0a-bbbe-4490-8f5a-3856f7476b12');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8b9b7d9f-e247-4e6b-8170-734850abbc7b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8b9b7d9f-e247-4e6b-8170-734850abbc7b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8b9b7d9f-e247-4e6b-8170-734850abbc7b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "Bval.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdSqmUkvYBpk"
      },
      "source": [
        "# Remove Duplicate Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8pV8omEYBpk",
        "outputId": "207112f2-af20-4890-8c5d-543c7a4b2c32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "\n",
            "[('fridaysforfuture', 564), ('climatechange', 514), ('extinctionrebellion', 508), ('climateaction', 502), ('greta', 502), ('climatestrike', 493), ('thunberg', 493), ('climatecrisis', 489), ('fool', 488), ('renewable', 486), ('globalwarme', 341), ('greenwashing', 283), ('greenwashe', 224), ('globalwarming', 169), ('lie', 41), ('we', 41), ('keep', 21), ('every', 20), ('green', 20), ('many', 19)]\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Assuming Btrain['tweet'] and Btrain['label'] are your tweet and label columns\n",
        "class_1_tweets = Btrain[Btrain['label'] == 0]['cleanText']\n",
        "class_2_tweets = Btrain[Btrain['label'] == 1]['cleanText']\n",
        "\n",
        "# Tokenize the tweets\n",
        "class_1_tokens = [token.lower() for tweet in class_1_tweets for token in word_tokenize(tweet)]\n",
        "class_2_tokens = [token.lower() for tweet in class_2_tweets for token in word_tokenize(tweet)]\n",
        "\n",
        "\n",
        "# Count the frequency of each token\n",
        "counter_class_1 = Counter(class_1_tokens)\n",
        "counter_class_2 = Counter(class_2_tokens)\n",
        "print(counter_class_1.most_common(20))\n",
        "print()\n",
        "print(counter_class_2.most_common(20))\n",
        "# Find the top 100 common tokens\n",
        "common_tokens = set(counter_class_1.most_common(50)).intersection(counter_class_2.most_common(50))\n",
        "\n",
        "# Print common tokens and their frequencies\n",
        "for token, freq in common_tokens:\n",
        "    print(f\"Token: {token}, Class 1 Frequency: {counter_class_1[token]}, Class 2 Frequency: {counter_class_2[token]}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "-FzBCx40YBpl"
      },
      "outputs": [],
      "source": [
        "# words_to_remove = [, 'climate', 'climBtestrike', 'climatecrisis', 'strike',\n",
        "#                    'peoplenotprofit', 'climBtestrike', 'climateaction', 'climatecrisis',\n",
        "#                    'extinctionrebellion', 'climatechange', 'thunberg', 'greta',\n",
        "#                    'gretathunberg', 'climateemergency', 'climatejustice',\n",
        "#                    'climateactionnow', 'renewable', 'crisis', 'change', 'action']\n",
        "\n",
        "# words_to_remove = ['fridaysforfuture']\n",
        "\n",
        "# def remove_specific_words(text):\n",
        "#     for word in words_to_remove:\n",
        "#         text = text.replace(word, '')\n",
        "#     return text\n",
        "\n",
        "# Btrain['cleanText'] = Btrain['cleanText'].apply(remove_specific_words)\n",
        "\n",
        "# Bval['cleanText'] = Bval['cleanText'].apply(remove_specific_words)\n",
        "\n",
        "# Btest['cleanText'] = Btest['cleanText'].apply(remove_specific_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN0FgBIkfQYH",
        "outputId": "cec2146f-4410-419c-d539-838ef59d1568"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label 1: 488 occurrences\n"
          ]
        }
      ],
      "source": [
        "# Text to search\n",
        "search_text = \"fool greta thunberg\"\n",
        "\n",
        "# Initialize a dictionary to store label-wise frequencies\n",
        "label_frequencies = {}\n",
        "\n",
        "# Iterate over each row in Btrain\n",
        "for index, row in Btrain.iterrows():\n",
        "    label = row['label']\n",
        "    tweet_text = row['cleanText']\n",
        "\n",
        "    # Check if the search text is present in the tweet text\n",
        "    if search_text in tweet_text:\n",
        "        # Increment the count for the label\n",
        "        label_frequencies[label] = label_frequencies.get(label, 0) + 1\n",
        "\n",
        "# Display the label-wise frequencies\n",
        "for label, frequency in label_frequencies.items():\n",
        "    print(f\"Label {label}: {frequency} occurrences\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "6_5skT7Qfwdq"
      },
      "outputs": [],
      "source": [
        "# for text in Btrain[(Btrain['cleanText'].str.contains('greta thunberg')) & (Btrain['label'] == 3)]['cleanText']:\n",
        "#     print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "CeYvvmHsfwdq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming Atrain['cleanText'] is the column containing the text\n",
        "\n",
        "# Keep just one row containing that text\n",
        "one_row = Btrain[Btrain['cleanText'].str.contains(\"fool greta thunberg\")].head(1)\n",
        "\n",
        "\n",
        "# Drop rows containing the specified text\n",
        "Btrain = Btrain[~Btrain['cleanText'].str.contains(\"fool greta thunberg\")]\n",
        "\n",
        "\n",
        "# Concatenate the one_row with the original DataFrame\n",
        "Btrain = pd.concat([Btrain, one_row], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lu_8as_kFmB9",
        "outputId": "8979ea87-17a4-4850-e859-e0d9799190a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# Assuming Btrain is your DataFrame\n",
        "duplicate_rows = Btrain[Btrain.duplicated('cleanText', keep=False)]\n",
        "\n",
        "# Display the duplicate rows\n",
        "duplicate_rows.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "SaenHXlqGOLt"
      },
      "outputs": [],
      "source": [
        "# Assuming Btrain is your DataFrame\n",
        "Btrain.drop_duplicates(subset='cleanText', keep='first', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEa975J0Gchl",
        "outputId": "6e9f04c4-bedc-4efb-f9f4-9dc2256037ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    105\n",
              "1     61\n",
              "3     31\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "Btrain['label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1WjlCul53-f"
      },
      "source": [
        "# Data Set Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV4HGnR7YBpl",
        "outputId": "d5e3f8b0-dcf6-4eee-e7c2-786ac5d4d8f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Class Name :  2\n",
            "Number of tweets:105\n",
            "Number of Words:2166\n",
            "Number of Unique Words:1142\n",
            "Most Frequent Words:\n",
            "\n",
            "fridaysforfuture\t107\n",
            "climate\t31\n",
            "climatecrisis\t29\n",
            "government\t22\n",
            "stop\t17\n",
            "fuel\t16\n",
            "company\t14\n",
            "fossil\t13\n",
            "need\t12\n",
            "climatestrike\t11\n",
            "\n",
            "Class Name :  1\n",
            "Number of tweets:61\n",
            "Number of Words:1213\n",
            "Number of Unique Words:738\n",
            "Most Frequent Words:\n",
            "\n",
            "fridaysforfuture\t62\n",
            "climate\t18\n",
            "greta\t15\n",
            "climatecrisis\t13\n",
            "climatechange\t12\n",
            "lie\t11\n",
            "we\t11\n",
            "climateaction\t11\n",
            "gretathunberg\t11\n",
            "get\t7\n",
            "\n",
            "Class Name :  3\n",
            "Number of tweets:31\n",
            "Number of Words:588\n",
            "Number of Unique Words:407\n",
            "Most Frequent Words:\n",
            "\n",
            "fridaysforfuture\t31\n",
            "climate\t15\n",
            "climatecrisis\t11\n",
            "change\t8\n",
            "climatechange\t6\n",
            "people\t6\n",
            "earth\t6\n",
            "climateemergency\t6\n",
            "climateaction\t6\n",
            "global\t5\n",
            "Total Number of Unique Words:1824\n"
          ]
        }
      ],
      "source": [
        "Btrain_summary = Btrain.filter(['cleanText', 'label'])\n",
        "\n",
        "def data_summary(dataset):\n",
        "    tweets = []\n",
        "    words = []\n",
        "    u_words = []\n",
        "    total_u_words = [word.strip().lower() for t in list(dataset.cleanText) for word in t.strip().split()]\n",
        "    class_label = [k for k, v in dataset.label.value_counts().to_dict().items()]\n",
        "    # find word list\n",
        "    for label in class_label:\n",
        "        word_list = [word.strip().lower() for t in list(dataset[dataset.label == label].cleanText) for word in t.strip().split()]\n",
        "        counts = dict()\n",
        "        for word in word_list:\n",
        "            counts[word] = counts.get(word, 0) + 1\n",
        "        # sort the dictionary of word list\n",
        "        ordered = sorted(counts.items(), key=lambda item: item[1], reverse=True)\n",
        "        # Documents per class\n",
        "        tweets.append(len(list(dataset[dataset.label == label].cleanText)))\n",
        "        # Total Word per class\n",
        "        words.append(len(word_list))\n",
        "        # Unique words per class\n",
        "        u_words.append(len(np.unique(word_list)))\n",
        "\n",
        "        print(\"\\nClass Name : \", label)\n",
        "        print(\"Number of tweets:{}\".format(len(list(dataset[dataset.label == label].cleanText))))\n",
        "        print(\"Number of Words:{}\".format(len(word_list)))\n",
        "        print(\"Number of Unique Words:{}\".format(len(np.unique(word_list))))\n",
        "        print(\"Most Frequent Words:\\n\")\n",
        "        for k, v in ordered[:10]:\n",
        "            print(\"{}\\t{}\".format(k, v))\n",
        "    print(\"Total Number of Unique Words:{}\".format(len(np.unique(total_u_words))))\n",
        "\n",
        "    return tweets, words, u_words, class_label\n",
        "\n",
        "# Call the function for Btrain\n",
        "Btrain_comments, Btrain_words, Btrain_u_words, Btrain_class_names = data_summary(Btrain_summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVxlGUhp53-g",
        "outputId": "19aef1a2-f8d6-4d63-9ed6-d54a715cb8ec"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "Btrain_data_matrix = pd.DataFrame({\n",
        "    'Total Tweets': Btrain_comments,\n",
        "    'Total Words': Btrain_words,\n",
        "    'Unique Words': Btrain_u_words,\n",
        "    'Class Names': Btrain_class_names\n",
        "})\n",
        "\n",
        "Btrain_df = pd.melt(Btrain_data_matrix, id_vars=\"Class Names\", var_name=\"Category\", value_name=\"Values\")\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "ax = plt.subplot()\n",
        "\n",
        "sns.barplot(data=Btrain_df, x='Class Names', y='Values', hue='Category')\n",
        "ax.set_xlabel('Class Names')\n",
        "ax.set_title('Data Statistics - Btrain')\n",
        "\n",
        "ax.xaxis.set_ticklabels(Btrain_class_names, rotation=45);\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a9u3m2j53-h",
        "outputId": "3b86cad7-2949-470e-da5c-f1d3ca17f8a5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum Length of a Tweet: 806\n",
            "Minimum Length of a Tweet: 28\n",
            "Average Length of a Tweet: 169.0\n"
          ]
        }
      ],
      "source": [
        "Btrain['Tweet_length'] = Btrain.cleanText.apply(lambda x: len(x))\n",
        "frequency = dict()\n",
        "\n",
        "for i in Btrain.Tweet_length:\n",
        "    frequency[i] = frequency.get(i, 0) + 1\n",
        "\n",
        "plt.bar(frequency.keys(), frequency.values(), color=\"b\")\n",
        "plt.xlim(1, 300)  # Adjust the xlim based on your data distribution\n",
        "plt.xlabel('Length of the Tweet')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Tweet Length-Frequency Distribution - Btrain')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Maximum Length of a Tweet: {max(Btrain.Tweet_length)}\")\n",
        "print(f\"Minimum Length of a Tweet: {min(Btrain.Tweet_length)}\")\n",
        "print(f\"Average Length of a Tweet: {round(np.mean(Btrain.Tweet_length), 0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnYvqqdn53-i",
        "outputId": "16b223b7-66a2-4d33-f3c4-ab43a648545f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2    3\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Btrain.loc[Btrain['Tweet_length'] > 256]['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_ke4o9gYBpn",
        "outputId": "6bb75dd1-9884-4e75-9bef-2568302ef0a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Class Name :  1\n",
            "Number of tweets:120\n",
            "Number of Words:1595\n",
            "Number of Unique Words:261\n",
            "Most Frequent Words:\n",
            "\n",
            "fridaysforfuture\t120\n",
            "extinctionrebellion\t105\n",
            "climatechange\t103\n",
            "climateaction\t101\n",
            "climatecrisis\t101\n",
            "thunberg\t100\n",
            "climatestrike\t99\n",
            "fool\t99\n",
            "greta\t99\n",
            "renewable\t97\n",
            "\n",
            "Class Name :  2\n",
            "Number of tweets:23\n",
            "Number of Words:472\n",
            "Number of Unique Words:330\n",
            "Most Frequent Words:\n",
            "\n",
            "fridaysforfuture\t23\n",
            "climate\t14\n",
            "climatestrike\t6\n",
            "fuel\t5\n",
            "government\t5\n",
            "fossil\t4\n",
            "industry\t4\n",
            "climatecrisis\t4\n",
            "gretathunberg\t3\n",
            "climateaction\t3\n",
            "\n",
            "Class Name :  3\n",
            "Number of tweets:7\n",
            "Number of Words:181\n",
            "Number of Unique Words:154\n",
            "Most Frequent Words:\n",
            "\n",
            "fridaysforfuture\t7\n",
            "climate\t4\n",
            "scientist\t3\n",
            "fff\t3\n",
            "liar\t3\n",
            "say\t2\n",
            "make\t2\n",
            "Â°\t2\n",
            "c\t2\n",
            "change\t2\n",
            "Total Number of Unique Words:643\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def data_summary(dataset):\n",
        "    tweets = []\n",
        "    words = []\n",
        "    u_words = []\n",
        "    total_u_words = [word.strip().lower() for t in list(dataset.cleanText) for word in t.strip().split()]\n",
        "    class_label = [k for k, v in dataset.label.value_counts().to_dict().items()]\n",
        "    # find word list\n",
        "    for label in class_label:\n",
        "        word_list = [word.strip().lower() for t in list(dataset[dataset.label == label].cleanText) for word in t.strip().split()]\n",
        "        counts = dict()\n",
        "        for word in word_list:\n",
        "            counts[word] = counts.get(word, 0) + 1\n",
        "        # sort the dictionary of word list\n",
        "        ordered = sorted(counts.items(), key=lambda item: item[1], reverse=True)\n",
        "        # Documents per class\n",
        "        tweets.append(len(list(dataset[dataset.label == label].cleanText)))\n",
        "        # Total Word per class\n",
        "        words.append(len(word_list))\n",
        "        # Unique words per class\n",
        "        u_words.append(len(np.unique(word_list)))\n",
        "\n",
        "        print(\"\\nClass Name : \", label)\n",
        "        print(\"Number of tweets:{}\".format(len(list(dataset[dataset.label == label].cleanText))))\n",
        "        print(\"Number of Words:{}\".format(len(word_list)))\n",
        "        print(\"Number of Unique Words:{}\".format(len(np.unique(word_list))))\n",
        "        print(\"Most Frequent Words:\\n\")\n",
        "        for k, v in ordered[:10]:\n",
        "            print(\"{}\\t{}\".format(k, v))\n",
        "    print(\"Total Number of Unique Words:{}\".format(len(np.unique(total_u_words))))\n",
        "\n",
        "    return tweets, words, u_words, class_label\n",
        "\n",
        "# Call the function for Bval\n",
        "Bval_comments, Bval_words, Bval_u_words, Bval_class_names = data_summary(Bval)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVoR08rm53-i",
        "outputId": "61755190-7484-4bba-b8e2-9ca61005314f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum Length of a Tweet: 85\n",
            "Minimum Length of a Tweet: 4\n",
            "Average Length of a Tweet: 15.0\n"
          ]
        }
      ],
      "source": [
        "# Assuming 'cleanText' contains the text in Bval_tweet\n",
        "Bval['Tweet_length'] = Bval['cleanText'].apply(lambda x: len(x.split()))\n",
        "\n",
        "frequency = dict()\n",
        "\n",
        "for i in Bval['Tweet_length']:\n",
        "    frequency[i] = frequency.get(i, 0) + 1\n",
        "\n",
        "plt.bar(frequency.keys(), frequency.values(), color=\"b\")\n",
        "plt.xlim(1, 50)  # Adjust the xlim based on your data distribution\n",
        "plt.xlabel('Length of the Tweet')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Tweet Length-Frequency Distribution - Bval_tweet')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Maximum Length of a Tweet: {max(Bval['Tweet_length'])}\")\n",
        "print(f\"Minimum Length of a Tweet: {min(Bval['Tweet_length'])}\")\n",
        "print(f\"Average Length of a Tweet: {round(np.mean(Bval['Tweet_length']), 0)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_o3AmR1YBpp",
        "outputId": "ac3c76a7-7f1b-4278-c765-a9d0fa034408"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset Summary\n",
            "Total Number of Words:2203\n",
            "Number of Unique Words:607\n",
            "Most Frequent Words:\n",
            "\n",
            "fridaysforfuture\t151\n",
            "climatecrisis\t118\n",
            "climatechange\t112\n",
            "extinctionrebellion\t111\n",
            "climateaction\t111\n",
            "greta\t110\n",
            "climatestrike\t109\n",
            "renewable\t106\n",
            "fool\t106\n",
            "thunberg\t106\n",
            "Total Number of Unique Words:607\n"
          ]
        }
      ],
      "source": [
        "Btest_summary = Btest.filter(['cleanText'])\n",
        "\n",
        "def data_summary(dataset):\n",
        "    tweets = []\n",
        "    words = []\n",
        "    u_words = []\n",
        "    total_u_words = [word.strip().lower() for t in list(dataset.cleanText) for word in t.strip().split()]\n",
        "\n",
        "    # find word list\n",
        "    word_list = [word.strip().lower() for t in list(dataset.cleanText) for word in t.strip().split()]\n",
        "    counts = dict()\n",
        "    for word in word_list:\n",
        "        counts[word] = counts.get(word, 0) + 1\n",
        "\n",
        "    # sort the dictionary of the word list\n",
        "    ordered = sorted(counts.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "    # Total Word per dataset\n",
        "    words.append(len(word_list))\n",
        "    # Unique words per dataset\n",
        "    u_words.append(len(np.unique(word_list)))\n",
        "\n",
        "    print(\"\\nDataset Summary\")\n",
        "    print(\"Total Number of Words:{}\".format(len(word_list)))\n",
        "    print(\"Number of Unique Words:{}\".format(len(np.unique(word_list))))\n",
        "    print(\"Most Frequent Words:\\n\")\n",
        "    for k, v in ordered[:10]:\n",
        "        print(\"{}\\t{}\".format(k, v))\n",
        "    print(\"Total Number of Unique Words:{}\".format(len(np.unique(total_u_words))))\n",
        "\n",
        "    return words, u_words\n",
        "\n",
        "# Call the function for Btest\n",
        "Btest_words, Btest_u_words = data_summary(Btest_summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgOG5Qm8YBpq",
        "outputId": "19da2c86-546f-4658-c215-1ea1efe89d91"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum Length of a Tweet: 28\n",
            "Minimum Length of a Tweet: 5\n",
            "Average Length of a Tweet: 15.0\n"
          ]
        }
      ],
      "source": [
        "# Assuming 'cleanText' contains the text in Btest\n",
        "Btest['Tweet_length'] = Btest['cleanText'].apply(lambda x: len(x.split()))\n",
        "\n",
        "frequency = dict()\n",
        "\n",
        "for i in Btest['Tweet_length']:\n",
        "    frequency[i] = frequency.get(i, 0) + 1\n",
        "\n",
        "plt.bar(frequency.keys(), frequency.values(), color=\"b\")\n",
        "plt.xlabel('Length of the Tweet')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Tweet Length-Frequency Distribution - Btest')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Maximum Length of a Tweet: {max(Btest['Tweet_length'])}\")\n",
        "print(f\"Minimum Length of a Tweet: {min(Btest['Tweet_length'])}\")\n",
        "print(f\"Average Length of a Tweet: {round(np.mean(Btest['Tweet_length']), 0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgzH4ATOSOny"
      },
      "source": [
        "# Converting tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Qc1x_AWwYBpr"
      },
      "outputs": [],
      "source": [
        "X_train = Btrain['cleanText'].tolist()\n",
        "y_train = Btrain['label'].tolist()\n",
        "X_valid = Bval['cleanText'].tolist()\n",
        "y_valid = Bval['label'].tolist()\n",
        "X_test = Btest['cleanText'].tolist()\n",
        "y_test = Btest['label'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSLbrkpc9kyM",
        "outputId": "9d354465-a5a9-47a0-8601-f120ff0b9ff6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2]\n",
            "[0 1 2]\n"
          ]
        }
      ],
      "source": [
        "Bval['enc_label'] = Bval['label'] - 1\n",
        "Btrain['enc_label'] = Btrain['label'] - 1\n",
        "Btest['enc_label'] = Btest['label'] - 1\n",
        "print(Bval['enc_label'].unique())\n",
        "print(Btrain['enc_label'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "zR5sNlyNJQzC"
      },
      "outputs": [],
      "source": [
        "y_train = [label - 1 for label in y_train]\n",
        "y_valid = [label - 1 for label in y_valid]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "O3YewwXNJSj7"
      },
      "outputs": [],
      "source": [
        "y_test = [label - 1 for label in y_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rObRhk9XYBpv",
        "outputId": "260dfacf-97f4-4211-f970-c0b2dc49ce5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "Bval.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gufiQOxQA4w_"
      },
      "source": [
        "# Compute Class Weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHaIgUJkA8Hm",
        "outputId": "d5c5e45d-b144-431b-d46f-471078f14f3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 1.0765027322404372, 1: 0.6253968253968254, 2: 2.118279569892473}"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "# cls = np.unique(train_data['Label'])\n",
        "# print(cls)\n",
        "class_weights = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(Btrain['label']),\n",
        "                                        y = Btrain['label']\n",
        "                                    )\n",
        "\n",
        "weight = {i : class_weights[i] for i in range(3)}\n",
        "weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_6NB5_6wPbb"
      },
      "source": [
        "# ML Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yg7Egt94jAkm"
      },
      "source": [
        "## TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvuxJRCDYBp0"
      },
      "outputs": [],
      "source": [
        "#TF-IDF\n",
        "tfidf = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_val_tfidf = tfidf.transform(X_valid)\n",
        "X_test_tfidf = tfidf.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqTGmilMByk5"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HglVN5o3YBp1"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# # Define the parameter grid to search\n",
        "# param_grid_rf = {\n",
        "#     'n_estimators': [100, 500, 1000],\n",
        "#     'max_depth': [None, 10, 20, 30],\n",
        "#     'min_samples_split': [2, 5, 10],\n",
        "#     'min_samples_leaf': [1, 2, 4],\n",
        "#     'class_weight': ['balanced', None]\n",
        "# }\n",
        "\n",
        "# # Create a RandomForestClassifier\n",
        "# rf_classifier = RandomForestClassifier()\n",
        "\n",
        "# # Create the GridSearchCV object\n",
        "# grid_search_rf = GridSearchCV(estimator=rf_classifier, param_grid=param_grid_rf,\n",
        "#                                scoring='accuracy', cv=5, n_jobs=-1, verbose=2)\n",
        "\n",
        "# # Fit the grid search to the data\n",
        "# grid_search_rf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# # Print the best parameters and the corresponding accuracy\n",
        "# print(\"Best Parameters: \", grid_search_rf.best_params_)\n",
        "# print(\"Best Accuracy: \", grid_search_rf.best_score_)\n",
        "\n",
        "# # Get the best model\n",
        "# best_rf_model = grid_search_rf.best_estimator_\n",
        "\n",
        "# # Predict on the validation set\n",
        "# y_pred_val = best_rf_model.predict(X_val_tfidf)\n",
        "\n",
        "# # Evaluate the model\n",
        "# accuracy_val = accuracy_score(y_val, y_pred_val)\n",
        "# classification_report_val = classification_report(y_val, y_pred_val)\n",
        "\n",
        "# print(\"Validation Accuracy: \", accuracy_val)\n",
        "# print(\"Classification Report (Validation):\\n\", classification_report_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "bQxLoeHxBxm_",
        "outputId": "ba66f204-0c39-4d87-ae68-c95f10e605f7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_estimators=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_estimators=1000)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(class_weight='balanced', n_estimators=1000)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "# Example: Training individual models\n",
        "model_rf = RandomForestClassifier(class_weight='balanced', n_estimators=1000)  #use class_weight='balanced'\n",
        "model_rf.fit(X_train_tfidf, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbN1YirlRgCq"
      },
      "source": [
        "### RF Validation Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JH8o5DIQHsfg",
        "outputId": "a1dc5df2-36bd-43c8-efa7-4e2538dcb645"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.84\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.96      0.88      0.92       120\n",
            "           2       0.51      0.91      0.66        23\n",
            "           3       0.00      0.00      0.00         7\n",
            "\n",
            "    accuracy                           0.84       150\n",
            "   macro avg       0.49      0.60      0.52       150\n",
            "weighted avg       0.85      0.84      0.83       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = model_rf.predict(X_val_tfidf)\n",
        "\n",
        "accuracy = accuracy_score(y_valid, y_pred)\n",
        "report = classification_report(y_valid, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)             #estimator 1000--> 0.58      0.57      0.57"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3_EqEk5RmrM"
      },
      "source": [
        "### RF Test Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN-0UDWRRpck",
        "outputId": "850bbf74-35a6-4522-8313-6d13f57be686"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.88\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.99      0.91      0.95       121\n",
            "           2       0.58      0.96      0.72        23\n",
            "           3       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.88       150\n",
            "   macro avg       0.52      0.62      0.56       150\n",
            "weighted avg       0.89      0.88      0.88       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = model_rf.predict(X_test_tfidf)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)             #estimator 1000--> 0.58      0.57      0.57"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPOel-Y-2rFn"
      },
      "source": [
        "### LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "Ih8U_AOLzuYK",
        "outputId": "28d391d5-58a0-4607-bc45-44f84e1adae4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, class_weight=&#x27;balanced&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, class_weight=&#x27;balanced&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(C=1, class_weight='balanced', solver='liblinear')"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Logistic Regression\n",
        "model_lr = LogisticRegression(class_weight = 'balanced', solver='liblinear', C=1)\n",
        "model_lr.fit(X_train_tfidf, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1my7K6cR-HZ"
      },
      "source": [
        "### LR Valdiation Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0M7Q-w42z33",
        "outputId": "44183642-29db-4a3c-c867-e376fbf91a70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy: 0.8533333333333334\n",
            "Classification Report for Logistic Regression:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.97      0.88      0.93       120\n",
            "           2       0.54      0.91      0.68        23\n",
            "           3       0.50      0.14      0.22         7\n",
            "\n",
            "    accuracy                           0.85       150\n",
            "   macro avg       0.67      0.65      0.61       150\n",
            "weighted avg       0.88      0.85      0.85       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Predict on the test set\n",
        "y_pred_lr = model_lr.predict(X_val_tfidf)\n",
        "\n",
        "# Evaluation\n",
        "accuracy_lr = accuracy_score(y_valid, y_pred_lr)\n",
        "classification_report_lr = classification_report(y_valid, y_pred_lr)\n",
        "\n",
        "print(f'Logistic Regression Accuracy: {accuracy_lr}')\n",
        "print('Classification Report for Logistic Regression:\\n', classification_report_lr) # 0.63      0.63      0.63"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEV8YGetSFoh"
      },
      "source": [
        "### LR Test Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhAbjfS_SIhG",
        "outputId": "7848fade-025f-445a-f57c-e86d153fb8bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy: 0.9066666666666666\n",
            "Classification Report for Logistic Regression:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.93      0.97       121\n",
            "           2       0.65      0.96      0.77        23\n",
            "           3       0.33      0.17      0.22         6\n",
            "\n",
            "    accuracy                           0.91       150\n",
            "   macro avg       0.66      0.69      0.65       150\n",
            "weighted avg       0.92      0.91      0.91       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Predict on the test set\n",
        "y_pred_lr = model_lr.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluation\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "classification_report_lr = classification_report(y_test, y_pred_lr)\n",
        "\n",
        "print(f'Logistic Regression Accuracy: {accuracy_lr}')\n",
        "print('Classification Report for Logistic Regression:\\n', classification_report_lr) # 0.63      0.63      0.63"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqjUcnogFE6F"
      },
      "outputs": [],
      "source": [
        "y_pred = model_lr.predict(X_test_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlWD1rm5FJNt"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "# import zipfile\n",
        "\n",
        "# # Assuming Btest is your DataFrame with an \"index\" column and y_pred is your predicted labels\n",
        "# # Replace y_pred with your actual predicted labels\n",
        "\n",
        "# # Create a DataFrame with \"index\" and \"prediction\" columns\n",
        "# submission_df = pd.DataFrame({\"index\": Btest[\"index\"].tolist(), \"prediction\": y_pred})\n",
        "\n",
        "# # Sort the DataFrame based on the \"index\" column\n",
        "# submission_df = submission_df.sort_values(by=\"index\")\n",
        "\n",
        "# # Define the path to save the submission file\n",
        "# submission_file_path = \"/content/submission.json\"\n",
        "\n",
        "# # Save the DataFrame to a JSON file\n",
        "# submission_df.to_json(submission_file_path, orient=\"records\", lines=True)\n",
        "\n",
        "# # Zip the JSON file\n",
        "# with zipfile.ZipFile(\"submission.zip\", \"w\") as zipf:\n",
        "#     zipf.write(submission_file_path, arcname=\"submission.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXTm7Ib6kO69"
      },
      "source": [
        "### MNB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIkP44MYUKTB"
      },
      "source": [
        "### MNB Validation Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eccjfmSukMOH",
        "outputId": "6abd365b-2e2d-4e56-ca10-36063f96af72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multinomial Naive Bayes Accuracy: 0.8266666666666667\n",
            "Classification Report for Multinomial Naive Bayes:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.99      0.84      0.91       120\n",
            "           2       0.48      1.00      0.65        23\n",
            "           3       0.00      0.00      0.00         7\n",
            "\n",
            "    accuracy                           0.83       150\n",
            "   macro avg       0.49      0.61      0.52       150\n",
            "weighted avg       0.87      0.83      0.83       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Multinomial Naive Bayes\n",
        "model_nb = MultinomialNB(class_prior=None, fit_prior=True)\n",
        "model_nb.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_nb = model_nb.predict(X_val_tfidf)\n",
        "\n",
        "# Evaluation\n",
        "accuracy_nb = accuracy_score(y_valid, y_pred_nb)\n",
        "classification_report_nb = classification_report(y_valid, y_pred_nb)\n",
        "\n",
        "print(f'Multinomial Naive Bayes Accuracy: {accuracy_nb}')\n",
        "print('Classification Report for Multinomial Naive Bayes:\\n', classification_report_nb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sng0wRMFUT0G"
      },
      "source": [
        "### MNB Test Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NY97UCDUUV7M",
        "outputId": "76125f4b-2c85-4670-a354-ccce7dd23ce0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multinomial Naive Bayes Accuracy: 0.88\n",
            "Classification Report for Multinomial Naive Bayes:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.90      0.95       121\n",
            "           2       0.56      1.00      0.72        23\n",
            "           3       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.88       150\n",
            "   macro avg       0.52      0.63      0.56       150\n",
            "weighted avg       0.89      0.88      0.87       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Predict on the test set\n",
        "y_pred_nb = model_nb.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluation\n",
        "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "classification_report_nb = classification_report(y_test, y_pred_nb)\n",
        "\n",
        "print(f'Multinomial Naive Bayes Accuracy: {accuracy_nb}')\n",
        "print('Classification Report for Multinomial Naive Bayes:\\n', classification_report_nb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4B05o7r0dzf"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbCNO1YxUpBA"
      },
      "source": [
        "### SVM Validation Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QV368gkj0f9n",
        "outputId": "a9a9c1ac-0687-4a32-8367-49b43c469056"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Accuracy: 0.8866666666666667\n",
            "Classification Report for SVM:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.95      0.93      0.94       120\n",
            "           2       0.67      0.87      0.75        23\n",
            "           3       0.50      0.14      0.22         7\n",
            "\n",
            "    accuracy                           0.89       150\n",
            "   macro avg       0.71      0.65      0.64       150\n",
            "weighted avg       0.88      0.89      0.88       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Support Vector Machine (SVM)\n",
        "model_svm = SVC(C=1, class_weight='balanced', kernel='linear')\n",
        "model_svm.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model_svm.predict(X_val_tfidf)\n",
        "\n",
        "# Evaluation\n",
        "accuracy_svm = accuracy_score(y_valid, y_pred)\n",
        "classification_report_svm = classification_report(y_valid, y_pred)\n",
        "\n",
        "print(f'SVM Accuracy: {accuracy_svm}')\n",
        "print('Classification Report for SVM:\\n', classification_report_svm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KV8zTruUt8f"
      },
      "source": [
        "### SVM Test Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4Vc8KrUUvr8",
        "outputId": "8f007c9f-6833-459b-92d1-2d6b987f6734"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Accuracy: 0.8866666666666667\n",
            "Classification Report for SVM:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.96      0.94      0.95       121\n",
            "           2       0.64      0.78      0.71        23\n",
            "           3       0.33      0.17      0.22         6\n",
            "\n",
            "    accuracy                           0.89       150\n",
            "   macro avg       0.64      0.63      0.63       150\n",
            "weighted avg       0.88      0.89      0.88       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Predict on the test set\n",
        "y_pred = model_svm.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluation\n",
        "accuracy_svm = accuracy_score(y_test, y_pred)\n",
        "classification_report_svm = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'SVM Accuracy: {accuracy_svm}')\n",
        "print('Classification Report for SVM:\\n', classification_report_svm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ac5B-aWlYBp4"
      },
      "outputs": [],
      "source": [
        "y_pred = model_svm.predict(X_test_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgL8h9soYBp4"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "# import zipfile\n",
        "\n",
        "# # Assuming Btest is your DataFrame with an \"index\" column and y_pred is your predicted labels\n",
        "# # Replace y_pred with your actual predicted labels\n",
        "\n",
        "# # Create a DataFrame with \"index\" and \"prediction\" columns\n",
        "# submission_df = pd.DataFrame({\"index\": Btest[\"index\"].tolist(), \"prediction\": y_pred})\n",
        "\n",
        "# # Sort the DataFrame based on the \"index\" column\n",
        "# submission_df = submission_df.sort_values(by=\"index\")\n",
        "\n",
        "# # Define the path to save the submission file\n",
        "# submission_file_path = \"/content/submission.json\"\n",
        "\n",
        "# # Save the DataFrame to a JSON file\n",
        "# submission_df.to_json(submission_file_path, orient=\"records\", lines=True)\n",
        "\n",
        "# # Zip the JSON file\n",
        "# with zipfile.ZipFile(\"submission.zip\", \"w\") as zipf:\n",
        "#     zipf.write(submission_file_path, arcname=\"submission.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqAuQsJjMm25"
      },
      "source": [
        "### Ensemble Majority Voting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "jCyZUA9sLiR3",
        "outputId": "18e3b29e-9322-46e9-f80c-b055adc08a4e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(class_weight=&#x27;balanced&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(class_weight=&#x27;balanced&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "DecisionTreeClassifier(class_weight='balanced')"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "# Example: Training individual models\n",
        "model_rf = RandomForestClassifier(class_weight = 'balanced', n_estimators=500)  #use class_weight='balanced' if classes are imbalanced\n",
        "model_rf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "model_lr = LogisticRegression(C = 1, class_weight = 'balanced', solver = 'liblinear')\n",
        "model_lr.fit(X_train_tfidf, y_train)\n",
        "\n",
        "model_svm = SVC(kernel='linear', C = 1, class_weight = 'balanced')    #kernel='poly'  kernel='rbf'   kernel='sigmoid'\n",
        "model_svm.fit(X_train_tfidf, y_train)\n",
        "\n",
        "model_dt = DecisionTreeClassifier(class_weight = 'balanced')\n",
        "model_dt.fit(X_train_tfidf, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "KoE5Hu_fMy7W",
        "outputId": "04808639-0e67-48c8-a35a-c2e6e31c8419"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;RandomForest&#x27;,\n",
              "                              RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
              "                                                     n_estimators=500)),\n",
              "                             (&#x27;LogisticRegression&#x27;,\n",
              "                              LogisticRegression(C=1, class_weight=&#x27;balanced&#x27;,\n",
              "                                                 solver=&#x27;liblinear&#x27;)),\n",
              "                             (&#x27;SVM&#x27;,\n",
              "                              SVC(C=1, class_weight=&#x27;balanced&#x27;,\n",
              "                                  kernel=&#x27;linear&#x27;)),\n",
              "                             (&#x27;DecisionTree&#x27;,\n",
              "                              DecisionTreeClassifier(class_weight=&#x27;balanced&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;RandomForest&#x27;,\n",
              "                              RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
              "                                                     n_estimators=500)),\n",
              "                             (&#x27;LogisticRegression&#x27;,\n",
              "                              LogisticRegression(C=1, class_weight=&#x27;balanced&#x27;,\n",
              "                                                 solver=&#x27;liblinear&#x27;)),\n",
              "                             (&#x27;SVM&#x27;,\n",
              "                              SVC(C=1, class_weight=&#x27;balanced&#x27;,\n",
              "                                  kernel=&#x27;linear&#x27;)),\n",
              "                             (&#x27;DecisionTree&#x27;,\n",
              "                              DecisionTreeClassifier(class_weight=&#x27;balanced&#x27;))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>RandomForest</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_estimators=500)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>LogisticRegression</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, class_weight=&#x27;balanced&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>SVM</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, class_weight=&#x27;balanced&#x27;, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>DecisionTree</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(class_weight=&#x27;balanced&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "VotingClassifier(estimators=[('RandomForest',\n",
              "                              RandomForestClassifier(class_weight='balanced',\n",
              "                                                     n_estimators=500)),\n",
              "                             ('LogisticRegression',\n",
              "                              LogisticRegression(C=1, class_weight='balanced',\n",
              "                                                 solver='liblinear')),\n",
              "                             ('SVM',\n",
              "                              SVC(C=1, class_weight='balanced',\n",
              "                                  kernel='linear')),\n",
              "                             ('DecisionTree',\n",
              "                              DecisionTreeClassifier(class_weight='balanced'))])"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Create a list of tuples with model names and trained models\n",
        "models = [\n",
        "    ('RandomForest', model_rf),\n",
        "    ('LogisticRegression', model_lr),\n",
        "    ('SVM', model_svm),\n",
        "    ('DecisionTree', model_dt)\n",
        "]\n",
        "\n",
        "# Create an ensemble model using VotingClassifier\n",
        "ensemble_model = VotingClassifier(estimators=models, voting='hard') # 'hard' voting for majority class\n",
        "ensemble_model.fit(X_train_tfidf, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRzd_5-LVJ4a"
      },
      "source": [
        "### Ensemble Validation Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy2E2dM5M279",
        "outputId": "b5f6065a-d9fc-4c50-d60e-b64ff54ffaec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.86\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.95      0.91      0.93       120\n",
            "           2       0.58      0.83      0.68        23\n",
            "           3       0.50      0.14      0.22         7\n",
            "\n",
            "    accuracy                           0.86       150\n",
            "   macro avg       0.67      0.63      0.61       150\n",
            "weighted avg       0.87      0.86      0.86       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Predictions\n",
        "y_pred = ensemble_model.predict(X_val_tfidf)\n",
        "accuracy = accuracy_score(y_valid, y_pred)\n",
        "report = classification_report(y_valid, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpGAcolgVUcb"
      },
      "source": [
        "### Ensemble Test Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYXiEn3GVV-U",
        "outputId": "f08d747f-ffbb-4ad6-e499-16905b4df1bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8933333333333333\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.98      0.93      0.96       121\n",
            "           2       0.62      0.87      0.73        23\n",
            "           3       0.33      0.17      0.22         6\n",
            "\n",
            "    accuracy                           0.89       150\n",
            "   macro avg       0.65      0.66      0.64       150\n",
            "weighted avg       0.90      0.89      0.89       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Predictions\n",
        "y_pred = ensemble_model.predict(X_test_tfidf)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clm9Q9OpYBp6"
      },
      "outputs": [],
      "source": [
        "y_pred = ensemble_model.predict(X_test_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Q5CKrSxYBp6"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "# import zipfile\n",
        "\n",
        "# # Assuming Btest is your DataFrame with an \"index\" column and y_pred is your predicted labels\n",
        "# # Replace y_pred with your actual predicted labels\n",
        "\n",
        "# # Create a DataFrame with \"index\" and \"prediction\" columns\n",
        "# submission_df = pd.DataFrame({\"index\": Bval[\"index\"].tolist(), \"prediction\": y_pred})\n",
        "\n",
        "# # Sort the DataFrame based on the \"index\" column\n",
        "# submission_df = submission_df.sort_values(by=\"index\")\n",
        "\n",
        "# # Define the path to save the submission file\n",
        "# submission_file_path = \"/content/submissiondev.json\"\n",
        "\n",
        "# # Save the DataFrame to a JSON file\n",
        "# submission_df.to_json(submission_file_path, orient=\"records\", lines=True)\n",
        "\n",
        "# # Zip the JSON file\n",
        "# with zipfile.ZipFile(\"submissiondev.zip\", \"w\") as zipf:\n",
        "#     zipf.write(submission_file_path, arcname=\"submissiondev.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "houT7Qd0nF8o"
      },
      "source": [
        "## Word2Vec(spacy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vBaPEq-wOUz",
        "outputId": "9ba77ca9-cd01-47f5-9d7d-a70aa2ef437c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-01-09 04:11:08.621156: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-09 04:11:08.621208: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-09 04:11:08.622503: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-09 04:11:09.846270: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-md==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.6.0/en_core_web_md-3.6.0-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.1.3)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.6.0\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0U_1xQ2nKUF"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "# Tokenize and extract word vectors using spaCy\n",
        "def spacy_word_vectors(text):\n",
        "    doc = nlp(text)\n",
        "    return doc.vector\n",
        "\n",
        "# Apply spaCy word vectors extraction to the training set\n",
        "X_train_spacy = [spacy_word_vectors(text) for text in X_train]\n",
        "\n",
        "# Apply spaCy word vectors extraction to the validation set\n",
        "X_valid_spacy = [spacy_word_vectors(text) for text in X_valid]\n",
        "\n",
        "# Apply spaCy word vectors extraction to the test set\n",
        "X_test_spacy = [spacy_word_vectors(text) for text in X_test]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mFztUMKnNFS"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTNys-PRVe1s"
      },
      "source": [
        "### SVM Validation Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpQsJnvInQCZ",
        "outputId": "eb81a91e-7868-44d2-f294-2acd055d6cb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Accuracy on Validation Set: 0.88\n",
            "Classification Report for SVM on Validation Set:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1     0.9407    0.9250    0.9328       120\n",
            "           2     0.6923    0.7826    0.7347        23\n",
            "           3     0.5000    0.4286    0.4615         7\n",
            "\n",
            "    accuracy                         0.8800       150\n",
            "   macro avg     0.7110    0.7121    0.7097       150\n",
            "weighted avg     0.8820    0.8800    0.8804       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_svm = SVC(C=1, class_weight='balanced', kernel='linear')\n",
        "model_svm.fit(X_train_spacy, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_pred_valid = model_svm.predict(X_valid_spacy)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_test = model_svm.predict(X_test_spacy)\n",
        "\n",
        "# Evaluation on the validation set\n",
        "accuracy_svm_valid = accuracy_score(y_valid, y_pred_valid)\n",
        "classification_report_svm_valid = classification_report(y_valid, y_pred_valid, digits = 4)\n",
        "\n",
        "print(f'SVM Accuracy on Validation Set: {accuracy_svm_valid}')\n",
        "print('Classification Report for SVM on Validation Set:\\n', classification_report_svm_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tqd3LEPIViGj"
      },
      "source": [
        "### SVM Test Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BebUynlVkXD",
        "outputId": "ab611e24-890e-4e3a-d6e7-d27d0077db88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Accuracy on Validation Set: 0.8933333333333333\n",
            "Classification Report for SVM on Validation Set:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1     0.9580    0.9421    0.9500       121\n",
            "           2     0.7083    0.7391    0.7234        23\n",
            "           3     0.4286    0.5000    0.4615         6\n",
            "\n",
            "    accuracy                         0.8933       150\n",
            "   macro avg     0.6983    0.7271    0.7116       150\n",
            "weighted avg     0.8985    0.8933    0.8957       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluation on the validation set\n",
        "accuracy_svm_test = accuracy_score(y_test, y_pred_test)\n",
        "classification_report_svm_test = classification_report(y_test, y_pred_test, digits = 4)\n",
        "\n",
        "print(f'SVM Accuracy on Validation Set: {accuracy_svm_test}')\n",
        "print('Classification Report for SVM on Validation Set:\\n', classification_report_svm_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOvF-Cexn1Hr"
      },
      "source": [
        "### MNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-kA3W0gyHSL"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaled_train_embed = scaler.fit_transform(X_train_spacy)\n",
        "scaled_val_embed = scaler.transform(X_valid_spacy)\n",
        "scaled_test_embed = scaler.transform(X_test_spacy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MwBrUpSWTBC"
      },
      "source": [
        "### MNB Validation Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmRhRac3n3H6",
        "outputId": "ae056b52-66fd-4818-87dd-e02cd49fe587"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MNB Accuracy on Validation Set: 0.84\n",
            "Classification Report for MNB on Validation Set:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1     0.9381    0.8833    0.9099       120\n",
            "           2     0.5484    0.7391    0.6296        23\n",
            "           3     0.5000    0.4286    0.4615         7\n",
            "\n",
            "    accuracy                         0.8400       150\n",
            "   macro avg     0.6621    0.6837    0.6670       150\n",
            "weighted avg     0.8579    0.8400    0.8460       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Multinomial Naive Bayes (MNB)\n",
        "model_mnb = MultinomialNB()\n",
        "model_mnb.fit(scaled_train_embed, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_pred_valid_mnb = model_mnb.predict(scaled_val_embed)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_test_mnb = model_mnb.predict(scaled_test_embed)\n",
        "\n",
        "# Evaluation on the validation set\n",
        "accuracy_mnb_valid = accuracy_score(y_valid, y_pred_valid_mnb)\n",
        "classification_report_mnb_valid = classification_report(y_valid, y_pred_valid_mnb, digits = 4)\n",
        "\n",
        "print(f'MNB Accuracy on Validation Set: {accuracy_mnb_valid}')\n",
        "print('Classification Report for MNB on Validation Set:\\n', classification_report_mnb_valid)\n",
        "\n",
        "# You can use y_pred_test_mnb for predictions on the test set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSeDWDjJWZdJ"
      },
      "source": [
        "### MNB Test Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJivKCV_WaQc",
        "outputId": "147f83d5-70e6-4fe4-d403-dec409d52d6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MNB Accuracy on Validation Set: 0.8666666666666667\n",
            "Classification Report for MNB on Validation Set:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1     0.9569    0.9174    0.9367       121\n",
            "           2     0.5758    0.8261    0.6786        23\n",
            "           3     0.0000    0.0000    0.0000         6\n",
            "\n",
            "    accuracy                         0.8667       150\n",
            "   macro avg     0.5109    0.5811    0.5384       150\n",
            "weighted avg     0.8602    0.8667    0.8597       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "accuracy_mnb_test = accuracy_score(y_test, y_pred_test_mnb)\n",
        "classification_report_mnb_test = classification_report(y_test, y_pred_test_mnb, digits = 4)\n",
        "\n",
        "print(f'MNB Accuracy on Validation Set: {accuracy_mnb_test}')\n",
        "print('Classification Report for MNB on Validation Set:\\n', classification_report_mnb_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gFHzkk-n4SD"
      },
      "source": [
        "### LR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkC-r4m_aUt7"
      },
      "source": [
        "### LR Validation Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4E5t4zln6Jw",
        "outputId": "25f00f12-042d-49a0-e4c5-11da37e9bea6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LR Accuracy on Validation Set: 0.8733333333333333\n",
            "Classification Report for LR on Validation Set:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.94      0.92      0.93       120\n",
            "           2       0.67      0.78      0.72        23\n",
            "           3       0.50      0.43      0.46         7\n",
            "\n",
            "    accuracy                           0.87       150\n",
            "   macro avg       0.70      0.71      0.70       150\n",
            "weighted avg       0.88      0.87      0.87       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Logistic Regression (LR)\n",
        "model_lr = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
        "model_lr.fit(X_train_spacy, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_pred_valid_lr = model_lr.predict(X_valid_spacy)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_test_lr = model_lr.predict(X_test_spacy)\n",
        "\n",
        "# Evaluation on the validation set\n",
        "accuracy_lr_valid = accuracy_score(y_valid, y_pred_valid_lr)\n",
        "classification_report_lr_valid = classification_report(y_valid, y_pred_valid_lr)\n",
        "\n",
        "print(f'LR Accuracy on Validation Set: {accuracy_lr_valid}')\n",
        "print('Classification Report for LR on Validation Set:\\n', classification_report_lr_valid)\n",
        "\n",
        "# You can use y_pred_test_lr for predictions on the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTEaMFnIaX9R"
      },
      "source": [
        "### LR Test Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1r6SssKaZ1q",
        "outputId": "3c608259-656d-4e43-91ce-779a1416e8eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LR Accuracy on Validation Set: 0.8866666666666667\n",
            "Classification Report for LR on Validation Set:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.97      0.93      0.95       121\n",
            "           2       0.65      0.74      0.69        23\n",
            "           3       0.43      0.50      0.46         6\n",
            "\n",
            "    accuracy                           0.89       150\n",
            "   macro avg       0.68      0.72      0.70       150\n",
            "weighted avg       0.90      0.89      0.89       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "accuracy_lr_test = accuracy_score(y_test, y_pred_test_lr)\n",
        "classification_report_lr_test = classification_report(y_test, y_pred_test_lr)\n",
        "\n",
        "print(f'LR Accuracy on Validation Set: {accuracy_lr_test}')\n",
        "print('Classification Report for LR on Validation Set:\\n', classification_report_lr_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8nPMNfubdMJ"
      },
      "source": [
        "## RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1bTfek8bfHV",
        "outputId": "cd09ff85-7f1f-4202-b424-eb5046acf20b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8466666666666667\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.9636    0.8833    0.9217       120\n",
            "           2     0.5128    0.8696    0.6452        23\n",
            "           3     1.0000    0.1429    0.2500         7\n",
            "\n",
            "    accuracy                         0.8467       150\n",
            "   macro avg     0.8255    0.6319    0.6056       150\n",
            "weighted avg     0.8962    0.8467    0.8480       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "# Example: Training individual models\n",
        "model_rf = RandomForestClassifier(class_weight='balanced', n_estimators=1000)  #use class_weight='balanced'\n",
        "model_rf.fit(X_train_spacy, y_train)\n",
        "y_pred = model_rf.predict(X_valid_spacy)\n",
        "\n",
        "accuracy = accuracy_score(y_valid, y_pred)\n",
        "report = classification_report(y_valid, y_pred, digits = 4)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)             #estimator 1000--> 0.58      0.57      0.57"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XeNXXODb6gq"
      },
      "source": [
        "### RF Test Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZU-5o19Yb-EM",
        "outputId": "ed56e5c8-8784-4f23-d880-6b981a255571"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8666666666666667\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.9649    0.9091    0.9362       121\n",
            "           2     0.5556    0.8696    0.6780        23\n",
            "           3     0.0000    0.0000    0.0000         6\n",
            "\n",
            "    accuracy                         0.8667       150\n",
            "   macro avg     0.5068    0.5929    0.5380       150\n",
            "weighted avg     0.8635    0.8667    0.8591       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = model_rf.predict(X_test_spacy)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, digits = 4)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uGKlKfM53--"
      },
      "source": [
        "# Deep Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHo_4GOEf8Ln"
      },
      "source": [
        "## BiGRU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RABu7-nR53-_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import LSTM,GRU\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5DgERI953-_"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words = 116000,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n-',\n",
        "                      split=' ', char_level=False, oov_token='<oov>', document_count=0)     #tokenization\n",
        "tokenizer.fit_on_texts(Btrain['cleanText'])\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index)+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYTLerKd53_A",
        "outputId": "72fa5948-7fe5-433e-f00f-70343bd860a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1826\n"
          ]
        }
      ],
      "source": [
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCEQWPte53_A",
        "outputId": "661337f3-aa57-4051-9c2d-70dd62a93fc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1825\n",
            "Number of Training Sequences : (197, 256)\n",
            "Number of Validation Sequences : (150, 256)\n",
            "Number of test Sequences : (150, 256)\n"
          ]
        }
      ],
      "source": [
        "max_len = 256\n",
        "# Training Sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "print(len(tokenizer.word_index))\n",
        "train_pad_sequences =  pad_sequences(train_sequences, value=0.0, padding='post', maxlen= max_len)\n",
        "print(\"Number of Training Sequences :\" ,train_pad_sequences.shape)\n",
        "\n",
        "# Validation Sequences\n",
        "validation_sequences = tokenizer.texts_to_sequences(X_valid)\n",
        "validation_pad_sequences =  pad_sequences(validation_sequences, value=0.0, padding='post', maxlen= max_len)\n",
        "print(\"Number of Validation Sequences :\" ,validation_pad_sequences.shape)\n",
        "\n",
        "# Validation Sequences\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "test_pad_sequences =  pad_sequences(test_sequences, value=0.0, padding='post', maxlen= max_len)\n",
        "print(\"Number of test Sequences :\" ,test_pad_sequences.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us4yuQYCTMkF",
        "outputId": "d65eba57-054d-4a14-b0c9-e8f70a4f963d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 2 3]\n"
          ]
        }
      ],
      "source": [
        "print(Btrain['label'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlPrFfaIR7BC",
        "outputId": "4bded80f-9a8f-42d0-a04d-fc7e0dfb6c53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1 2]\n",
            "[0 1 2]\n"
          ]
        }
      ],
      "source": [
        "Bval['label'] = Bval['label'] - 1\n",
        "Btrain['label'] = Btrain['label'] - 1\n",
        "Btest['label'] = Btest['label'] - 1\n",
        "print(Bval['label'].unique())\n",
        "print(Btrain['label'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfhY9m1ocZoa",
        "outputId": "050fdbc3-c74e-479e-8994-24d372fde7e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1 2]\n"
          ]
        }
      ],
      "source": [
        "print(Btrain['label'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DP_aWEJZ53_B",
        "outputId": "c92c0315-c1d5-4e4b-adee-1c77dcdcf262"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 256, 300)          547800    \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 256, 256)          330240    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 65536)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 196611    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1074651 (4.10 MB)\n",
            "Trainable params: 1074651 (4.10 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "num_classes = 3            #### change class number\n",
        "\n",
        "accuracy_threshold = 0.99\n",
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy')>accuracy_threshold):\n",
        "        print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
        "        self.model.stop_training = True\n",
        "\n",
        "acc_callback = myCallback()\n",
        "# Saved the Best Model\n",
        "filepath = \"/content/drive/MyDrive/Colab Notebooks/case/\" + \"TaskB_BiGRU_tf.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "# callback list\n",
        "callback_list = [acc_callback, checkpoint]\n",
        "model = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Embedding(vocab_size, 300, input_length = max_len),\n",
        "#tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
        "#tf.keras.layers.MaxPooling1D(5),\n",
        "tf.keras.layers.Bidirectional(GRU(units = 128,return_sequences=True,dropout = 0.2)),\n",
        "tf.keras.layers.Flatten(),\n",
        "tf.keras.layers.Dense(3, activation='softmax')])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJ4Gh1ry53_C",
        "outputId": "a7233058-da9b-45e8-bf09-1f099747a133"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.2223 - accuracy: 0.3909\n",
            "Epoch 1: val_accuracy improved from -inf to 0.80000, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskB_BiGRU_tf.h5\n",
            "7/7 [==============================] - 19s 678ms/step - loss: 1.2223 - accuracy: 0.3909 - val_loss: 0.6512 - val_accuracy: 0.8000\n",
            "Epoch 2/15\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.1557 - accuracy: 0.4010\n",
            "Epoch 2: val_accuracy did not improve from 0.80000\n",
            "7/7 [==============================] - 4s 497ms/step - loss: 1.1557 - accuracy: 0.4010 - val_loss: 1.0764 - val_accuracy: 0.1533\n",
            "Epoch 3/15\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9064 - accuracy: 0.6650\n",
            "Epoch 3: val_accuracy did not improve from 0.80000\n",
            "7/7 [==============================] - 2s 297ms/step - loss: 0.9064 - accuracy: 0.6650 - val_loss: 1.2776 - val_accuracy: 0.1533\n",
            "Epoch 4/15\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8098 - accuracy: 0.7259\n",
            "Epoch 4: val_accuracy did not improve from 0.80000\n",
            "7/7 [==============================] - 2s 237ms/step - loss: 0.8098 - accuracy: 0.7259 - val_loss: 0.9462 - val_accuracy: 0.1800\n",
            "Epoch 5/15\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6015 - accuracy: 0.8020\n",
            "Epoch 5: val_accuracy improved from 0.80000 to 0.87333, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskB_BiGRU_tf.h5\n",
            "7/7 [==============================] - 2s 217ms/step - loss: 0.6015 - accuracy: 0.8020 - val_loss: 0.6939 - val_accuracy: 0.8733\n",
            "Epoch 6/15\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3607 - accuracy: 0.9594\n",
            "Epoch 6: val_accuracy did not improve from 0.87333\n",
            "7/7 [==============================] - 2s 240ms/step - loss: 0.3607 - accuracy: 0.9594 - val_loss: 0.6691 - val_accuracy: 0.8533\n",
            "Epoch 7/15\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1492 - accuracy: 0.9898\n",
            "Epoch 7: val_accuracy did not improve from 0.87333\n",
            "7/7 [==============================] - 1s 204ms/step - loss: 0.1492 - accuracy: 0.9898 - val_loss: 0.4828 - val_accuracy: 0.8733\n",
            "Epoch 8/15\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 1.0000\n",
            "Reached 99.00% accuracy so we will stop trianing\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.87333\n",
            "7/7 [==============================] - 1s 155ms/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 0.4242 - val_accuracy: 0.8667\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_pad_sequences,\n",
        "    Btrain['label'],\n",
        "    epochs=15,\n",
        "    batch_size=32,\n",
        "    validation_data=(validation_pad_sequences, Bval['label']),\n",
        "    verbose=1,\n",
        "    callbacks=callback_list,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6D0b30j53_C",
        "outputId": "639600cd-34e2-4a08-9a43-581ff84a5788"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 16ms/step\n",
            "F1-Score: 55.36411285825805\n",
            "Accuracy: 87.33333333333333\n"
          ]
        }
      ],
      "source": [
        "# Load the saved model\n",
        "model = load_model(filepath)\n",
        "# prediction\n",
        "y_pred = np.argmax(model.predict(validation_pad_sequences), axis=-1)\n",
        "\n",
        "print(\"F1-Score:\",f1_score(Bval['label'],y_pred,average='macro')*100)\n",
        "print(\"Accuracy:\",accuracy_score(Bval['label'],y_pred)*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FS9XRspcdW4"
      },
      "source": [
        "### Validation Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1YdXm3u51Db",
        "outputId": "2aeddb73-6471-4572-8ec7-6e6b6111aec2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.94      0.93       120\n",
            "           1       0.69      0.78      0.73        23\n",
            "           2       0.00      0.00      0.00         7\n",
            "\n",
            "    accuracy                           0.87       150\n",
            "   macro avg       0.53      0.57      0.55       150\n",
            "weighted avg       0.84      0.87      0.85       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#Show precision and recall per genre\n",
        "report = classification_report(Bval['label'], y_pred)\n",
        "\n",
        "#print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRk4C35lckRp"
      },
      "source": [
        "### Test Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VUkc2nxcjns",
        "outputId": "2e6fbde8-4849-4002-f4bb-0702adac573f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 18ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9280    0.9587    0.9431       121\n",
            "           1     0.6400    0.6957    0.6667        23\n",
            "           2     0.0000    0.0000    0.0000         6\n",
            "\n",
            "    accuracy                         0.8800       150\n",
            "   macro avg     0.5227    0.5514    0.5366       150\n",
            "weighted avg     0.8467    0.8800    0.8630       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(test_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Btest['label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncH8losetlp6"
      },
      "source": [
        "## Glove BiLSTM + CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_41IZjgtpmM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Load GloVe embeddings\n",
        "glove_file = '/content/drive/MyDrive/Colab Notebooks/case/glove.twitter.27B.100d.txt'  # Specify the path to your GloVe file\n",
        "word2vec_output_file = '/content/drive/MyDrive/Colab Notebooks/case/glove.twitter.27B.100d.word2vec'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "op56yLpfgyU6"
      },
      "outputs": [],
      "source": [
        "# glove2word2vec(glove_file, word2vec_output_file)\n",
        "glove_model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RujB7tcMYwbH"
      },
      "outputs": [],
      "source": [
        "# Create an embedding matrix\n",
        "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, 100))  # Assuming GloVe embeddings are 300-dimensional\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in glove_model:\n",
        "        embedding_matrix[i] = glove_model[word]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLJssmVBbCzE"
      },
      "outputs": [],
      "source": [
        "folderpath = \"/content/drive/MyDrive/Colab Notebooks/case/TaskB\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GU4DYiUOXLuq",
        "outputId": "490ac3fb-2f22-4df0-e59a-a01f0e402bd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 256, 100)          182600    \n",
            "                                                                 \n",
            " bidirectional_6 (Bidirecti  (None, 256, 128)          84480     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 254, 64)           24640     \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1  (None, 84, 64)            0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 5376)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               688256    \n",
            "                                                                 \n",
            " dropout_114 (Dropout)       (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 980363 (3.74 MB)\n",
            "Trainable params: 797763 (3.04 MB)\n",
            "Non-trainable params: 182600 (713.28 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "\n",
        "num_classes = 3            #### change class number\n",
        "\n",
        "accuracy_threshold = 0.99\n",
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy')>accuracy_threshold):\n",
        "        print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
        "        self.model.stop_training = True\n",
        "\n",
        "acc_callback = myCallback()\n",
        "# Saved the Best Model\n",
        "filepath = folderpath + \"glovebilstmcnn.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "# callback list\n",
        "callback_list = [acc_callback, checkpoint]\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(tokenizer.word_index) + 1, 100, input_length=max_len, weights=[embedding_matrix], trainable=False))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Conv1D(64, 3, activation='relu'))\n",
        "model.add(MaxPooling1D(3))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(3, activation='softmax'))  # Adjust for binary/multi-class classification\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvjPquoIY1yR"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDH9tzHvZ6i0",
        "outputId": "60f76641-068d-46c6-c276-c408fdb519bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.0374 - accuracy: 0.4873\n",
            "Epoch 1: val_accuracy improved from -inf to 0.15333, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBglovebilstmcnn.h5\n",
            "7/7 [==============================] - 9s 384ms/step - loss: 1.0374 - accuracy: 0.4873 - val_loss: 1.0858 - val_accuracy: 0.1533\n",
            "Epoch 2/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9561 - accuracy: 0.5482\n",
            "Epoch 2: val_accuracy improved from 0.15333 to 0.18000, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBglovebilstmcnn.h5\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.9561 - accuracy: 0.5482 - val_loss: 1.0200 - val_accuracy: 0.1800\n",
            "Epoch 3/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8558 - accuracy: 0.6193\n",
            "Epoch 3: val_accuracy improved from 0.18000 to 0.19333, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBglovebilstmcnn.h5\n",
            "7/7 [==============================] - 0s 53ms/step - loss: 0.8558 - accuracy: 0.6193 - val_loss: 0.9840 - val_accuracy: 0.1933\n",
            "Epoch 4/30\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.7931 - accuracy: 0.6510\n",
            "Epoch 4: val_accuracy did not improve from 0.19333\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.7862 - accuracy: 0.6599 - val_loss: 1.0929 - val_accuracy: 0.1933\n",
            "Epoch 5/30\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.6820 - accuracy: 0.7031\n",
            "Epoch 5: val_accuracy improved from 0.19333 to 0.85333, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBglovebilstmcnn.h5\n",
            "7/7 [==============================] - 0s 52ms/step - loss: 0.6954 - accuracy: 0.6954 - val_loss: 0.7687 - val_accuracy: 0.8533\n",
            "Epoch 6/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5869 - accuracy: 0.7462\n",
            "Epoch 6: val_accuracy improved from 0.85333 to 0.86000, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBglovebilstmcnn.h5\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.5869 - accuracy: 0.7462 - val_loss: 0.6363 - val_accuracy: 0.8600\n",
            "Epoch 7/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4995 - accuracy: 0.8376\n",
            "Epoch 7: val_accuracy improved from 0.86000 to 0.87333, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBglovebilstmcnn.h5\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.4995 - accuracy: 0.8376 - val_loss: 0.5066 - val_accuracy: 0.8733\n",
            "Epoch 8/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4113 - accuracy: 0.8731\n",
            "Epoch 8: val_accuracy did not improve from 0.87333\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.4113 - accuracy: 0.8731 - val_loss: 0.5537 - val_accuracy: 0.8600\n",
            "Epoch 9/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3258 - accuracy: 0.8832\n",
            "Epoch 9: val_accuracy did not improve from 0.87333\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.3258 - accuracy: 0.8832 - val_loss: 0.4489 - val_accuracy: 0.8600\n",
            "Epoch 10/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2749 - accuracy: 0.9239\n",
            "Epoch 10: val_accuracy did not improve from 0.87333\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.2749 - accuracy: 0.9239 - val_loss: 0.4570 - val_accuracy: 0.8733\n",
            "Epoch 11/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2114 - accuracy: 0.9340\n",
            "Epoch 11: val_accuracy did not improve from 0.87333\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.2114 - accuracy: 0.9340 - val_loss: 0.4207 - val_accuracy: 0.8733\n",
            "Epoch 12/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1640 - accuracy: 0.9492\n",
            "Epoch 12: val_accuracy did not improve from 0.87333\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1640 - accuracy: 0.9492 - val_loss: 0.4086 - val_accuracy: 0.8733\n",
            "Epoch 13/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1411 - accuracy: 0.9594\n",
            "Epoch 13: val_accuracy did not improve from 0.87333\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1411 - accuracy: 0.9594 - val_loss: 0.5802 - val_accuracy: 0.8533\n",
            "Epoch 14/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2302 - accuracy: 0.9340\n",
            "Epoch 14: val_accuracy did not improve from 0.87333\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.2302 - accuracy: 0.9340 - val_loss: 0.5132 - val_accuracy: 0.8400\n",
            "Epoch 15/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2429 - accuracy: 0.9137\n",
            "Epoch 15: val_accuracy did not improve from 0.87333\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.2429 - accuracy: 0.9137 - val_loss: 0.5355 - val_accuracy: 0.8267\n",
            "Epoch 16/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1795 - accuracy: 0.9239\n",
            "Epoch 16: val_accuracy improved from 0.87333 to 0.88667, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBglovebilstmcnn.h5\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 0.1795 - accuracy: 0.9239 - val_loss: 0.4384 - val_accuracy: 0.8867\n",
            "Epoch 17/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0664 - accuracy: 0.9797\n",
            "Epoch 17: val_accuracy did not improve from 0.88667\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0664 - accuracy: 0.9797 - val_loss: 0.4824 - val_accuracy: 0.8400\n",
            "Epoch 18/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 0.9898\n",
            "Epoch 18: val_accuracy did not improve from 0.88667\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0564 - accuracy: 0.9898 - val_loss: 0.5122 - val_accuracy: 0.8667\n",
            "Epoch 19/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 1.0000\n",
            "Reached 99.00% accuracy so we will stop trianing\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.88667\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.6013 - val_accuracy: 0.8467\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_pad_sequences,\n",
        "    Btrain['label'],\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_data=(validation_pad_sequences, Bval['label']),\n",
        "    verbose=1,\n",
        "    callbacks=callback_list\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1VvkireaB2a",
        "outputId": "1cd84292-7d27-46db-ea32-c9ffbcea9097"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 15ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9339    0.9417    0.9378       120\n",
            "           1     0.6800    0.7391    0.7083        23\n",
            "           2     0.7500    0.4286    0.5455         7\n",
            "\n",
            "    accuracy                         0.8867       150\n",
            "   macro avg     0.7880    0.7031    0.7305       150\n",
            "weighted avg     0.8864    0.8867    0.8843       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(validation_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Bval['label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37jyzZHjeQmj"
      },
      "source": [
        "### Test Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjKC3REkeSkk",
        "outputId": "abcad541-f176-421e-f7a5-4d0badfe167d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 15ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9194    0.9421    0.9306       121\n",
            "           1     0.7273    0.6957    0.7111        23\n",
            "           2     0.5000    0.3333    0.4000         6\n",
            "\n",
            "    accuracy                         0.8800       150\n",
            "   macro avg     0.7155    0.6570    0.6806       150\n",
            "weighted avg     0.8731    0.8800    0.8757       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(folderpath + \"glovebilstmcnn.h5\")\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(test_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Btest['label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cJx0XUia2ck"
      },
      "source": [
        "## Glove BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmelMhCVa5nM",
        "outputId": "dd6284af-6a01-4c11-b693-7ae9588a1cb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     (None, 256, 100)          182600    \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirecti  (None, 256, 128)          84480     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 32768)             0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               4194432   \n",
            "                                                                 \n",
            " dropout_115 (Dropout)       (None, 128)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4461899 (17.02 MB)\n",
            "Trainable params: 4279299 (16.32 MB)\n",
            "Non-trainable params: 182600 (713.28 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "num_classes = 2            #### change class number\n",
        "\n",
        "accuracy_threshold = 0.99\n",
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy')>accuracy_threshold):\n",
        "        print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
        "        self.model.stop_training = True\n",
        "\n",
        "acc_callback = myCallback()\n",
        "# Saved the Best Model\n",
        "filepath = folderpath + \"glovebilstm.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "# callback list\n",
        "callback_list = [acc_callback, checkpoint]\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(tokenizer.word_index) + 1, 100, input_length=max_len, weights=[embedding_matrix], trainable=False))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "# model.add(Conv1D(64, 3, activation='relu'))\n",
        "# model.add(MaxPooling1D(3))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(3, activation='softmax'))  # Adjust for binary/multi-class classification\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao_H5M4AbSBM",
        "outputId": "4f6864f0-c537-4186-c56f-530198cdb2aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.0596 - accuracy: 0.4721\n",
            "Epoch 1: val_accuracy improved from -inf to 0.86000, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBglovebilstm.h5\n",
            "7/7 [==============================] - 5s 219ms/step - loss: 1.0596 - accuracy: 0.4721 - val_loss: 0.8151 - val_accuracy: 0.8600\n",
            "Epoch 2/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8279 - accuracy: 0.6041\n",
            "Epoch 2: val_accuracy did not improve from 0.86000\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.8279 - accuracy: 0.6041 - val_loss: 0.9152 - val_accuracy: 0.2933\n",
            "Epoch 3/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6918 - accuracy: 0.6904\n",
            "Epoch 3: val_accuracy did not improve from 0.86000\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 0.6918 - accuracy: 0.6904 - val_loss: 0.7079 - val_accuracy: 0.8467\n",
            "Epoch 4/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5558 - accuracy: 0.7817\n",
            "Epoch 4: val_accuracy did not improve from 0.86000\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.5558 - accuracy: 0.7817 - val_loss: 0.8030 - val_accuracy: 0.8400\n",
            "Epoch 5/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4246 - accuracy: 0.8579\n",
            "Epoch 5: val_accuracy improved from 0.86000 to 0.86667, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBglovebilstm.h5\n",
            "7/7 [==============================] - 1s 186ms/step - loss: 0.4246 - accuracy: 0.8579 - val_loss: 0.4837 - val_accuracy: 0.8667\n",
            "Epoch 6/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2724 - accuracy: 0.9492\n",
            "Epoch 6: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 1s 84ms/step - loss: 0.2724 - accuracy: 0.9492 - val_loss: 0.5090 - val_accuracy: 0.8667\n",
            "Epoch 7/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1729 - accuracy: 0.9695\n",
            "Epoch 7: val_accuracy improved from 0.86667 to 0.87333, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBglovebilstm.h5\n",
            "7/7 [==============================] - 1s 174ms/step - loss: 0.1729 - accuracy: 0.9695 - val_loss: 0.4717 - val_accuracy: 0.8733\n",
            "Epoch 8/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1105 - accuracy: 0.9848\n",
            "Epoch 8: val_accuracy did not improve from 0.87333\n",
            "7/7 [==============================] - 1s 98ms/step - loss: 0.1105 - accuracy: 0.9848 - val_loss: 0.4419 - val_accuracy: 0.8667\n",
            "Epoch 9/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0650 - accuracy: 0.9848\n",
            "Epoch 9: val_accuracy did not improve from 0.87333\n",
            "7/7 [==============================] - 1s 87ms/step - loss: 0.0650 - accuracy: 0.9848 - val_loss: 0.4704 - val_accuracy: 0.8533\n",
            "Epoch 10/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 0.9949\n",
            "Reached 99.00% accuracy so we will stop trianing\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.87333\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0387 - accuracy: 0.9949 - val_loss: 0.5108 - val_accuracy: 0.8467\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_pad_sequences,\n",
        "    Btrain['label'],\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_data=(validation_pad_sequences, Bval['label']),\n",
        "    verbose=1,\n",
        "    callbacks=callback_list\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTszLtqkbfUJ",
        "outputId": "06e2e7fe-a51c-45b1-c518-123c72f8ff01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 3s 25ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9478    0.9083    0.9277       120\n",
            "           1     0.6000    0.7826    0.6792        23\n",
            "           2     0.8000    0.5714    0.6667         7\n",
            "\n",
            "    accuracy                         0.8733       150\n",
            "   macro avg     0.7826    0.7541    0.7579       150\n",
            "weighted avg     0.8876    0.8733    0.8774       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(validation_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Bval['label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zxOg_IMegxq"
      },
      "source": [
        "### Test Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsVhFdwBei5T",
        "outputId": "190a9adf-1344-4eb8-c94f-f1d26d658866"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 16ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9268    0.9421    0.9344       121\n",
            "           1     0.6667    0.6957    0.6809        23\n",
            "           2     0.3333    0.1667    0.2222         6\n",
            "\n",
            "    accuracy                         0.8733       150\n",
            "   macro avg     0.6423    0.6015    0.6125       150\n",
            "weighted avg     0.8632    0.8733    0.8671       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(folderpath + \"glovebilstm.h5\")\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(test_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Btest['label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDk-xZj7boaL"
      },
      "source": [
        "## Glove CNN + BiGRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImiuYic3bj0I",
        "outputId": "b233cd84-3e83-4a75-ac93-1e019b3bde11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 256)]             0         \n",
            "                                                                 \n",
            " embedding_8 (Embedding)     (None, 256, 100)          182600    \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 252, 128)          64128     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPoolin  (None, 50, 128)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " bidirectional_8 (Bidirecti  (None, 50, 128)           74496     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               819328    \n",
            "                                                                 \n",
            " dropout_116 (Dropout)       (None, 128)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_117 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1149003 (4.38 MB)\n",
            "Trainable params: 966403 (3.69 MB)\n",
            "Non-trainable params: 182600 (713.28 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "num_classes = 3            #### change class number\n",
        "\n",
        "accuracy_threshold = 0.99\n",
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy')>accuracy_threshold):\n",
        "        print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
        "        self.model.stop_training = True\n",
        "\n",
        "acc_callback = myCallback()\n",
        "# Saved the Best Model\n",
        "filepath = folderpath + \"TaskBglovebigrucnn.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "# callback list\n",
        "callback_list = [acc_callback, checkpoint]\n",
        "\n",
        "# Model Architecture\n",
        "input_layer = Input(shape=(max_len,), dtype=tf.int32)\n",
        "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_len, trainable=False)(input_layer)\n",
        "\n",
        "# Convolutional Neural Network (CNN)\n",
        "conv1 = Conv1D(128, 5, activation='relu')(embedding_layer)\n",
        "max_pooling = MaxPooling1D(5)(conv1)\n",
        "\n",
        "# Recurrent Neural Network (RNN)\n",
        "bi_gru = Bidirectional(GRU(units=64, return_sequences=True, dropout=0.2))(max_pooling)\n",
        "\n",
        "# Flatten and Dense Layers\n",
        "flatten = Flatten()(bi_gru)\n",
        "dense1 = Dense(128, activation='relu')(flatten)\n",
        "dropout1 = Dropout(0.2)(dense1)\n",
        "dense2 = Dense(64, activation='relu')(dropout1)\n",
        "dropout2 = Dropout(0.2)(dense2)\n",
        "\n",
        "# Output Layer\n",
        "output_layer = Dense(3, activation='softmax')(dropout2)\n",
        "\n",
        "# Model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4Drb8XCcCZC",
        "outputId": "39ce7b85-949c-4b0e-daf7-97cc222b12aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.0525 - accuracy: 0.4467\n",
            "Epoch 1: val_accuracy improved from -inf to 0.15333, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBTaskBglovebigrucnn.h5\n",
            "7/7 [==============================] - 10s 182ms/step - loss: 1.0525 - accuracy: 0.4467 - val_loss: 1.0850 - val_accuracy: 0.1533\n",
            "Epoch 2/30\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.9388 - accuracy: 0.5521\n",
            "Epoch 2: val_accuracy improved from 0.15333 to 0.21333, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBTaskBglovebigrucnn.h5\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.9353 - accuracy: 0.5533 - val_loss: 0.9891 - val_accuracy: 0.2133\n",
            "Epoch 3/30\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.8517 - accuracy: 0.6146\n",
            "Epoch 3: val_accuracy improved from 0.21333 to 0.45333, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBTaskBglovebigrucnn.h5\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.8551 - accuracy: 0.6142 - val_loss: 0.9456 - val_accuracy: 0.4533\n",
            "Epoch 4/30\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.7280 - accuracy: 0.7031\n",
            "Epoch 4: val_accuracy did not improve from 0.45333\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.7191 - accuracy: 0.7107 - val_loss: 1.0322 - val_accuracy: 0.2667\n",
            "Epoch 5/30\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.5951 - accuracy: 0.7604\n",
            "Epoch 5: val_accuracy improved from 0.45333 to 0.83333, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBTaskBglovebigrucnn.h5\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.6028 - accuracy: 0.7513 - val_loss: 0.5965 - val_accuracy: 0.8333\n",
            "Epoch 6/30\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.3884 - accuracy: 0.8750\n",
            "Epoch 6: val_accuracy improved from 0.83333 to 0.84000, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBTaskBglovebigrucnn.h5\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.3970 - accuracy: 0.8680 - val_loss: 0.4631 - val_accuracy: 0.8400\n",
            "Epoch 7/30\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.2071 - accuracy: 0.9479\n",
            "Epoch 7: val_accuracy improved from 0.84000 to 0.86000, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBTaskBglovebigrucnn.h5\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.2063 - accuracy: 0.9492 - val_loss: 0.4199 - val_accuracy: 0.8600\n",
            "Epoch 8/30\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.1567 - accuracy: 0.9375\n",
            "Epoch 8: val_accuracy did not improve from 0.86000\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.1663 - accuracy: 0.9340 - val_loss: 0.4364 - val_accuracy: 0.8533\n",
            "Epoch 9/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.1266 - accuracy: 0.9500\n",
            "Epoch 9: val_accuracy did not improve from 0.86000\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1150 - accuracy: 0.9594 - val_loss: 0.5092 - val_accuracy: 0.8533\n",
            "Epoch 10/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0709 - accuracy: 0.9875\n",
            "Epoch 10: val_accuracy did not improve from 0.86000\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.0639 - accuracy: 0.9898 - val_loss: 0.6069 - val_accuracy: 0.8467\n",
            "Epoch 11/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0360 - accuracy: 0.9937\n",
            "Reached 99.00% accuracy so we will stop trianing\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.86000 to 0.86667, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBTaskBglovebigrucnn.h5\n",
            "7/7 [==============================] - 0s 55ms/step - loss: 0.0377 - accuracy: 0.9949 - val_loss: 0.5245 - val_accuracy: 0.8667\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_pad_sequences,\n",
        "    Btrain['label'],\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_data=(validation_pad_sequences, Bval['label']),\n",
        "    verbose=1,\n",
        "    callbacks=callback_list\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5_ETeFecHg1",
        "outputId": "5eeabc2b-8617-41f9-8042-01caacdb3b8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 6ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9256    0.9333    0.9295       120\n",
            "           1     0.6154    0.6957    0.6531        23\n",
            "           2     0.6667    0.2857    0.4000         7\n",
            "\n",
            "    accuracy                         0.8667       150\n",
            "   macro avg     0.7359    0.6382    0.6608       150\n",
            "weighted avg     0.8660    0.8667    0.8624       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(validation_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Bval['label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaJYzRBbhywj"
      },
      "source": [
        "### Test Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOltffj5hn1k",
        "outputId": "d3a59af9-04ed-40d1-b188-ac5405e67cd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 2s 105ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9344    0.9421    0.9383       121\n",
            "           1     0.6800    0.7391    0.7083        23\n",
            "           2     0.3333    0.1667    0.2222         6\n",
            "\n",
            "    accuracy                         0.8800       150\n",
            "   macro avg     0.6493    0.6160    0.6229       150\n",
            "weighted avg     0.8714    0.8800    0.8744       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(folderpath + \"TaskBglovebigrucnn.h5\")\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(test_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Btest['label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUN0CEBNsJQL"
      },
      "source": [
        "## FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYB97qpEsM8K"
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlopen\n",
        "import gzip\n",
        "\n",
        "# get the vectors\n",
        "file = gzip.open(urlopen('https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ml.300.vec.gz'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OGntAMr53_E"
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlopen\n",
        "import gzip\n",
        "\n",
        "# get the vectors\n",
        "file = gzip.open(urlopen('https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ml.300.vec.gz'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtggwCbs53_F"
      },
      "outputs": [],
      "source": [
        "vocab_and_vectors = {}\n",
        "# put words as dict indexes and vectors as words values\n",
        "for line in file:\n",
        "  values = line.split()\n",
        "  word = values [0].decode('utf-8')\n",
        "  vector = np.asarray(values[1:], dtype='float32')\n",
        "  vocab_and_vectors[word] = vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJHx88tX53_G"
      },
      "outputs": [],
      "source": [
        "embedding_matrixx = np.zeros((vocab_size, 300))\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = vocab_and_vectors.get(word)\n",
        "  # words that cannot be found will be set to 0\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrixx[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OmJBY9m53_D"
      },
      "source": [
        "## FastText CNN + BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2EkiS6h53_H",
        "outputId": "f7373f41-f062-440f-9f7e-98fe7431afba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, 256, 300)          547800    \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 254, 128)          115328    \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPoolin  (None, 84, 128)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " bidirectional_9 (Bidirecti  (None, 84, 512)           788480    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 43008)             0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 3)                 129027    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1580635 (6.03 MB)\n",
            "Trainable params: 1032835 (3.94 MB)\n",
            "Non-trainable params: 547800 (2.09 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "num_classes = 3\n",
        "\n",
        "accuracy_threshold = 0.99\n",
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy')>accuracy_threshold):\n",
        "        print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
        "        self.model.stop_training = True\n",
        "\n",
        "acc_callback = myCallback()\n",
        "# Saved the Best Model\n",
        "filepath = folderpath +\"TaskBfasttext_CNNBiLSTMModel.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "# callback list\n",
        "callback_list = [acc_callback, checkpoint]\n",
        "model = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Embedding(vocab_size, 300, weights=[embedding_matrixx],trainable=False, input_length = max_len),\n",
        "tf.keras.layers.Conv1D(128, 3, activation='relu'),\n",
        "tf.keras.layers.MaxPooling1D(3),\n",
        "tf.keras.layers.Bidirectional(LSTM(units = 256,return_sequences=True,dropout = 0.2)),\n",
        "tf.keras.layers.Flatten(),\n",
        "tf.keras.layers.Dense(3, activation='softmax')])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e0JhE9053_I",
        "outputId": "4f1251ee-dfe1-468b-f04c-2e07bf32ba20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.0590 - accuracy: 0.4518\n",
            "Epoch 1: val_accuracy improved from -inf to 0.15333, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBTaskBfasttext_CNNBiLSTMModel.h5\n",
            "7/7 [==============================] - 7s 289ms/step - loss: 1.0590 - accuracy: 0.4518 - val_loss: 1.0628 - val_accuracy: 0.1533\n",
            "Epoch 2/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.9942 - accuracy: 0.5312\n",
            "Epoch 2: val_accuracy did not improve from 0.15333\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.9826 - accuracy: 0.5330 - val_loss: 1.0714 - val_accuracy: 0.1533\n",
            "Epoch 3/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.9658 - accuracy: 0.5188\n",
            "Epoch 3: val_accuracy improved from 0.15333 to 0.17333, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBTaskBfasttext_CNNBiLSTMModel.h5\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.9481 - accuracy: 0.5381 - val_loss: 1.0768 - val_accuracy: 0.1733\n",
            "Epoch 4/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.9164 - accuracy: 0.5625\n",
            "Epoch 4: val_accuracy improved from 0.17333 to 0.18000, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBTaskBfasttext_CNNBiLSTMModel.h5\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.8897 - accuracy: 0.5635 - val_loss: 1.1391 - val_accuracy: 0.1800\n",
            "Epoch 5/30\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.7916 - accuracy: 0.6667\n",
            "Epoch 5: val_accuracy did not improve from 0.18000\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.7978 - accuracy: 0.6650 - val_loss: 1.1532 - val_accuracy: 0.1800\n",
            "Epoch 6/30\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.6705 - accuracy: 0.7292\n",
            "Epoch 6: val_accuracy improved from 0.18000 to 0.86000, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBTaskBfasttext_CNNBiLSTMModel.h5\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.6693 - accuracy: 0.7259 - val_loss: 0.9333 - val_accuracy: 0.8600\n",
            "Epoch 7/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.5499 - accuracy: 0.8062\n",
            "Epoch 7: val_accuracy did not improve from 0.86000\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.5505 - accuracy: 0.8071 - val_loss: 1.0659 - val_accuracy: 0.8600\n",
            "Epoch 8/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.4111 - accuracy: 0.8750\n",
            "Epoch 8: val_accuracy did not improve from 0.86000\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.3888 - accuracy: 0.8680 - val_loss: 1.4480 - val_accuracy: 0.6933\n",
            "Epoch 9/30\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.2650 - accuracy: 0.9271\n",
            "Epoch 9: val_accuracy did not improve from 0.86000\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.2622 - accuracy: 0.9289 - val_loss: 1.1128 - val_accuracy: 0.8467\n",
            "Epoch 10/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.3609 - accuracy: 0.9125\n",
            "Epoch 10: val_accuracy did not improve from 0.86000\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.3819 - accuracy: 0.8934 - val_loss: 1.6780 - val_accuracy: 0.1800\n",
            "Epoch 11/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.2623 - accuracy: 0.8813\n",
            "Epoch 11: val_accuracy improved from 0.86000 to 0.86667, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBTaskBfasttext_CNNBiLSTMModel.h5\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.2958 - accuracy: 0.8528 - val_loss: 1.1443 - val_accuracy: 0.8667\n",
            "Epoch 12/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.3523 - accuracy: 0.8625\n",
            "Epoch 12: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.3508 - accuracy: 0.8731 - val_loss: 1.1123 - val_accuracy: 0.4467\n",
            "Epoch 13/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.2946 - accuracy: 0.9563\n",
            "Epoch 13: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.2907 - accuracy: 0.9442 - val_loss: 1.3159 - val_accuracy: 0.1867\n",
            "Epoch 14/30\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.2301 - accuracy: 0.9427\n",
            "Epoch 14: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.2273 - accuracy: 0.9442 - val_loss: 1.0522 - val_accuracy: 0.8400\n",
            "Epoch 15/30\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.1586 - accuracy: 0.9948\n",
            "Epoch 15: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.1615 - accuracy: 0.9898 - val_loss: 1.2147 - val_accuracy: 0.8400\n",
            "Epoch 16/30\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.1088 - accuracy: 0.9792\n",
            "Epoch 16: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.1087 - accuracy: 0.9797 - val_loss: 1.2397 - val_accuracy: 0.8467\n",
            "Epoch 17/30\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.0904 - accuracy: 0.9896\n",
            "Epoch 17: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.0899 - accuracy: 0.9898 - val_loss: 1.3256 - val_accuracy: 0.8400\n",
            "Epoch 18/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0541 - accuracy: 1.0000\n",
            "Reached 99.00% accuracy so we will stop trianing\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0523 - accuracy: 1.0000 - val_loss: 1.4925 - val_accuracy: 0.8400\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_pad_sequences,\n",
        "    Btrain['label'],\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_data=(validation_pad_sequences, Bval['label']),\n",
        "    verbose=1,\n",
        "    callbacks=callback_list\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inrHhLQf53_I",
        "outputId": "146ea65e-3175-4be7-e8cf-87e6951895f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 6ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9328    0.9250    0.9289       120\n",
            "           1     0.6538    0.7391    0.6939        23\n",
            "           2     0.4000    0.2857    0.3333         7\n",
            "\n",
            "    accuracy                         0.8667       150\n",
            "   macro avg     0.6622    0.6499    0.6520       150\n",
            "weighted avg     0.8651    0.8667    0.8650       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(validation_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Bval['label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0awXjycPh82M"
      },
      "source": [
        "### Test Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2G7-qV5iAB5",
        "outputId": "d9939996-f9b5-4c03-e7b7-f3816167ac16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 2s 35ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9339    0.9339    0.9339       121\n",
            "           1     0.6296    0.7391    0.6800        23\n",
            "           2     0.5000    0.1667    0.2500         6\n",
            "\n",
            "    accuracy                         0.8733       150\n",
            "   macro avg     0.6878    0.6132    0.6213       150\n",
            "weighted avg     0.8699    0.8733    0.8676       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(folderpath + \"TaskBfasttext_CNNBiLSTMModel.h5\")\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(test_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Btest['label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHVI7E_AeeZZ"
      },
      "source": [
        "## FastText CNN + BiGRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-TPQegjeg-z",
        "outputId": "0bbd8f70-b903-44e0-c414-c5391d8ed3c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 256)]             0         \n",
            "                                                                 \n",
            " embedding_10 (Embedding)    (None, 256, 300)          547800    \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 252, 128)          192128    \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPoolin  (None, 50, 128)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " bidirectional_10 (Bidirect  (None, 50, 128)           74496     \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 128)               819328    \n",
            "                                                                 \n",
            " dropout_118 (Dropout)       (None, 128)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_119 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1642203 (6.26 MB)\n",
            "Trainable params: 1094403 (4.17 MB)\n",
            "Non-trainable params: 547800 (2.09 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "num_classes = 3\n",
        "\n",
        "accuracy_threshold = 0.99\n",
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy')>accuracy_threshold):\n",
        "        print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
        "        self.model.stop_training = True\n",
        "\n",
        "acc_callback = myCallback()\n",
        "# Saved the Best Model\n",
        "filepath = folderpath +\"TaskBfasttext_CNNBiGRU.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "# callback list\n",
        "callback_list = [acc_callback, checkpoint]\n",
        "\n",
        "# Model Architecture\n",
        "input_layer = Input(shape=(max_len,), dtype=tf.int32)\n",
        "embedding_layer = Embedding(vocab_size, 300, weights=[embedding_matrixx], input_length=max_len, trainable=False)(input_layer)\n",
        "\n",
        "# Convolutional Neural Network (CNN)\n",
        "conv1 = Conv1D(128, 5, activation='relu')(embedding_layer)\n",
        "max_pooling = MaxPooling1D(5)(conv1)\n",
        "\n",
        "# Recurrent Neural Network (RNN)\n",
        "bi_gru = Bidirectional(GRU(units=64, return_sequences=True, dropout=0.2))(max_pooling)\n",
        "\n",
        "# Flatten and Dense Layers\n",
        "flatten = Flatten()(bi_gru)\n",
        "dense1 = Dense(128, activation='relu')(flatten)\n",
        "dropout1 = Dropout(0.2)(dense1)\n",
        "dense2 = Dense(64, activation='relu')(dropout1)\n",
        "dropout2 = Dropout(0.2)(dense2)\n",
        "\n",
        "# Output Layer\n",
        "output_layer = Dense(3, activation='softmax')(dropout2)\n",
        "\n",
        "# Model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZK0w9a3eoKO",
        "outputId": "6c601272-0968-41cb-83c0-a1f05e8183f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.0440 - accuracy: 0.4416\n",
            "Epoch 1: val_accuracy improved from -inf to 0.15333, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBTaskBfasttext_CNNBiGRU.h5\n",
            "7/7 [==============================] - 6s 191ms/step - loss: 1.0440 - accuracy: 0.4416 - val_loss: 1.1221 - val_accuracy: 0.1533\n",
            "Epoch 2/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.0086 - accuracy: 0.5533\n",
            "Epoch 2: val_accuracy improved from 0.15333 to 0.17333, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBTaskBfasttext_CNNBiGRU.h5\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 1.0086 - accuracy: 0.5533 - val_loss: 1.0121 - val_accuracy: 0.1733\n",
            "Epoch 3/30\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.9657 - accuracy: 0.5677\n",
            "Epoch 3: val_accuracy improved from 0.17333 to 0.18000, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBTaskBfasttext_CNNBiGRU.h5\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.9657 - accuracy: 0.5685 - val_loss: 1.0742 - val_accuracy: 0.1800\n",
            "Epoch 4/30\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.9298 - accuracy: 0.5521\n",
            "Epoch 4: val_accuracy did not improve from 0.18000\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.9288 - accuracy: 0.5533 - val_loss: 1.1106 - val_accuracy: 0.1733\n",
            "Epoch 5/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.8177 - accuracy: 0.6562\n",
            "Epoch 5: val_accuracy did not improve from 0.18000\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.8133 - accuracy: 0.6599 - val_loss: 1.1388 - val_accuracy: 0.1733\n",
            "Epoch 6/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.6739 - accuracy: 0.7063\n",
            "Epoch 6: val_accuracy did not improve from 0.18000\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.7039 - accuracy: 0.6802 - val_loss: 1.0759 - val_accuracy: 0.1800\n",
            "Epoch 7/30\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.5515 - accuracy: 0.7656\n",
            "Epoch 7: val_accuracy improved from 0.18000 to 0.20000, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBTaskBfasttext_CNNBiGRU.h5\n",
            "7/7 [==============================] - 0s 55ms/step - loss: 0.5449 - accuracy: 0.7665 - val_loss: 1.0563 - val_accuracy: 0.2000\n",
            "Epoch 8/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.3927 - accuracy: 0.8938\n",
            "Epoch 8: val_accuracy did not improve from 0.20000\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.3710 - accuracy: 0.9036 - val_loss: 1.3424 - val_accuracy: 0.2000\n",
            "Epoch 9/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.1630 - accuracy: 0.9688\n",
            "Epoch 9: val_accuracy improved from 0.20000 to 0.21333, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBTaskBfasttext_CNNBiGRU.h5\n",
            "7/7 [==============================] - 0s 54ms/step - loss: 0.1540 - accuracy: 0.9695 - val_loss: 1.4692 - val_accuracy: 0.2133\n",
            "Epoch 10/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0766 - accuracy: 0.9750\n",
            "Epoch 10: val_accuracy did not improve from 0.21333\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.1154 - accuracy: 0.9492 - val_loss: 1.9436 - val_accuracy: 0.2000\n",
            "Epoch 11/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0670 - accuracy: 0.9812\n",
            "Epoch 11: val_accuracy did not improve from 0.21333\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.0603 - accuracy: 0.9797 - val_loss: 2.4713 - val_accuracy: 0.1800\n",
            "Epoch 12/30\n",
            "4/7 [================>.............] - ETA: 0s - loss: 0.0740 - accuracy: 0.9688\n",
            "Epoch 12: val_accuracy improved from 0.21333 to 0.80667, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBTaskBfasttext_CNNBiGRU.h5\n",
            "7/7 [==============================] - 0s 59ms/step - loss: 0.0591 - accuracy: 0.9797 - val_loss: 1.3067 - val_accuracy: 0.8067\n",
            "Epoch 13/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9848\n",
            "Epoch 13: val_accuracy did not improve from 0.80667\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.0667 - accuracy: 0.9848 - val_loss: 1.9523 - val_accuracy: 0.1933\n",
            "Epoch 14/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.9848\n",
            "Epoch 14: val_accuracy improved from 0.80667 to 0.82667, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBTaskBfasttext_CNNBiGRU.h5\n",
            "7/7 [==============================] - 0s 67ms/step - loss: 0.0659 - accuracy: 0.9848 - val_loss: 1.0514 - val_accuracy: 0.8267\n",
            "Epoch 15/30\n",
            "4/7 [================>.............] - ETA: 0s - loss: 0.1927 - accuracy: 0.9844\n",
            "Epoch 15: val_accuracy did not improve from 0.82667\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.1324 - accuracy: 0.9898 - val_loss: 1.3463 - val_accuracy: 0.8000\n",
            "Epoch 16/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0185 - accuracy: 1.0000\n",
            "Reached 99.00% accuracy so we will stop trianing\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.82667\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.3532 - val_accuracy: 0.7933\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_pad_sequences,\n",
        "    Btrain['label'],\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_data=(validation_pad_sequences, Bval['label']),\n",
        "    verbose=1,\n",
        "    callbacks=callback_list\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLMXTOfxfGe7",
        "outputId": "5233c7c3-a79a-4fe8-c746-2f0c6f3b6264"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 6ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9091    0.9167    0.9129       120\n",
            "           1     0.6316    0.5217    0.5714        23\n",
            "           2     0.2000    0.2857    0.2353         7\n",
            "\n",
            "    accuracy                         0.8267       150\n",
            "   macro avg     0.5802    0.5747    0.5732       150\n",
            "weighted avg     0.8334    0.8267    0.8289       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(validation_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Bval['label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rmOWvvHiVnF"
      },
      "source": [
        "### Test Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2ylyJhjiXti",
        "outputId": "24e8beb0-1119-4b7f-ed34-c27ed25127f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 2s 75ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8898    0.9339    0.9113       121\n",
            "           1     0.5556    0.4348    0.4878        23\n",
            "           2     0.4000    0.3333    0.3636         6\n",
            "\n",
            "    accuracy                         0.8333       150\n",
            "   macro avg     0.6151    0.5673    0.5876       150\n",
            "weighted avg     0.8189    0.8333    0.8244       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(folderpath + \"TaskBfasttext_CNNBiGRU.h5\")\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(test_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Btest['label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44sOKMWPeCAa"
      },
      "source": [
        "## FastText BiGRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cZNQiGXeBl9",
        "outputId": "5843a927-d69f-4a0c-e733-3ec6b77364f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_11 (Embedding)    (None, 256, 300)          547800    \n",
            "                                                                 \n",
            " bidirectional_11 (Bidirect  (None, 256, 512)          857088    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 131072)            0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 3)                 393219    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1798107 (6.86 MB)\n",
            "Trainable params: 1250307 (4.77 MB)\n",
            "Non-trainable params: 547800 (2.09 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "num_classes = 3\n",
        "\n",
        "accuracy_threshold = 0.99\n",
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy')>accuracy_threshold):\n",
        "        print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
        "        self.model.stop_training = True\n",
        "\n",
        "acc_callback = myCallback()\n",
        "# Saved the Best Model\n",
        "filepath = folderpath +\"TaskBfasttext_BiGRUModel_FastText.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "# callback list\n",
        "callback_list = [acc_callback, checkpoint]\n",
        "model = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Embedding(vocab_size, 300, weights=[embedding_matrixx],trainable=False, input_length = max_len),\n",
        "# tf.keras.layers.Conv1D(128, 2, activation='relu'),\n",
        "# tf.keras.layers.MaxPooling1D(2),\n",
        "tf.keras.layers.Bidirectional(GRU(units = 256,return_sequences=True,dropout = 0.2)),\n",
        "tf.keras.layers.Flatten(),\n",
        "tf.keras.layers.Dense(3, activation='softmax')])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wk6S6EUseb2-",
        "outputId": "62ce5679-e1f3-4320-8885-e49c8c8c34ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 1.0287 - accuracy: 0.4635\n",
            "Epoch 1: val_accuracy improved from -inf to 0.82000, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBTaskBfasttext_BiGRUModel_FastText.h5\n",
            "7/7 [==============================] - 9s 194ms/step - loss: 1.0258 - accuracy: 0.4619 - val_loss: 0.9412 - val_accuracy: 0.8200\n",
            "Epoch 2/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9236 - accuracy: 0.5431\n",
            "Epoch 2: val_accuracy did not improve from 0.82000\n",
            "7/7 [==============================] - 0s 59ms/step - loss: 0.9236 - accuracy: 0.5431 - val_loss: 1.0101 - val_accuracy: 0.1800\n",
            "Epoch 3/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8297 - accuracy: 0.6142\n",
            "Epoch 3: val_accuracy did not improve from 0.82000\n",
            "7/7 [==============================] - 0s 57ms/step - loss: 0.8297 - accuracy: 0.6142 - val_loss: 0.9628 - val_accuracy: 0.8200\n",
            "Epoch 4/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7036 - accuracy: 0.7056\n",
            "Epoch 4: val_accuracy did not improve from 0.82000\n",
            "7/7 [==============================] - 0s 58ms/step - loss: 0.7036 - accuracy: 0.7056 - val_loss: 0.9847 - val_accuracy: 0.1800\n",
            "Epoch 5/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6265 - accuracy: 0.7259\n",
            "Epoch 5: val_accuracy did not improve from 0.82000\n",
            "7/7 [==============================] - 0s 59ms/step - loss: 0.6265 - accuracy: 0.7259 - val_loss: 1.0177 - val_accuracy: 0.1600\n",
            "Epoch 6/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5048 - accuracy: 0.8477\n",
            "Epoch 6: val_accuracy improved from 0.82000 to 0.82667, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBTaskBfasttext_BiGRUModel_FastText.h5\n",
            "7/7 [==============================] - 1s 80ms/step - loss: 0.5048 - accuracy: 0.8477 - val_loss: 0.8785 - val_accuracy: 0.8267\n",
            "Epoch 7/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4224 - accuracy: 0.8832\n",
            "Epoch 7: val_accuracy did not improve from 0.82667\n",
            "7/7 [==============================] - 0s 59ms/step - loss: 0.4224 - accuracy: 0.8832 - val_loss: 0.9753 - val_accuracy: 0.5800\n",
            "Epoch 8/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3397 - accuracy: 0.9036\n",
            "Epoch 8: val_accuracy did not improve from 0.82667\n",
            "7/7 [==============================] - 0s 58ms/step - loss: 0.3397 - accuracy: 0.9036 - val_loss: 1.0856 - val_accuracy: 0.1600\n",
            "Epoch 9/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3143 - accuracy: 0.9086\n",
            "Epoch 9: val_accuracy did not improve from 0.82667\n",
            "7/7 [==============================] - 0s 59ms/step - loss: 0.3143 - accuracy: 0.9086 - val_loss: 1.0551 - val_accuracy: 0.4333\n",
            "Epoch 10/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.3170 - accuracy: 0.8832\n",
            "Epoch 10: val_accuracy improved from 0.82667 to 0.84667, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBTaskBfasttext_BiGRUModel_FastText.h5\n",
            "7/7 [==============================] - 0s 61ms/step - loss: 0.3170 - accuracy: 0.8832 - val_loss: 0.7326 - val_accuracy: 0.8467\n",
            "Epoch 11/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2587 - accuracy: 0.9188\n",
            "Epoch 11: val_accuracy did not improve from 0.84667\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.2587 - accuracy: 0.9188 - val_loss: 1.0883 - val_accuracy: 0.2200\n",
            "Epoch 12/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2068 - accuracy: 0.9442\n",
            "Epoch 12: val_accuracy did not improve from 0.84667\n",
            "7/7 [==============================] - 0s 62ms/step - loss: 0.2068 - accuracy: 0.9442 - val_loss: 0.9743 - val_accuracy: 0.6800\n",
            "Epoch 13/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.1260 - accuracy: 0.9937\n",
            "Epoch 13: val_accuracy did not improve from 0.84667\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.1447 - accuracy: 0.9848 - val_loss: 1.2924 - val_accuracy: 0.1667\n",
            "Epoch 14/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1463 - accuracy: 0.9543\n",
            "Epoch 14: val_accuracy did not improve from 0.84667\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.1463 - accuracy: 0.9543 - val_loss: 1.1367 - val_accuracy: 0.1733\n",
            "Epoch 15/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.1163 - accuracy: 0.9750\n",
            "Epoch 15: val_accuracy did not improve from 0.84667\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.1100 - accuracy: 0.9746 - val_loss: 1.3346 - val_accuracy: 0.1667\n",
            "Epoch 16/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0904 - accuracy: 0.9750\n",
            "Epoch 16: val_accuracy did not improve from 0.84667\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.0885 - accuracy: 0.9797 - val_loss: 0.8309 - val_accuracy: 0.8333\n",
            "Epoch 17/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0891 - accuracy: 0.9750\n",
            "Epoch 17: val_accuracy did not improve from 0.84667\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.0976 - accuracy: 0.9695 - val_loss: 1.5030 - val_accuracy: 0.1467\n",
            "Epoch 18/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0808 - accuracy: 0.9812\n",
            "Epoch 18: val_accuracy improved from 0.84667 to 0.86000, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBTaskBfasttext_BiGRUModel_FastText.h5\n",
            "7/7 [==============================] - 0s 56ms/step - loss: 0.0829 - accuracy: 0.9797 - val_loss: 0.8747 - val_accuracy: 0.8600\n",
            "Epoch 19/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0729 - accuracy: 0.9688\n",
            "Epoch 19: val_accuracy did not improve from 0.86000\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.0729 - accuracy: 0.9695 - val_loss: 1.2859 - val_accuracy: 0.1733\n",
            "Epoch 20/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0552 - accuracy: 0.9812\n",
            "Epoch 20: val_accuracy did not improve from 0.86000\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.0659 - accuracy: 0.9797 - val_loss: 1.1442 - val_accuracy: 0.6267\n",
            "Epoch 21/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0490 - accuracy: 0.9898\n",
            "Epoch 21: val_accuracy did not improve from 0.86000\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 0.0490 - accuracy: 0.9898 - val_loss: 1.0992 - val_accuracy: 0.5000\n",
            "Epoch 22/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0456 - accuracy: 0.9875\n",
            "Epoch 22: val_accuracy did not improve from 0.86000\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.0453 - accuracy: 0.9898 - val_loss: 1.2635 - val_accuracy: 0.1733\n",
            "Epoch 23/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.0261 - accuracy: 0.9937\n",
            "Reached 99.00% accuracy so we will stop trianing\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.86000\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.0247 - accuracy: 0.9949 - val_loss: 1.3568 - val_accuracy: 0.1667\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_pad_sequences,\n",
        "    Btrain['label'],\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_data=(validation_pad_sequences, Bval['label']),\n",
        "    verbose=1,\n",
        "    callbacks=callback_list\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yg4joNJerJa",
        "outputId": "c6b2c949-41cc-42f0-8863-ccb083520ba8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 24ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8976    0.9500    0.9231       120\n",
            "           1     0.6667    0.6087    0.6364        23\n",
            "           2     0.5000    0.1429    0.2222         7\n",
            "\n",
            "    accuracy                         0.8600       150\n",
            "   macro avg     0.6881    0.5672    0.5939       150\n",
            "weighted avg     0.8437    0.8600    0.8464       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(validation_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Bval['label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgXKhvtSii4x"
      },
      "source": [
        "### Test Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6pVefp0ikxT",
        "outputId": "6ea5411f-d0f7-4a65-e7a3-9080bcd25e74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 2s 23ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9055    0.9504    0.9274       121\n",
            "           1     0.6316    0.5217    0.5714        23\n",
            "           2     0.2500    0.1667    0.2000         6\n",
            "\n",
            "    accuracy                         0.8533       150\n",
            "   macro avg     0.5957    0.5463    0.5663       150\n",
            "weighted avg     0.8373    0.8533    0.8437       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(folderpath + \"TaskBfasttext_BiGRUModel_FastText.h5\")\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(test_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Btest['label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FlxOcTRfw3B"
      },
      "source": [
        "## FastText BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFiTKTW4f1t7",
        "outputId": "2ab69ba2-ae5c-46ce-c75a-33b88756acfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_13 (Embedding)    (None, 256, 300)          547800    \n",
            "                                                                 \n",
            " bidirectional_12 (Bidirect  (None, 256, 128)          186880    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 32768)             0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 128)               4194432   \n",
            "                                                                 \n",
            " dropout_120 (Dropout)       (None, 128)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4929499 (18.80 MB)\n",
            "Trainable params: 4381699 (16.71 MB)\n",
            "Non-trainable params: 547800 (2.09 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "num_classes = 3            #### change class number\n",
        "\n",
        "accuracy_threshold = 0.99\n",
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy')>accuracy_threshold):\n",
        "        print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
        "        self.model.stop_training = True\n",
        "\n",
        "acc_callback = myCallback()\n",
        "# Saved the Best Model\n",
        "filepath = folderpath + \"FastTextglovebilstm.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "# callback list\n",
        "callback_list = [acc_callback, checkpoint]\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 300, weights=[embedding_matrixx],trainable=False, input_length = max_len))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "# model.add(Conv1D(64, 3, activation='relu'))\n",
        "# model.add(MaxPooling1D(3))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(3, activation='softmax'))  # Adjust for binary/multi-class classification\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "comOqeMZgVN6",
        "outputId": "77ba7dd5-a074-4adc-af6a-ae9f522dac26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 1.0213 - accuracy: 0.4938\n",
            "Epoch 1: val_accuracy improved from -inf to 0.15333, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBFastTextglovebilstm.h5\n",
            "7/7 [==============================] - 10s 229ms/step - loss: 1.0358 - accuracy: 0.4873 - val_loss: 1.0521 - val_accuracy: 0.1533\n",
            "Epoch 2/30\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.9627 - accuracy: 0.5437\n",
            "Epoch 2: val_accuracy improved from 0.15333 to 0.18000, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBFastTextglovebilstm.h5\n",
            "7/7 [==============================] - 1s 82ms/step - loss: 0.9508 - accuracy: 0.5482 - val_loss: 1.0275 - val_accuracy: 0.1800\n",
            "Epoch 3/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8646 - accuracy: 0.5736\n",
            "Epoch 3: val_accuracy did not improve from 0.18000\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.8646 - accuracy: 0.5736 - val_loss: 1.0278 - val_accuracy: 0.1733\n",
            "Epoch 4/30\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.7916 - accuracy: 0.6250\n",
            "Epoch 4: val_accuracy did not improve from 0.18000\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.7919 - accuracy: 0.6294 - val_loss: 1.0686 - val_accuracy: 0.1733\n",
            "Epoch 5/30\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.6391 - accuracy: 0.7240\n",
            "Epoch 5: val_accuracy did not improve from 0.18000\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6426 - accuracy: 0.7259 - val_loss: 1.1063 - val_accuracy: 0.1667\n",
            "Epoch 6/30\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.4829 - accuracy: 0.8177\n",
            "Epoch 6: val_accuracy did not improve from 0.18000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.4964 - accuracy: 0.8122 - val_loss: 1.0667 - val_accuracy: 0.1800\n",
            "Epoch 7/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4481 - accuracy: 0.8122\n",
            "Epoch 7: val_accuracy improved from 0.18000 to 0.82667, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBFastTextglovebilstm.h5\n",
            "7/7 [==============================] - 1s 87ms/step - loss: 0.4481 - accuracy: 0.8122 - val_loss: 0.5762 - val_accuracy: 0.8267\n",
            "Epoch 8/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.4204 - accuracy: 0.8274\n",
            "Epoch 8: val_accuracy improved from 0.82667 to 0.84000, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBFastTextglovebilstm.h5\n",
            "7/7 [==============================] - 1s 95ms/step - loss: 0.4204 - accuracy: 0.8274 - val_loss: 0.7271 - val_accuracy: 0.8400\n",
            "Epoch 9/30\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.3153 - accuracy: 0.9115\n",
            "Epoch 9: val_accuracy did not improve from 0.84000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.3151 - accuracy: 0.9086 - val_loss: 1.2407 - val_accuracy: 0.1600\n",
            "Epoch 10/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2317 - accuracy: 0.9289\n",
            "Epoch 10: val_accuracy did not improve from 0.84000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.2317 - accuracy: 0.9289 - val_loss: 0.9530 - val_accuracy: 0.8333\n",
            "Epoch 11/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2005 - accuracy: 0.9442\n",
            "Epoch 11: val_accuracy did not improve from 0.84000\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.2005 - accuracy: 0.9442 - val_loss: 1.0201 - val_accuracy: 0.8333\n",
            "Epoch 12/30\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.1358 - accuracy: 0.9427\n",
            "Epoch 12: val_accuracy did not improve from 0.84000\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.1447 - accuracy: 0.9340 - val_loss: 1.1741 - val_accuracy: 0.4467\n",
            "Epoch 13/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1249 - accuracy: 0.9645\n",
            "Epoch 13: val_accuracy did not improve from 0.84000\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1249 - accuracy: 0.9645 - val_loss: 1.8925 - val_accuracy: 0.1600\n",
            "Epoch 14/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1112 - accuracy: 0.9746\n",
            "Epoch 14: val_accuracy did not improve from 0.84000\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.1112 - accuracy: 0.9746 - val_loss: 1.2526 - val_accuracy: 0.4600\n",
            "Epoch 15/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0804 - accuracy: 0.9797\n",
            "Epoch 15: val_accuracy did not improve from 0.84000\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0804 - accuracy: 0.9797 - val_loss: 1.7623 - val_accuracy: 0.1667\n",
            "Epoch 16/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1018 - accuracy: 0.9695\n",
            "Epoch 16: val_accuracy did not improve from 0.84000\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.1018 - accuracy: 0.9695 - val_loss: 1.1143 - val_accuracy: 0.8333\n",
            "Epoch 17/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.1211 - accuracy: 0.9492\n",
            "Epoch 17: val_accuracy did not improve from 0.84000\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1211 - accuracy: 0.9492 - val_loss: 1.7997 - val_accuracy: 0.1733\n",
            "Epoch 18/30\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9949\n",
            "Reached 99.00% accuracy so we will stop trianing\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.84000\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0445 - accuracy: 0.9949 - val_loss: 1.2881 - val_accuracy: 0.5800\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_pad_sequences,\n",
        "    Btrain['label'],\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_data=(validation_pad_sequences, Bval['label']),\n",
        "    verbose=1,\n",
        "    callbacks=callback_list\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpMOemg1ggDf",
        "outputId": "23095747-34a5-42c6-8b27-3eef356f1c87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 15ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9098    0.9250    0.9174       120\n",
            "           1     0.5652    0.5652    0.5652        23\n",
            "           2     0.4000    0.2857    0.3333         7\n",
            "\n",
            "    accuracy                         0.8400       150\n",
            "   macro avg     0.6250    0.5920    0.6053       150\n",
            "weighted avg     0.8332    0.8400    0.8361       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(validation_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Bval['label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfxPEtEUi0Gh"
      },
      "source": [
        "### Test Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GySwGuYlizfy",
        "outputId": "ae9504b1-6e20-4a3a-f7a7-c3e38a6a1c12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 18ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8779    0.9504    0.9127       121\n",
            "           1     0.5385    0.3043    0.3889        23\n",
            "           2     0.3333    0.3333    0.3333         6\n",
            "\n",
            "    accuracy                         0.8267       150\n",
            "   macro avg     0.5832    0.5294    0.5450       150\n",
            "weighted avg     0.8040    0.8267    0.8092       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(folderpath + \"FastTextglovebilstm.h5\")\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(test_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Btest['label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9-2bOoIg-ER"
      },
      "source": [
        "## Fusion Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xma4L25wi8jX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import re,nltk,json\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from tensorflow.keras.layers import LSTM,GRU\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_auc_score\n",
        "from sklearn.metrics import average_precision_score,roc_auc_score, roc_curve, precision_recall_curve\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Input, Dense, Activation, Dropout,Flatten,Embedding\n",
        "from keras.layers import Conv1D,MaxPooling1D,GlobalAveragePooling1D, Bidirectional, LSTM, GRU\n",
        "from keras.models import Model\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mc80_pNdhBH5",
        "outputId": "5a88f2c6-eab6-4825-94ee-da6bdccb90c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1824\n"
          ]
        }
      ],
      "source": [
        "max_words = 50000\n",
        "tokenizer = Tokenizer(num_words = max_words, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n-',\n",
        "                      split=' ', char_level=False, oov_token='<oov>', document_count=0)\n",
        "tokenizer.fit_on_texts(Btrain['cleanText'])\n",
        "\n",
        "word_counts = tokenizer.word_counts\n",
        "word_docs = tokenizer.word_docs\n",
        "word_index = tokenizer.word_index\n",
        "document_count = tokenizer.document_count\n",
        "\n",
        "print(len(word_counts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uj7iIvchogY"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(folderpath+'tokenizer_7th.pickle','wb') as f:\n",
        "    pickle.dump(tokenizer,f,protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjZ-QXhPhsUU"
      },
      "outputs": [],
      "source": [
        "sequences = tokenizer.texts_to_sequences(X_train)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "max_len = 256\n",
        "corpus = pad_sequences(sequences, value=0, padding='post', maxlen= max_len)\n",
        "\n",
        "validation_sequences = tokenizer.texts_to_sequences(X_valid)\n",
        "validation_pad_sequences =  pad_sequences(validation_sequences, value=0.0, padding='post', maxlen= max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Qf4waebhtgc"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, Dense, Activation, Dropout,Flatten,Embedding\n",
        "from keras.layers import Conv1D,MaxPooling1D,GlobalAveragePooling1D, Bidirectional, LSTM, GRU\n",
        "from keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxJpJUjzhy3M"
      },
      "outputs": [],
      "source": [
        "import keras.backend as K\n",
        "K.clear_session()\n",
        "\n",
        "embedding_dim = 300\n",
        "\n",
        "#BiGRU\n",
        "bigru_in = Input(shape=(max_len,))\n",
        "bigru_em_layer = Embedding(max_words,embedding_dim)(bigru_in)\n",
        "bigru_layer_1 = Bidirectional(GRU(128,dropout= 0.2))(bigru_em_layer)\n",
        "bigru_dense_layer_1 = Dense(128,activation='relu')(bigru_layer_1)\n",
        "bigru_flatten1 = Flatten()(bigru_dense_layer_1)\n",
        "bigru_out = Dense(3,activation = 'softmax')(bigru_flatten1)\n",
        "bigru_model = Model(inputs=bigru_in, outputs=bigru_out)\n",
        "\n",
        "#BiLSTM\n",
        "bilstm_in = Input(shape=(max_len,))\n",
        "bilstm_em_layer = Embedding(max_words,embedding_dim)(bilstm_in)\n",
        "bilstm_layer_1 = Bidirectional(LSTM(128,dropout= 0.2))(bilstm_em_layer)\n",
        "bilstm_dense_layer_1 = Dense(128,activation='relu')(bilstm_layer_1)\n",
        "bilstm_flatten1 = Flatten()(bilstm_dense_layer_1)\n",
        "bilstm_out = Dense(3,activation = 'softmax')(bilstm_flatten1)\n",
        "bilstm_model = Model(inputs=bilstm_in, outputs=bilstm_out)\n",
        "\n",
        "#BiGRU+CNN\n",
        "hybrid_in = Input(shape=(max_len,))\n",
        "hybrid_em_layer = Embedding(max_words,embedding_dim)(hybrid_in)\n",
        "gru_Layer = Bidirectional(GRU(128,return_sequences=True))(hybrid_em_layer)\n",
        "hybrid_conv1 = Conv1D(128,3,activation='relu')(gru_Layer)\n",
        "hybrid_pool1 = MaxPooling1D(3)(hybrid_conv1)\n",
        "hybrid_flat1 = Flatten()(hybrid_pool1)\n",
        "hybrid_out = Dense(3, activation='softmax')(hybrid_flat1)\n",
        "gru_cnn = Model(inputs=hybrid_in, outputs=hybrid_out)\n",
        "\n",
        "#BiLSTM+CNN\n",
        "blcnn_in = Input(shape=(max_len,))\n",
        "blcnn_em_layer = Embedding(max_words,embedding_dim)(blcnn_in)\n",
        "bl_layer = Bidirectional(LSTM(128,return_sequences=True))(blcnn_em_layer)\n",
        "blcnn_conv1 = Conv1D(128,3,activation='relu')(bl_layer)\n",
        "blcnn_pool1 = MaxPooling1D(3)(blcnn_conv1)\n",
        "blcnn_flat1 = Flatten()(blcnn_pool1)\n",
        "blcnn_out = Dense(3, activation='softmax')(blcnn_flat1)\n",
        "lstm_cnn = Model(inputs=blcnn_in, outputs=blcnn_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TIcXFEvh8y6"
      },
      "outputs": [],
      "source": [
        "fusion_layer = keras.layers.concatenate([bigru_model.output, bilstm_model.output,gru_cnn.output,lstm_cnn.output],name = 'Lately-Fused_4')\n",
        "fused_dense = Dense(64, activation='relu')(fusion_layer)\n",
        "fused_flatten = Flatten()(fused_dense)\n",
        "fused_out = Dense(3, activation='softmax')(fused_flatten)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myZJO9xRh_Co"
      },
      "outputs": [],
      "source": [
        "Lf4_model = Model(inputs = [bigru_model.input, bilstm_model.input,gru_cnn.input,lstm_cnn.input], outputs=fused_out,name = \"LF_Trio\")\n",
        "Lf4_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTp-UF0wiCjq",
        "outputId": "7d13473b-f4f8-48d5-c1c9-2049845d0014"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"LF_Trio\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 256)]                0         []                            \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)        [(None, 256)]                0         []                            \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)        [(None, 256)]                0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 256)]                0         []                            \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)     (None, 256, 300)             1500000   ['input_3[0][0]']             \n",
            "                                                          0                                       \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)     (None, 256, 300)             1500000   ['input_4[0][0]']             \n",
            "                                                          0                                       \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 256, 300)             1500000   ['input_1[0][0]']             \n",
            "                                                          0                                       \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, 256, 300)             1500000   ['input_2[0][0]']             \n",
            "                                                          0                                       \n",
            "                                                                                                  \n",
            " bidirectional_2 (Bidirecti  (None, 256, 256)             330240    ['embedding_2[0][0]']         \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " bidirectional_3 (Bidirecti  (None, 256, 256)             439296    ['embedding_3[0][0]']         \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " bidirectional (Bidirection  (None, 256)                  330240    ['embedding[0][0]']           \n",
            " al)                                                                                              \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirecti  (None, 256)                  439296    ['embedding_1[0][0]']         \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)             (None, 254, 128)             98432     ['bidirectional_2[0][0]']     \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)           (None, 254, 128)             98432     ['bidirectional_3[0][0]']     \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 128)                  32896     ['bidirectional[0][0]']       \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 128)                  32896     ['bidirectional_1[0][0]']     \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1  (None, 84, 128)              0         ['conv1d[0][0]']              \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPoolin  (None, 84, 128)              0         ['conv1d_1[0][0]']            \n",
            " g1D)                                                                                             \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 128)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)         (None, 128)                  0         ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)         (None, 10752)                0         ['max_pooling1d[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)         (None, 10752)                0         ['max_pooling1d_1[0][0]']     \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 3)                    387       ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 3)                    387       ['flatten_1[0][0]']           \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 3)                    32259     ['flatten_2[0][0]']           \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 3)                    32259     ['flatten_3[0][0]']           \n",
            "                                                                                                  \n",
            " Lately-Fused_4 (Concatenat  (None, 12)                   0         ['dense_1[0][0]',             \n",
            " e)                                                                  'dense_3[0][0]',             \n",
            "                                                                     'dense_4[0][0]',             \n",
            "                                                                     'dense_5[0][0]']             \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 64)                   832       ['Lately-Fused_4[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_4 (Flatten)         (None, 64)                   0         ['dense_6[0][0]']             \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 3)                    195       ['flatten_4[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 61868047 (236.01 MB)\n",
            "Trainable params: 61868047 (236.01 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "Lf4_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RB9cVg_Nmltv",
        "outputId": "183b689a-0944-4177-b126-4529d69d1aff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pygraphviz\n",
            "  Using cached pygraphviz-1.11.zip (120 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pygraphviz\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pygraphviz (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for pygraphviz\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for pygraphviz\n",
            "Failed to build pygraphviz\n",
            "\u001b[31mERROR: Could not build wheels for pygraphviz, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "pip install pygraphviz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "7b43ABfDiE2Z",
        "outputId": "d78e0204-1c89-4f29-dc34-ce33674966e9"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras.utils.vis_utils'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-564-4550ca103cc1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvis_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLf4_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/LF4_model.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.utils.vis_utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(Lf4_model, to_file='/content/LF4_model.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-fFmhO-iHO0"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "early_stp = EarlyStopping(\n",
        "    monitor=\"val_accuracy\",\n",
        "    patience=10,\n",
        "    verbose=0,\n",
        "    mode=\"max\",\n",
        ")\n",
        "model_check = ModelCheckpoint(folderpath + \"LF_Trio_stp.h5\", monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "callback_lst = [early_stp,model_check]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giciNwcFiMl_",
        "outputId": "41f05cc0-6817-4843-ef37-e96d1ff95cdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0427 - accuracy: 0.4873\n",
            "Epoch 1: val_accuracy improved from -inf to 0.15333, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBLF_Trio_stp.h5\n",
            "13/13 [==============================] - 97s 4s/step - loss: 1.0427 - accuracy: 0.4873 - val_loss: 1.0466 - val_accuracy: 0.1533\n",
            "Epoch 2/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9943 - accuracy: 0.5330\n",
            "Epoch 2: val_accuracy did not improve from 0.15333\n",
            "13/13 [==============================] - 4s 316ms/step - loss: 0.9943 - accuracy: 0.5330 - val_loss: 1.0742 - val_accuracy: 0.1533\n",
            "Epoch 3/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9864 - accuracy: 0.5330\n",
            "Epoch 3: val_accuracy did not improve from 0.15333\n",
            "13/13 [==============================] - 5s 399ms/step - loss: 0.9864 - accuracy: 0.5330 - val_loss: 1.0989 - val_accuracy: 0.1533\n",
            "Epoch 4/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9675 - accuracy: 0.5330\n",
            "Epoch 4: val_accuracy did not improve from 0.15333\n",
            "13/13 [==============================] - 7s 541ms/step - loss: 0.9675 - accuracy: 0.5330 - val_loss: 1.0976 - val_accuracy: 0.1533\n",
            "Epoch 5/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9611 - accuracy: 0.5330\n",
            "Epoch 5: val_accuracy did not improve from 0.15333\n",
            "13/13 [==============================] - 5s 308ms/step - loss: 0.9611 - accuracy: 0.5330 - val_loss: 1.0572 - val_accuracy: 0.1533\n",
            "Epoch 6/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8444 - accuracy: 0.5330\n",
            "Epoch 6: val_accuracy did not improve from 0.15333\n",
            "13/13 [==============================] - 4s 336ms/step - loss: 0.8444 - accuracy: 0.5330 - val_loss: 0.9491 - val_accuracy: 0.1533\n",
            "Epoch 7/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.7338 - accuracy: 0.5330\n",
            "Epoch 7: val_accuracy did not improve from 0.15333\n",
            "13/13 [==============================] - 5s 417ms/step - loss: 0.7338 - accuracy: 0.5330 - val_loss: 0.8677 - val_accuracy: 0.1533\n",
            "Epoch 8/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.6242 - accuracy: 0.7970\n",
            "Epoch 8: val_accuracy improved from 0.15333 to 0.84000, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBLF_Trio_stp.h5\n",
            "13/13 [==============================] - 26s 2s/step - loss: 0.6242 - accuracy: 0.7970 - val_loss: 0.7906 - val_accuracy: 0.8400\n",
            "Epoch 9/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.5297 - accuracy: 0.9695\n",
            "Epoch 9: val_accuracy did not improve from 0.84000\n",
            "13/13 [==============================] - 4s 349ms/step - loss: 0.5297 - accuracy: 0.9695 - val_loss: 0.7059 - val_accuracy: 0.8333\n",
            "Epoch 10/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.4455 - accuracy: 1.0000\n",
            "Epoch 10: val_accuracy did not improve from 0.84000\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.4455 - accuracy: 1.0000 - val_loss: 0.6634 - val_accuracy: 0.8267\n",
            "Epoch 11/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.3758 - accuracy: 1.0000\n",
            "Epoch 11: val_accuracy did not improve from 0.84000\n",
            "13/13 [==============================] - 3s 269ms/step - loss: 0.3758 - accuracy: 1.0000 - val_loss: 0.6100 - val_accuracy: 0.8333\n",
            "Epoch 12/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.3168 - accuracy: 1.0000\n",
            "Epoch 12: val_accuracy did not improve from 0.84000\n",
            "13/13 [==============================] - 3s 267ms/step - loss: 0.3168 - accuracy: 1.0000 - val_loss: 0.5638 - val_accuracy: 0.8400\n",
            "Epoch 13/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.2679 - accuracy: 1.0000\n",
            "Epoch 13: val_accuracy did not improve from 0.84000\n",
            "13/13 [==============================] - 3s 255ms/step - loss: 0.2679 - accuracy: 1.0000 - val_loss: 0.5249 - val_accuracy: 0.8400\n",
            "Epoch 14/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.2264 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy improved from 0.84000 to 0.84667, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBLF_Trio_stp.h5\n",
            "13/13 [==============================] - 33s 3s/step - loss: 0.2264 - accuracy: 1.0000 - val_loss: 0.5108 - val_accuracy: 0.8467\n",
            "Epoch 15/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.1933 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy did not improve from 0.84667\n",
            "13/13 [==============================] - 5s 361ms/step - loss: 0.1933 - accuracy: 1.0000 - val_loss: 0.4987 - val_accuracy: 0.8467\n",
            "Epoch 16/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.1650 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy did not improve from 0.84667\n",
            "13/13 [==============================] - 3s 254ms/step - loss: 0.1650 - accuracy: 1.0000 - val_loss: 0.4968 - val_accuracy: 0.8467\n",
            "Epoch 17/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.1419 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy did not improve from 0.84667\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.1419 - accuracy: 1.0000 - val_loss: 0.4842 - val_accuracy: 0.8467\n",
            "Epoch 18/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.1229 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 0.84667\n",
            "13/13 [==============================] - 2s 197ms/step - loss: 0.1229 - accuracy: 1.0000 - val_loss: 0.4845 - val_accuracy: 0.8400\n",
            "Epoch 19/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.1067 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 0.84667\n",
            "13/13 [==============================] - 4s 307ms/step - loss: 0.1067 - accuracy: 1.0000 - val_loss: 0.4882 - val_accuracy: 0.8400\n",
            "Epoch 20/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.84667\n",
            "13/13 [==============================] - 3s 220ms/step - loss: 0.0935 - accuracy: 1.0000 - val_loss: 0.4925 - val_accuracy: 0.8467\n",
            "Epoch 21/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0826 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 0.84667\n",
            "13/13 [==============================] - 2s 179ms/step - loss: 0.0826 - accuracy: 1.0000 - val_loss: 0.4970 - val_accuracy: 0.8467\n",
            "Epoch 22/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0734 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 0.84667\n",
            "13/13 [==============================] - 4s 308ms/step - loss: 0.0734 - accuracy: 1.0000 - val_loss: 0.5006 - val_accuracy: 0.8467\n",
            "Epoch 23/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.84667\n",
            "13/13 [==============================] - 3s 256ms/step - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.5061 - val_accuracy: 0.8467\n",
            "Epoch 24/30\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0589 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.84667\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.0589 - accuracy: 1.0000 - val_loss: 0.5121 - val_accuracy: 0.8467\n"
          ]
        }
      ],
      "source": [
        "history = Lf4_model.fit([corpus, corpus, corpus, corpus],\n",
        "                          Btrain['label'],\n",
        "                          epochs = 30,\n",
        "                          batch_size = 16,\n",
        "                          verbose = 1,\n",
        "                          validation_data = ([validation_pad_sequences, validation_pad_sequences,\n",
        "                                            validation_pad_sequences, validation_pad_sequences], Bval['label']),\n",
        "                          callbacks = callback_lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9zoydWtjwMw",
        "outputId": "02424814-21b6-4064-ffeb-e8cdedc6112a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 3s 54ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9727    0.8917    0.9304       120\n",
            "           1     0.5152    0.7391    0.6071        23\n",
            "           2     0.4286    0.4286    0.4286         7\n",
            "\n",
            "    accuracy                         0.8467       150\n",
            "   macro avg     0.6388    0.6865    0.6554       150\n",
            "weighted avg     0.8772    0.8467    0.8574       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Assuming you have separate validation data for each input\n",
        "validation_data = [\n",
        "    validation_pad_sequences,  # Validation data for input_1\n",
        "    validation_pad_sequences,  # Validation data for input_2\n",
        "    validation_pad_sequences,  # Validation data for input_3\n",
        "    validation_pad_sequences   # Validation data for input_4\n",
        "]\n",
        "\n",
        "# Assuming you have separate validation labels (Aval['label']) for each input\n",
        "validation_labels = Bval['label']\n",
        "\n",
        "model = load_model(folderpath + \"LF_Trio_stp.h5\")\n",
        "# Now, make predictions using the model\n",
        "y_pred = model.predict(validation_data)\n",
        "\n",
        "# Assuming binary classification, convert probabilities to binary predictions\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Bval['label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMANbpdykbkY"
      },
      "outputs": [],
      "source": [
        "test_data = Btest['cleanText']  # Apply the same preprocessing steps\n",
        "\n",
        "# Tokenize and pad the test data\n",
        "test_sequences = tokenizer.texts_to_sequences(test_data)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict({'input_1': test_sequences, 'input_2': test_sequences, 'input_3': test_sequences, 'input_4': test_sequences})\n",
        "\n",
        "# Assuming binary classification, convert probabilities to binary predictions\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# If you want the predictions as a flat array\n",
        "flat_predictions = y_pred_classes.flatten()\n",
        "\n",
        "# Now 'flat_predictions' contains the binary predictions for the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHqoq3-_lIXw"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import zipfile\n",
        "\n",
        "# Create a DataFrame with \"index\" and \"prediction\" columns\n",
        "submission_df = pd.DataFrame({\"index\": Btest[\"index\"].tolist(), \"prediction\": flat_predictions})\n",
        "\n",
        "# Sort the DataFrame based on the \"index\" column\n",
        "submission_df = submission_df.sort_values(by=\"index\")\n",
        "\n",
        "# Define the path to save the submission file\n",
        "submission_file_path = \"/content/submission.json\"\n",
        "\n",
        "# Save the DataFrame to a JSON file\n",
        "submission_df.to_json(submission_file_path, orient=\"records\", lines=True)\n",
        "\n",
        "# Zip the JSON file\n",
        "with zipfile.ZipFile(\"ref.zip\", \"w\") as zipf:\n",
        "    zipf.write(submission_file_path, arcname=\"submission.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPy3sgv5iPTY"
      },
      "outputs": [],
      "source": [
        "loss_values = history.history['loss']\n",
        "val_loss_values = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, color='midnightblue', linewidth = 2,\n",
        "          marker='o', markersize=8,label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, color='darkred', linewidth = 2,\n",
        "          marker='o', markersize=8,label='Training Accuracy')\n",
        "plt.title('Training and validation accuracy',fontsize=12)\n",
        "plt.xlabel('Epochs',fontsize=12)\n",
        "plt.ylabel('Accuracy',fontsize=12)\n",
        "plt.legend(['Training Accuracy','Validation Accuracy'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3AceduXiR5X"
      },
      "outputs": [],
      "source": [
        "plt.plot(epochs, loss_values, color='midnightblue', linewidth = 2,\n",
        "          marker='o', markersize=8,label='Training Accuracy')\n",
        "plt.plot(epochs, val_loss_values, color='darkred', linewidth = 2,\n",
        "          marker='o', markersize=8,label='Training Accuracy')\n",
        "plt.title('Training and validation Loss',fontsize=12)\n",
        "plt.xlabel('Epochs',fontsize=12)\n",
        "plt.ylabel('Loss',fontsize=12)\n",
        "plt.legend(['Training Loss','Validation Loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXz4yMhJiUnl"
      },
      "outputs": [],
      "source": [
        "best_model = keras.models.load_model('./LF_Trio_stp.h5')\n",
        "def predict_res(sample):\n",
        "    processed_text = text_preprocess(sample)\n",
        "    with open('./tokenizer_7th.pickle', 'rb') as handle:\n",
        "        loaded_tokenizer = pickle.load(handle)\n",
        "    seq= loaded_tokenizer.texts_to_sequences([processed_text])\n",
        "    padded = pad_sequences(seq, value=0,padding='post', maxlen= 200)\n",
        "    pred = best_model.predict([padded,padded,padded,padded])[0]\n",
        "    pred_f = (pred>0.5).astype('int')\n",
        "    return pred_f[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIFH8hualgYO"
      },
      "outputs": [],
      "source": [
        "loss_values = history.history['loss']\n",
        "val_loss_values = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, color='midnightblue', linewidth = 2,\n",
        "          marker='o', markersize=8,label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, color='darkred', linewidth = 2,\n",
        "          marker='o', markersize=8,label='Training Accuracy')\n",
        "plt.title('Training and validation accuracy',fontsize=12)\n",
        "plt.xlabel('Epochs',fontsize=12)\n",
        "plt.ylabel('Accuracy',fontsize=12)\n",
        "plt.legend(['Training Accuracy','Validation Accuracy'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJfWvgXBlhQp"
      },
      "outputs": [],
      "source": [
        "plt.plot(epochs, loss_values, color='midnightblue', linewidth = 2,\n",
        "          marker='o', markersize=8,label='Training Accuracy')\n",
        "plt.plot(epochs, val_loss_values, color='darkred', linewidth = 2,\n",
        "          marker='o', markersize=8,label='Training Accuracy')\n",
        "plt.title('Training and validation Loss',fontsize=12)\n",
        "plt.xlabel('Epochs',fontsize=12)\n",
        "plt.ylabel('Loss',fontsize=12)\n",
        "plt.legend(['Training Loss','Validation Loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3o7j_WZzljR1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd-CAe8Ibyxb"
      },
      "source": [
        "# ktrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caZBKu7Rb88A",
        "outputId": "514763f2-2f80-47b2-eded-77de98231086"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ktrain\n",
            "  Downloading ktrain-0.39.0.tar.gz (25.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m25.3/25.3 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from ktrain) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.5.3)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ktrain) (2.31.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.3.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ktrain) (23.2)\n",
            "Collecting langdetect (from ktrain)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from ktrain) (0.42.1)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.10/dist-packages (from ktrain) (3.3.2)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from ktrain) (5.2.0)\n",
            "Collecting syntok>1.3.3 (from ktrain)\n",
            "  Downloading syntok-1.4.4-py3-none-any.whl (24 kB)\n",
            "Collecting tika (from ktrain)\n",
            "  Downloading tika-2.6.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers>=4.17.0 in /usr/local/lib/python3.10/dist-packages (from ktrain) (4.35.2)\n",
            "Collecting sentencepiece (from ktrain)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras_bert>=0.86.0 (from ktrain)\n",
            "  Downloading keras-bert-0.89.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting whoosh (from ktrain)\n",
            "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m468.8/468.8 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras_bert>=0.86.0->ktrain) (1.23.5)\n",
            "Collecting keras-transformer==0.40.0 (from keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-transformer-0.40.0.tar.gz (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-pos-embd==0.13.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-multi-head==0.29.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-layer-normalization==0.16.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-position-wise-feed-forward==0.8.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-embed-sim==0.10.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-self-attention==0.51.0 (from keras-multi-head==0.29.0->keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->ktrain) (2023.3.post1)\n",
            "Requirement already satisfied: regex>2016 in /usr/local/lib/python3.10/dist-packages (from syntok>1.3.3->ktrain) (2023.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (0.20.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (4.66.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->ktrain) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (2023.11.17)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (3.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tika->ktrain) (67.7.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers>=4.17.0->ktrain) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers>=4.17.0->ktrain) (4.5.0)\n",
            "Building wheels for collected packages: ktrain, keras_bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, langdetect, tika\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ktrain: filename=ktrain-0.39.0-py3-none-any.whl size=25319737 sha256=518cfac6431e4031f28946c6ead4692e1ca840e0d3bc2dbddf6b28dc515bdf07\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/fd/0a/ef6252223f3d2c49b06d18e71c74caa43bbf4c64a8c183a46e\n",
            "  Building wheel for keras_bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras_bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33499 sha256=1ed3b0874029d5713123bfd3e48cc099ab4d687eaeb281003032249fc9f8e336\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/0c/04/646b6fdf6375911b42c8d540a8a3fda8d5d77634e5dcbe7b26\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12286 sha256=9c6bac92b85d5f831fe982ffe0c9c9af4f1c2cef2752b0f95c8ef19292a198ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/cb/22/75a0ad376129177f7c95c0d91331a18f5368fd657f4035ba7c\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3943 sha256=2d53862f1f5eebf71c0c139a768e3a7c0b5739b6af37456af9efac6f17ff5579\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/32/c7/fd35d0d1b840a6c7cbd4343f808d10d0f7b87d271a4dbe796f\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4653 sha256=dba77849877f92de9c9fc2c373c1512019abdcb1bc7b689eecef4eb6750484af\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/3a/4b/21db23c0cc56c4b219616e181f258eb7c57d36cc5d056fae9a\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14975 sha256=8be323063f841d73a62db467785e4e4c5c82b5ebba2d2bd3f343b6dce828c44f\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/23/4b/06d7ae21714f70fcc25b48f972cc8e5e7f4b6b764a038b509d\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6946 sha256=b93a53911aedbcecbdfc55283384a99c0c32d8096d4bd73aef6e212b4a8b5e54\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/07/1b/b1ca47b6ac338554b75c8f52c54e6a2bfbe1b07d79579979a4\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4968 sha256=a5b62d77f02e136f2a2e56458e69a89ab66e1a4c534cf318bb29108363ab1a8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/6a/04/d1706a53b23b2cb5f9a0a76269bf87925daa1bca09eac01b21\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18895 sha256=a9752c280b622c86fe040f13e5503c575d7208b4716278b4e37dd2be1bcd92db\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/f7/24/607b483144fb9c47b4ba2c5fba6b68e54aeee2d5bf6c05302e\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=4934a663af807426cf2a5ecf5f0bb3d81bf872b2fe569012dd64148691159ce6\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32622 sha256=a6742d975d4583aa62f9ae451477e3af6576521f6211fda631b5df926077fa99\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/71/c7/b757709531121b1700cffda5b6b0d4aad095fb507ec84316d0\n",
            "Successfully built ktrain keras_bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention langdetect tika\n",
            "Installing collected packages: whoosh, sentencepiece, syntok, langdetect, keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-layer-normalization, keras-embed-sim, tika, keras-multi-head, keras-transformer, keras_bert, ktrain\n",
            "Successfully installed keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0 keras_bert-0.89.0 ktrain-0.39.0 langdetect-1.0.9 sentencepiece-0.1.99 syntok-1.4.4 tika-2.6.0 whoosh-2.7.4\n"
          ]
        }
      ],
      "source": [
        "!pip install ktrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEdORDT8b5OC"
      },
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWkkVcSYciz0"
      },
      "outputs": [],
      "source": [
        "import ktrain\n",
        "from ktrain import text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UE_nECS8cNcb"
      },
      "outputs": [],
      "source": [
        "categories=['1', '2', '3']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtl_Lbo453_e"
      },
      "source": [
        "## Ktrain mBert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "q_uEfOPM53_f",
        "outputId": "9f879513-b745-4bfb-ca03-3092eadc8a43"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c4ac8e1daa647089e70289d48a28293",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fdfc8020955c4e96abff692b67dcaf96",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_name = 'bert-base-multilingual-cased'\n",
        "trans = text.Transformer(model_name,maxlen=256,class_names=categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "5B_SaoHfYBqD",
        "outputId": "a55b2086-d363-47cb-bdbf-de01ad43f6ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 20\n",
            "\t95percentile : 28\n",
            "\t99percentile : 38\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "088dfd67feba4bca9e7915094a906962",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83bcac637fb248b6aa315919911ef2c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e404046aa40641cfbca96fd6ca729cda",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 15\n",
            "\t95percentile : 27\n",
            "\t99percentile : 29\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n"
          ]
        }
      ],
      "source": [
        "train = trans.preprocess_train(X_train, y_train)\n",
        "valid = trans.preprocess_train(X_valid, y_valid)\n",
        "model = trans.get_classifier()\n",
        "CasedmBertlearner = ktrain.get_learner(model, train_data=train,val_data=valid, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg_4uWrZ53_g",
        "outputId": "6e3e3b1f-2f4a-48a7-f23c-550d000f70a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 3e-05...\n",
            "Epoch 1/8\n",
            "13/13 [==============================] - 69s 1s/step - loss: 1.1256 - accuracy: 0.4670 - val_loss: 1.1591 - val_accuracy: 0.1533\n",
            "Epoch 2/8\n",
            "13/13 [==============================] - 13s 1s/step - loss: 1.1034 - accuracy: 0.3706 - val_loss: 1.1192 - val_accuracy: 0.0467\n",
            "Epoch 3/8\n",
            "13/13 [==============================] - 13s 1s/step - loss: 1.0992 - accuracy: 0.2589 - val_loss: 1.1650 - val_accuracy: 0.0467\n",
            "Epoch 4/8\n",
            "13/13 [==============================] - 14s 1s/step - loss: 1.0669 - accuracy: 0.3756 - val_loss: 0.9586 - val_accuracy: 0.8200\n",
            "Epoch 5/8\n",
            "13/13 [==============================] - 13s 1s/step - loss: 1.0101 - accuracy: 0.4975 - val_loss: 0.7445 - val_accuracy: 0.8867\n",
            "Epoch 6/8\n",
            "13/13 [==============================] - 13s 1s/step - loss: 0.9341 - accuracy: 0.5228 - val_loss: 1.1716 - val_accuracy: 0.2600\n",
            "Epoch 7/8\n",
            "13/13 [==============================] - 16s 1s/step - loss: 0.6649 - accuracy: 0.6701 - val_loss: 1.1657 - val_accuracy: 0.2867\n",
            "Epoch 8/8\n",
            "13/13 [==============================] - 13s 1s/step - loss: 0.4965 - accuracy: 0.8629 - val_loss: 0.7747 - val_accuracy: 0.8000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7923dfb2fe50>"
            ]
          },
          "execution_count": 281,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CasedmBertlearner.fit_onecycle(3e-5,8, class_weight = weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvCUCK4Nx6zI",
        "outputId": "c80b6d9b-76ff-44fc-9843-0986033567fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 3e-05...\n",
            "Epoch 1/2\n",
            "13/13 [==============================] - 14s 1s/step - loss: 0.1671 - accuracy: 0.9645 - val_loss: 0.3714 - val_accuracy: 0.9067\n",
            "Epoch 2/2\n",
            "13/13 [==============================] - 16s 1s/step - loss: 0.1179 - accuracy: 0.9746 - val_loss: 0.4195 - val_accuracy: 0.8867\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7923d7dff250>"
            ]
          },
          "execution_count": 291,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CasedmBertlearner.fit_onecycle(3e-5, 2, class_weight = weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AncG3TVX53_g",
        "outputId": "11bbde21-c7db-4740-f07d-21a24ba411df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 3s 560ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.96      0.92      0.94       120\n",
            "           2       0.72      0.78      0.75        23\n",
            "           3       0.50      0.71      0.59         7\n",
            "\n",
            "    accuracy                           0.89       150\n",
            "   macro avg       0.73      0.80      0.76       150\n",
            "weighted avg       0.90      0.89      0.89       150\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[110,   6,   4],\n",
              "       [  4,  18,   1],\n",
              "       [  1,   1,   5]])"
            ]
          },
          "execution_count": 292,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CasedmBertlearner.validate(class_names=categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZ-vbH3M53_h"
      },
      "outputs": [],
      "source": [
        "predictor = ktrain.get_predictor(CasedmBertlearner.model, preproc=trans)\n",
        "y_pred = predictor.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqeqG4Y3rwYy"
      },
      "outputs": [],
      "source": [
        "y_pred = np.array(y_pred).astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtFvSnNHxju8",
        "outputId": "e5dcd15c-59ed-4f6b-d820-5097dd7ae2de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy: 0.86\n",
            "Classification Report for Logistic Regression:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.97      0.92      0.94       121\n",
            "           2       0.65      0.65      0.65        23\n",
            "           3       0.25      0.50      0.33         6\n",
            "\n",
            "    accuracy                           0.86       150\n",
            "   macro avg       0.62      0.69      0.64       150\n",
            "weighted avg       0.89      0.86      0.87       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "accuracy_mbert = accuracy_score(y_test, y_pred)\n",
        "classification_report_mbert = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'mBERT Accuracy: {accuracy_mbert}')\n",
        "print('Classification Report for mBERT:\\n', classification_report_mbert) # 0.63      0.63      0.63"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geE_OQBPYBqE"
      },
      "outputs": [],
      "source": [
        "predictor.save('/content/drive/MyDrive/Colab Notebooks/case/'+'TaskB'+'/taskbmBERTCasedOver')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOVOKvW3YBqE"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "# import zipfile\n",
        "\n",
        "# # Assuming Btest is your DataFrame with an \"index\" column and y_pred is your predicted labels\n",
        "# # Replace y_pred with your actual predicted labels\n",
        "\n",
        "# # Create a DataFrame with \"index\" and \"prediction\" columns\n",
        "# submission_df = pd.DataFrame({\"index\": Btest[\"index\"].tolist(), \"prediction\": y_pred})\n",
        "\n",
        "# # Sort the DataFrame based on the \"index\" column\n",
        "# submission_df = submission_df.sort_values(by=\"index\")\n",
        "\n",
        "# # Define the path to save the submission file\n",
        "# submission_file_path = \"/content/submission.json\"\n",
        "\n",
        "# # Save the DataFrame to a JSON file\n",
        "# submission_df.to_json(submission_file_path, orient=\"records\", lines=True)\n",
        "\n",
        "# # Zip the JSON file\n",
        "# with zipfile.ZipFile(\"ref.zip\", \"w\") as zipf:\n",
        "#     zipf.write(submission_file_path, arcname=\"submission.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkJ0caVu53_k"
      },
      "source": [
        "## Ktrain DistilmBert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "gdlYign153_k",
        "outputId": "aeb4e3a7-5239-4987-efd5-55c12eadb3a4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b723a5604d54ad4af427f2089bd748a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/466 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3a579da10c9430295de6dc63593f68f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/542M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 20\n",
            "\t95percentile : 28\n",
            "\t99percentile : 38\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc65c566713b406890aeb1b28195880a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb1d94bbb95f4dc0a620f7c8218f7a9d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1da2889565de4a2280f9fa2b462d45f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 15\n",
            "\t95percentile : 27\n",
            "\t99percentile : 29\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n"
          ]
        }
      ],
      "source": [
        "model_name = 'distilbert-base-multilingual-cased'\n",
        "trans = text.Transformer(model_name,maxlen=256,class_names=categories)\n",
        "train = trans.preprocess_train(X_train, y_train)\n",
        "valid = trans.preprocess_train(X_valid, y_valid)\n",
        "model = trans.get_classifier()\n",
        "Distillearner = ktrain.get_learner(model, train_data=train,val_data=valid, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4YOGDt553_l",
        "outputId": "31644071-0c8a-4f80-ae43-d84dbd07440a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 3e-05...\n",
            "Epoch 1/12\n",
            "13/13 [==============================] - 23s 797ms/step - loss: 1.0975 - accuracy: 0.2487 - val_loss: 1.0740 - val_accuracy: 0.7533\n",
            "Epoch 2/12\n",
            "13/13 [==============================] - 7s 535ms/step - loss: 1.0905 - accuracy: 0.4772 - val_loss: 1.0561 - val_accuracy: 0.7600\n",
            "Epoch 3/12\n",
            "13/13 [==============================] - 8s 640ms/step - loss: 1.0310 - accuracy: 0.6396 - val_loss: 0.9627 - val_accuracy: 0.8867\n",
            "Epoch 4/12\n",
            "13/13 [==============================] - 7s 541ms/step - loss: 0.7962 - accuracy: 0.7157 - val_loss: 0.5930 - val_accuracy: 0.8867\n",
            "Epoch 5/12\n",
            "13/13 [==============================] - 8s 650ms/step - loss: 0.4583 - accuracy: 0.8376 - val_loss: 0.2964 - val_accuracy: 0.9000\n",
            "Epoch 6/12\n",
            "13/13 [==============================] - 7s 541ms/step - loss: 0.1766 - accuracy: 0.9594 - val_loss: 0.4648 - val_accuracy: 0.8400\n",
            "Epoch 7/12\n",
            "13/13 [==============================] - 8s 647ms/step - loss: 0.0734 - accuracy: 0.9898 - val_loss: 0.4103 - val_accuracy: 0.8733\n",
            "Epoch 8/12\n",
            "13/13 [==============================] - 7s 536ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.4092 - val_accuracy: 0.8933\n",
            "Epoch 9/12\n",
            "13/13 [==============================] - 8s 644ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.4036 - val_accuracy: 0.8933\n",
            "Epoch 10/12\n",
            "13/13 [==============================] - 7s 534ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.3942 - val_accuracy: 0.9000\n",
            "Epoch 11/12\n",
            "13/13 [==============================] - 7s 540ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.4062 - val_accuracy: 0.8933\n",
            "Epoch 12/12\n",
            "13/13 [==============================] - 7s 533ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.4087 - val_accuracy: 0.8933\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7923d7b230a0>"
            ]
          },
          "execution_count": 297,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Distillearner.fit_onecycle(3e-5,12, class_weight = weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Bu_frxa53_l",
        "outputId": "0cb3c288-32ed-4812-9516-e9218eb2e921"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 3s 303ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.94      0.94      0.94       120\n",
            "           2       0.74      0.74      0.74        23\n",
            "           3       0.57      0.57      0.57         7\n",
            "\n",
            "    accuracy                           0.89       150\n",
            "   macro avg       0.75      0.75      0.75       150\n",
            "weighted avg       0.89      0.89      0.89       150\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[113,   5,   2],\n",
              "       [  5,  17,   1],\n",
              "       [  2,   1,   4]])"
            ]
          },
          "execution_count": 298,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Distillearner.validate(class_names=categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORwYAlI753_m"
      },
      "outputs": [],
      "source": [
        "predictor = ktrain.get_predictor(Distillearner.model, preproc=trans)\n",
        "y_pred = predictor.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nggi7EJfYBqJ"
      },
      "outputs": [],
      "source": [
        "y_pred = np.array(y_pred).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeGTaJ1RYBqK"
      },
      "outputs": [],
      "source": [
        "predictor.save('/content/drive/MyDrive/Colab Notebooks/case/'+'TaskB'+'/taskbDistilmBERT')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5irIhYjwzwPF",
        "outputId": "5d3b64a7-a12e-46d1-9899-e2ed52c32f10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy: 0.8533333333333334\n",
            "Classification Report for Logistic Regression:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      0.93      0.93       121\n",
            "           2       0.59      0.57      0.58        23\n",
            "           3       0.43      0.50      0.46         6\n",
            "\n",
            "    accuracy                           0.85       150\n",
            "   macro avg       0.65      0.66      0.65       150\n",
            "weighted avg       0.85      0.85      0.85       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "accuracy_distilmBERT = accuracy_score(y_test, y_pred)\n",
        "classification_report_distilmBERT = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'DistilmBERT Accuracy: {accuracy_distilmBERT}')\n",
        "print('Classification Report for DistilmBERT:\\n', classification_report_distilmBERT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McAFLuiCYBqK"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "# import zipfile\n",
        "\n",
        "# # Assuming Btest is your DataFrame with an \"index\" column and y_pred is your predicted labels\n",
        "# # Replace y_pred with your actual predicted labels\n",
        "\n",
        "# # Create a DataFrame with \"index\" and \"prediction\" columns\n",
        "# submission_df = pd.DataFrame({\"index\": Btest[\"index\"].tolist(), \"prediction\": y_pred})\n",
        "\n",
        "# # Sort the DataFrame based on the \"index\" column\n",
        "# submission_df = submission_df.sort_values(by=\"index\")\n",
        "\n",
        "# # Define the path to save the submission file\n",
        "# submission_file_path = \"/content/submissiondistil.json\"\n",
        "\n",
        "# # Save the DataFrame to a JSON file\n",
        "# submission_df.to_json(submission_file_path, orient=\"records\", lines=True)\n",
        "\n",
        "# # Zip the JSON file\n",
        "# with zipfile.ZipFile(\"distilmBERTTaskB.zip\", \"w\") as zipf:\n",
        "#     zipf.write(submission_file_path, arcname=\"submissiondistil.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6paYwL3y53_i"
      },
      "source": [
        "## Ktrain XLMR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "N6JwTmwc53_i",
        "outputId": "c0695b87-4177-4a04-f64c-1e820f8a3d15"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41d8c8c2ea38430990968ec9c704d1ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4614de97d01c4ad6b069ff3602750c6f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/512 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0e043c288284876b5ecdd9c262d96b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tf_model.h5:   0%|          | 0.00/1.89G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 20\n",
            "\t95percentile : 28\n",
            "\t99percentile : 38\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e146c94b303d44a5a3d9ccd6e6c2477a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 15\n",
            "\t95percentile : 27\n",
            "\t99percentile : 29\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n"
          ]
        }
      ],
      "source": [
        "model_name = 'xlm-roberta-base'\n",
        "trans = text.Transformer(model_name,maxlen=256,class_names=categories)\n",
        "train = trans.preprocess_train(X_train, y_train)\n",
        "valid = trans.preprocess_train(X_valid, y_valid)\n",
        "model = trans.get_classifier()\n",
        "XLlearner = ktrain.get_learner(model, train_data=train,val_data=valid, batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVnz6rQ553_j",
        "outputId": "6fb63def-29e1-49b6-f229-2cd527ade3c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 2e-05...\n",
            "Epoch 1/12\n",
            "25/25 [==============================] - 72s 930ms/step - loss: 1.0989 - accuracy: 0.2234 - val_loss: 1.1369 - val_accuracy: 0.0467\n",
            "Epoch 2/12\n",
            "25/25 [==============================] - 16s 623ms/step - loss: 1.0988 - accuracy: 0.2640 - val_loss: 1.0904 - val_accuracy: 0.0867\n",
            "Epoch 3/12\n",
            "25/25 [==============================] - 16s 632ms/step - loss: 1.0741 - accuracy: 0.3858 - val_loss: 1.2217 - val_accuracy: 0.0467\n",
            "Epoch 4/12\n",
            "25/25 [==============================] - 16s 631ms/step - loss: 1.0150 - accuracy: 0.4569 - val_loss: 1.0823 - val_accuracy: 0.1867\n",
            "Epoch 5/12\n",
            "25/25 [==============================] - 16s 624ms/step - loss: 1.0257 - accuracy: 0.4975 - val_loss: 0.9730 - val_accuracy: 0.8800\n",
            "Epoch 6/12\n",
            "25/25 [==============================] - 15s 619ms/step - loss: 0.9455 - accuracy: 0.5685 - val_loss: 0.7708 - val_accuracy: 0.8267\n",
            "Epoch 7/12\n",
            "25/25 [==============================] - 15s 621ms/step - loss: 0.9643 - accuracy: 0.5685 - val_loss: 1.1491 - val_accuracy: 0.1600\n",
            "Epoch 8/12\n",
            "25/25 [==============================] - 15s 622ms/step - loss: 0.9179 - accuracy: 0.6396 - val_loss: 0.5065 - val_accuracy: 0.8733\n",
            "Epoch 9/12\n",
            "25/25 [==============================] - 16s 626ms/step - loss: 0.7608 - accuracy: 0.7157 - val_loss: 0.3786 - val_accuracy: 0.9067\n",
            "Epoch 10/12\n",
            "25/25 [==============================] - 16s 626ms/step - loss: 0.4603 - accuracy: 0.8528 - val_loss: 0.3467 - val_accuracy: 0.9200\n",
            "Epoch 11/12\n",
            "25/25 [==============================] - 16s 625ms/step - loss: 0.3266 - accuracy: 0.9137 - val_loss: 0.2831 - val_accuracy: 0.9267\n",
            "Epoch 12/12\n",
            "25/25 [==============================] - 15s 623ms/step - loss: 0.2635 - accuracy: 0.9239 - val_loss: 0.2990 - val_accuracy: 0.9267\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7923d4de95a0>"
            ]
          },
          "execution_count": 303,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "XLlearner.fit_onecycle(2e-5,12, class_weight = weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ny7kHt253_j",
        "outputId": "71dbc711-2dc8-4f85-e242-505f6c103412"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 6s 642ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.97      0.97      0.97       120\n",
            "           2       0.86      0.78      0.82        23\n",
            "           3       0.56      0.71      0.63         7\n",
            "\n",
            "    accuracy                           0.93       150\n",
            "   macro avg       0.79      0.82      0.80       150\n",
            "weighted avg       0.93      0.93      0.93       150\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[116,   3,   1],\n",
              "       [  2,  18,   3],\n",
              "       [  2,   0,   5]])"
            ]
          },
          "execution_count": 304,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "XLlearner.validate(class_names=categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ME_HiZYj53_j"
      },
      "outputs": [],
      "source": [
        "predictor = ktrain.get_predictor(XLlearner.model, preproc=trans)\n",
        "y_pred = predictor.predict(X_test)\n",
        "# y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQ8yiYhj2ay3"
      },
      "outputs": [],
      "source": [
        "y_pred = np.array(y_pred).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2jVp4D22eV3",
        "outputId": "87e4b1d6-816a-4cfe-c456-25710a0a4219"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XLMR Accuracy: 0.8533333333333334\n",
            "Classification Report for XLMR:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      0.93      0.93       121\n",
            "           2       0.76      0.57      0.65        23\n",
            "           3       0.23      0.50      0.32         6\n",
            "\n",
            "    accuracy                           0.85       150\n",
            "   macro avg       0.64      0.66      0.63       150\n",
            "weighted avg       0.88      0.85      0.86       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "accuracy_XLMR = accuracy_score(y_test, y_pred)\n",
        "classification_report_XLMR = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'XLMR Accuracy: {accuracy_XLMR}')\n",
        "print('Classification Report for XLMR:\\n', classification_report_XLMR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OE9UBWXNYBqG"
      },
      "outputs": [],
      "source": [
        "predictor.save('/content/drive/MyDrive/Colab Notebooks/case/'+'TaskB'+'/taskbxlmr')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8T3CUS61YBqH"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "# import zipfile\n",
        "\n",
        "# # Assuming Btest is your DataFrame with an \"index\" column and y_pred is your predicted labels\n",
        "# # Replace y_pred with your actual predicted labels\n",
        "\n",
        "# # Create a DataFrame with \"index\" and \"prediction\" columns\n",
        "# submission_df = pd.DataFrame({\"index\": Btest[\"index\"].tolist(), \"prediction\": y_pred})\n",
        "\n",
        "# # Sort the DataFrame based on the \"index\" column\n",
        "# submission_df = submission_df.sort_values(by=\"index\")\n",
        "\n",
        "# # Define the path to save the submission file\n",
        "# submission_file_path = \"/content/submissionxlmr.json\"\n",
        "\n",
        "# # Save the DataFrame to a JSON file\n",
        "# submission_df.to_json(submission_file_path, orient=\"records\", lines=True)\n",
        "\n",
        "# # Zip the JSON file\n",
        "# with zipfile.ZipFile(\"TaskBXLMR.zip\", \"w\") as zipf:\n",
        "#     zipf.write(submission_file_path, arcname=\"submissionxlmr.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64F6_rRR53_o"
      },
      "source": [
        "## Ktrain ClimateBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "FSP3NScK53_o",
        "outputId": "9484a021-2251-460c-c384-03673df8e3ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 20\n",
            "\t95percentile : 28\n",
            "\t99percentile : 38\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 15\n",
            "\t95percentile : 27\n",
            "\t99percentile : 29\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n"
          ]
        }
      ],
      "source": [
        "model_name = 'climatebert/distilroberta-base-climate-f'\n",
        "trans = text.Transformer(model_name,maxlen=256,class_names=categories)\n",
        "train = trans.preprocess_train(X_train, y_train)\n",
        "valid = trans.preprocess_train(X_valid, y_valid)\n",
        "model = trans.get_classifier()\n",
        "AlbertLearner = ktrain.get_learner(model, train_data=train,val_data=valid, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2evDDr7YBqN",
        "outputId": "03f5b861-e052-4d0d-e3d7-2e0b88e85ce4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 3e-05...\n",
            "Epoch 1/10\n",
            "13/13 [==============================] - 29s 922ms/step - loss: 1.0995 - accuracy: 0.2386 - val_loss: 1.0922 - val_accuracy: 0.0533\n",
            "Epoch 2/10\n",
            "13/13 [==============================] - 7s 537ms/step - loss: 1.0831 - accuracy: 0.3756 - val_loss: 1.0438 - val_accuracy: 0.8600\n",
            "Epoch 3/10\n",
            "13/13 [==============================] - 7s 573ms/step - loss: 1.0290 - accuracy: 0.5279 - val_loss: 0.7544 - val_accuracy: 0.8733\n",
            "Epoch 4/10\n",
            "13/13 [==============================] - 8s 635ms/step - loss: 0.7065 - accuracy: 0.7513 - val_loss: 0.3792 - val_accuracy: 0.8600\n",
            "Epoch 5/10\n",
            "13/13 [==============================] - 8s 638ms/step - loss: 0.5037 - accuracy: 0.7817 - val_loss: 0.3030 - val_accuracy: 0.8867\n",
            "Epoch 6/10\n",
            "13/13 [==============================] - 8s 631ms/step - loss: 0.2424 - accuracy: 0.8883 - val_loss: 0.3411 - val_accuracy: 0.9067\n",
            "Epoch 7/10\n",
            "13/13 [==============================] - 8s 620ms/step - loss: 0.0840 - accuracy: 0.9746 - val_loss: 0.3215 - val_accuracy: 0.8933\n",
            "Epoch 8/10\n",
            "13/13 [==============================] - 7s 508ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.3416 - val_accuracy: 0.9000\n",
            "Epoch 9/10\n",
            "13/13 [==============================] - 7s 542ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.3581 - val_accuracy: 0.9067\n",
            "Epoch 10/10\n",
            "13/13 [==============================] - 7s 512ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.3572 - val_accuracy: 0.9000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78458cc3fca0>"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "AlbertLearner.fit_onecycle(3e-5,10, class_weight = weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVY54Y-cYBqN",
        "outputId": "c595f6b2-0046-4ede-dde1-6d6073f471ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 5s 445ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      0.96      0.95       120\n",
            "           2       0.74      0.74      0.74        23\n",
            "           3       0.75      0.43      0.55         7\n",
            "\n",
            "    accuracy                           0.90       150\n",
            "   macro avg       0.81      0.71      0.74       150\n",
            "weighted avg       0.90      0.90      0.90       150\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[115,   4,   1],\n",
              "       [  6,  17,   0],\n",
              "       [  2,   2,   3]])"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "AlbertLearner.validate(class_names=categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmUu_8LP3UBY"
      },
      "outputs": [],
      "source": [
        "predictor = ktrain.get_predictor(AlbertLearner.model, preproc=trans)\n",
        "y_pred = predictor.predict(X_test)\n",
        "# y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaKjGb3HBtEA"
      },
      "outputs": [],
      "source": [
        "y_pred = np.array(y_pred).astype(int)\n",
        "# predictor.save('/content/drive/MyDrive/Colab Notebooks/case/'+'TaskB'+'/taskbAlbert')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uswr9whs0s4e"
      },
      "outputs": [],
      "source": [
        "y_pred = y_pred - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp4hktf00aDX",
        "outputId": "d070dd01-6d53-4306-aaa8-ddc5f10072b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "climateBERT Accuracy: 0.88\n",
            "Classification Report for climateBERT:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.94      0.94       121\n",
            "           1       0.65      0.74      0.69        23\n",
            "           2       0.50      0.17      0.25         6\n",
            "\n",
            "    accuracy                           0.88       150\n",
            "   macro avg       0.70      0.62      0.63       150\n",
            "weighted avg       0.87      0.88      0.87       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "accuracy_climateBERT = accuracy_score(y_test, y_pred)\n",
        "classification_report_climateBERT = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'climateBERT Accuracy: {accuracy_climateBERT}')\n",
        "print('Classification Report for climateBERT:\\n', classification_report_climateBERT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwjyVCUzB2_g"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import zipfile\n",
        "\n",
        "# Assuming Btest is your DataFrame with an \"index\" column and y_pred is your predicted labels\n",
        "# Replace y_pred with your actual predicted labels\n",
        "\n",
        "# Create a DataFrame with \"index\" and \"prediction\" columns\n",
        "submission_df = pd.DataFrame({\"index\": Btest[\"index\"].tolist(), \"prediction\": y_pred})\n",
        "\n",
        "# Sort the DataFrame based on the \"index\" column\n",
        "submission_df = submission_df.sort_values(by=\"index\")\n",
        "\n",
        "# Define the path to save the submission file\n",
        "submission_file_path = \"/content/submissionalbert.json\"\n",
        "\n",
        "# Save the DataFrame to a JSON file\n",
        "submission_df.to_json(submission_file_path, orient=\"records\", lines=True)\n",
        "\n",
        "# Zip the JSON file\n",
        "with zipfile.ZipFile(\"submission.zip\", \"w\") as zipf:\n",
        "    zipf.write(submission_file_path, arcname=\"submissionalbert.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG3tcNbW53_m"
      },
      "source": [
        "## Ktrain mBert Uncased"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "IVtAuToe53_n",
        "outputId": "e82e0ff7-bf55-40b8-d0f3-e0edffb17b7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 18\n",
            "\t95percentile : 27\n",
            "\t99percentile : 33\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 15\n",
            "\t95percentile : 27\n",
            "\t99percentile : 29\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n"
          ]
        }
      ],
      "source": [
        "model_name = 'bert-base-multilingual-uncased'\n",
        "trans = text.Transformer(model_name,maxlen=256,class_names=categories)\n",
        "train = trans.preprocess_train(X_train, y_train)\n",
        "valid = trans.preprocess_train(X_valid, y_valid)\n",
        "model = trans.get_classifier()\n",
        "mBertUncasedLearner = ktrain.get_learner(model, train_data=train,val_data=valid, batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmqNoW0A53_n",
        "outputId": "51dd7467-925c-4194-ec91-3aefe25b8cc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 3e-05...\n",
            "Epoch 1/15\n",
            "16/16 [==============================] - 64s 1s/step - loss: 1.0754 - accuracy: 0.2734 - val_loss: 0.8603 - val_accuracy: 0.7667\n",
            "Epoch 2/15\n",
            "16/16 [==============================] - 16s 991ms/step - loss: 1.0158 - accuracy: 0.3555 - val_loss: 0.8554 - val_accuracy: 0.6933\n",
            "Epoch 3/15\n",
            "16/16 [==============================] - 16s 1s/step - loss: 0.9386 - accuracy: 0.4766 - val_loss: 0.6905 - val_accuracy: 0.8133\n",
            "Epoch 4/15\n",
            "16/16 [==============================] - 16s 1s/step - loss: 0.9315 - accuracy: 0.5664 - val_loss: 0.6666 - val_accuracy: 0.7800\n",
            "Epoch 5/15\n",
            "16/16 [==============================] - 19s 1s/step - loss: 0.7629 - accuracy: 0.6836 - val_loss: 0.5602 - val_accuracy: 0.8333\n",
            "Epoch 6/15\n",
            "16/16 [==============================] - 17s 1s/step - loss: 0.7932 - accuracy: 0.6172 - val_loss: 0.6061 - val_accuracy: 0.7600\n",
            "Epoch 7/15\n",
            "16/16 [==============================] - 19s 1s/step - loss: 0.5816 - accuracy: 0.7969 - val_loss: 0.4302 - val_accuracy: 0.8733\n",
            "Epoch 8/15\n",
            "16/16 [==============================] - 17s 1s/step - loss: 0.3523 - accuracy: 0.8750 - val_loss: 0.3824 - val_accuracy: 0.9000\n",
            "Epoch 9/15\n",
            "16/16 [==============================] - 17s 1s/step - loss: 0.2448 - accuracy: 0.9219 - val_loss: 0.3535 - val_accuracy: 0.8933\n",
            "Epoch 10/15\n",
            "16/16 [==============================] - 19s 1s/step - loss: 0.2169 - accuracy: 0.9531 - val_loss: 0.3514 - val_accuracy: 0.9000\n",
            "Epoch 11/15\n",
            "16/16 [==============================] - 17s 1s/step - loss: 0.1397 - accuracy: 0.9766 - val_loss: 0.3380 - val_accuracy: 0.8933\n",
            "Epoch 12/15\n",
            "16/16 [==============================] - 17s 1s/step - loss: 0.1063 - accuracy: 0.9844 - val_loss: 0.3638 - val_accuracy: 0.8933\n",
            "Epoch 13/15\n",
            "16/16 [==============================] - 17s 1s/step - loss: 0.0671 - accuracy: 0.9961 - val_loss: 0.3615 - val_accuracy: 0.9000\n",
            "Epoch 14/15\n",
            "16/16 [==============================] - 17s 1s/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.3669 - val_accuracy: 0.9133\n",
            "Epoch 15/15\n",
            "16/16 [==============================] - 20s 1s/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.3710 - val_accuracy: 0.9067\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7abcd9683070>"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mBertUncasedLearner.fit_onecycle(3e-5,15, class_weight = weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JykVORpp53_n",
        "outputId": "ad37ef1c-e6f0-45f7-9781-364bcf2f8022"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 7s 622ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.97      0.94      0.96       120\n",
            "           2       0.68      0.83      0.75        23\n",
            "           3       0.67      0.57      0.62         7\n",
            "\n",
            "    accuracy                           0.91       150\n",
            "   macro avg       0.77      0.78      0.77       150\n",
            "weighted avg       0.91      0.91      0.91       150\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[113,   7,   0],\n",
              "       [  2,  19,   2],\n",
              "       [  1,   2,   4]])"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mBertUncasedLearner.validate(class_names=categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULLB0TN453_o"
      },
      "outputs": [],
      "source": [
        "predictor = ktrain.get_predictor(mBertUncasedLearner.model, preproc=trans)\n",
        "y_pred = predictor.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhN5WctCYBqL"
      },
      "outputs": [],
      "source": [
        "y_pred = np.array(y_pred).astype(int)\n",
        "predictor.save('/content/drive/MyDrive/Colab Notebooks/case/'+'TaskB'+'/taskbmBertUncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HP0N1b9YBqM"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import zipfile\n",
        "\n",
        "# Assuming Btest is your DataFrame with an \"index\" column and y_pred is your predicted labels\n",
        "# Replace y_pred with your actual predicted labels\n",
        "\n",
        "# Create a DataFrame with \"index\" and \"prediction\" columns\n",
        "submission_df = pd.DataFrame({\"index\": Btest[\"index\"].tolist(), \"prediction\": y_pred})\n",
        "\n",
        "# Sort the DataFrame based on the \"index\" column\n",
        "submission_df = submission_df.sort_values(by=\"index\")\n",
        "\n",
        "# Define the path to save the submission file\n",
        "submission_file_path = \"/content/submissionuncased.json\"\n",
        "\n",
        "# Save the DataFrame to a JSON file\n",
        "submission_df.to_json(submission_file_path, orient=\"records\", lines=True)\n",
        "\n",
        "# Zip the JSON file\n",
        "with zipfile.ZipFile(\"submission.zip\", \"w\") as zipf:\n",
        "    zipf.write(submission_file_path, arcname=\"submissionuncased.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1yjwWbH2nsO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4vNdf592ocr"
      },
      "source": [
        "# Hybrid Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw6EOtBr2ocs"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7geH8gB2ocu",
        "outputId": "4d404995-f705-4515-c8b8-a30e33b5c3b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.10/dist-packages (0.6.2)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (1.23.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (1.34.18)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (4.66.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (2023.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (2.1.0)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.18 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch_pretrained_bert) (1.34.18)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch_pretrained_bert) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.18->boto3->pytorch_pretrained_bert) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.1->pytorch_pretrained_bert) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.1->pytorch_pretrained_bert) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.18->boto3->pytorch_pretrained_bert) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pytorch_pretrained_bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4wvzdBf2ocw",
        "outputId": "9c9c85ef-05fa-424b-a199-9c53f7bba2d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_text in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (0.15.0)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msHp9S6D2ocy"
      },
      "source": [
        "## mBert + BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWXOBHrg2ocz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from tensorflow.keras.layers import Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sw1f-D4n2oc0"
      },
      "outputs": [],
      "source": [
        "bert_preprocess2 = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3\")\n",
        "bert_encoder2 = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQf9_FTr2oc1"
      },
      "outputs": [],
      "source": [
        "#BERT Layers\n",
        "text_input = Input(shape=(), dtype=tf.string, name='cleanText')\n",
        "preprocessed_text2 = bert_preprocess2(text_input)\n",
        "outputs2 = bert_encoder2(preprocessed_text2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBDaVEqZ2oc2"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Reshape, Bidirectional, LSTM, GlobalAveragePooling1D, GlobalMaxPooling1D, Dense, Dropout, Input, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "# BERT embeddings\n",
        "bert_embedding = outputs2['pooled_output']  # or 'sequence_output' based on your use case\n",
        "bert_embedding = Dropout(0.2)(bert_embedding)\n",
        "\n",
        "# Reshape BERT embeddings to a 3D tensor\n",
        "bert_embedding = Reshape((-1, 768))(bert_embedding)  # Replace 768 with the actual hidden size\n",
        "\n",
        "# Bidirectional LSTM layer\n",
        "lstm_output = Bidirectional(LSTM(64, return_sequences=True))(bert_embedding)\n",
        "\n",
        "# Pooling layers\n",
        "avg_pooling = GlobalAveragePooling1D()(lstm_output)\n",
        "max_pooling = GlobalMaxPooling1D()(lstm_output)\n",
        "\n",
        "# Concatenate and additional dense layers\n",
        "concat_output = concatenate([avg_pooling, max_pooling])\n",
        "dense_layer = Dense(128, activation='relu')(concat_output)\n",
        "dense_layer = Dropout(0.2)(dense_layer)\n",
        "\n",
        "# Additional Dense layer\n",
        "dense_layer_2 = Dense(64, activation='relu')(dense_layer)\n",
        "dense_layer_2 = Dropout(0.2)(dense_layer_2)\n",
        "\n",
        "# Output layer\n",
        "output_layer = Dense(3, activation='softmax')(dense_layer_2)\n",
        "\n",
        "# Connect the input and output layers to create the model\n",
        "model2 = Model(inputs=text_input, outputs=output_layer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUv5x0D12oc3"
      },
      "outputs": [],
      "source": [
        "num_classes = 3            #### change class number\n",
        "\n",
        "accuracy_threshold = 0.99\n",
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy')>accuracy_threshold):\n",
        "        print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
        "        self.model.stop_training = True\n",
        "\n",
        "acc_callback = myCallback()\n",
        "# Saved the Best Model\n",
        "filepath = \"/content/drive/MyDrive/Colab Notebooks/case/\" + \"hybrid1.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "# callback list\n",
        "callback_list = [acc_callback, checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNYcJVhg2oc4",
        "outputId": "00717753-84b5-4b77-9913-a89a1d545b97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " cleanText (InputLayer)      [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " keras_layer (KerasLayer)    {'input_type_ids': (None,    0         ['cleanText[0][0]']           \n",
            "                             128),                                                                \n",
            "                              'input_mask': (None, 128)                                           \n",
            "                             , 'input_word_ids': (None,                                           \n",
            "                              128)}                                                               \n",
            "                                                                                                  \n",
            " keras_layer_1 (KerasLayer)  {'encoder_outputs': [(None   1778534   ['keras_layer[0][0]',         \n",
            "                             , 128, 768),                 41         'keras_layer[0][1]',         \n",
            "                              (None, 128, 768),                      'keras_layer[0][2]']         \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768)],                                                  \n",
            "                              'sequence_output': (None,                                           \n",
            "                              128, 768),                                                          \n",
            "                              'default': (None, 768),                                             \n",
            "                              'pooled_output': (None, 7                                           \n",
            "                             68)}                                                                 \n",
            "                                                                                                  \n",
            " dropout_274 (Dropout)       (None, 768)                  0         ['keras_layer_1[0][13]']      \n",
            "                                                                                                  \n",
            " reshape (Reshape)           (None, 1, 768)               0         ['dropout_274[0][0]']         \n",
            "                                                                                                  \n",
            " bidirectional (Bidirection  (None, 1, 128)               426496    ['reshape[0][0]']             \n",
            " al)                                                                                              \n",
            "                                                                                                  \n",
            " global_average_pooling1d (  (None, 128)                  0         ['bidirectional[0][0]']       \n",
            " GlobalAveragePooling1D)                                                                          \n",
            "                                                                                                  \n",
            " global_max_pooling1d (Glob  (None, 128)                  0         ['bidirectional[0][0]']       \n",
            " alMaxPooling1D)                                                                                  \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 256)                  0         ['global_average_pooling1d[0][\n",
            "                                                                    0]',                          \n",
            "                                                                     'global_max_pooling1d[0][0]']\n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 128)                  32896     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_275 (Dropout)       (None, 128)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 64)                   8256      ['dropout_275[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_276 (Dropout)       (None, 64)                   0         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 3)                    195       ['dropout_276[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 178321284 (680.24 MB)\n",
            "Trainable params: 467843 (1.78 MB)\n",
            "Non-trainable params: 177853441 (678.46 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuBr8Vla2oc5"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.optimizers import AdamW\n",
        "# METRICS = [\n",
        "#       tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "#       tf.keras.metrics.Precision(name='precision'),\n",
        "#       tf.keras.metrics.Recall(name='recall')\n",
        "# ]\n",
        "\n",
        "# model2.compile(optimizer='adam',\n",
        "#               loss='sparse_categorical_crossentropy',\n",
        "#               metrics=METRICS)\n",
        "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fmKdebk2oc7",
        "outputId": "c9874bf0-c590-4643-e8d6-b5b097a9e4c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.0263 - accuracy: 0.5025\n",
            "Epoch 1: val_accuracy improved from -inf to 0.15333, saving model to /content/drive/MyDrive/Colab Notebooks/case/hybrid1.h5\n",
            "7/7 [==============================] - 41s 3s/step - loss: 1.0263 - accuracy: 0.5025 - val_loss: 1.1228 - val_accuracy: 0.1533\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.0151 - accuracy: 0.5127\n",
            "Epoch 2: val_accuracy did not improve from 0.15333\n",
            "7/7 [==============================] - 5s 782ms/step - loss: 1.0151 - accuracy: 0.5127 - val_loss: 0.9873 - val_accuracy: 0.1533\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9883 - accuracy: 0.5482\n",
            "Epoch 3: val_accuracy did not improve from 0.15333\n",
            "7/7 [==============================] - 5s 715ms/step - loss: 0.9883 - accuracy: 0.5482 - val_loss: 1.0190 - val_accuracy: 0.1533\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9992 - accuracy: 0.5127\n",
            "Epoch 4: val_accuracy did not improve from 0.15333\n",
            "7/7 [==============================] - 5s 715ms/step - loss: 0.9992 - accuracy: 0.5127 - val_loss: 1.0533 - val_accuracy: 0.1533\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9807 - accuracy: 0.5330\n",
            "Epoch 5: val_accuracy did not improve from 0.15333\n",
            "7/7 [==============================] - 4s 572ms/step - loss: 0.9807 - accuracy: 0.5330 - val_loss: 1.0354 - val_accuracy: 0.1533\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9999 - accuracy: 0.5330\n",
            "Epoch 6: val_accuracy did not improve from 0.15333\n",
            "7/7 [==============================] - 5s 718ms/step - loss: 0.9999 - accuracy: 0.5330 - val_loss: 1.0090 - val_accuracy: 0.1533\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9968 - accuracy: 0.4822\n",
            "Epoch 7: val_accuracy did not improve from 0.15333\n",
            "7/7 [==============================] - 5s 722ms/step - loss: 0.9968 - accuracy: 0.4822 - val_loss: 0.9909 - val_accuracy: 0.1533\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9923 - accuracy: 0.5279\n",
            "Epoch 8: val_accuracy did not improve from 0.15333\n",
            "7/7 [==============================] - 4s 578ms/step - loss: 0.9923 - accuracy: 0.5279 - val_loss: 1.0105 - val_accuracy: 0.1533\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9729 - accuracy: 0.5431\n",
            "Epoch 9: val_accuracy did not improve from 0.15333\n",
            "7/7 [==============================] - 5s 720ms/step - loss: 0.9729 - accuracy: 0.5431 - val_loss: 1.0206 - val_accuracy: 0.1533\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9822 - accuracy: 0.5279\n",
            "Epoch 10: val_accuracy did not improve from 0.15333\n",
            "7/7 [==============================] - 4s 591ms/step - loss: 0.9822 - accuracy: 0.5279 - val_loss: 0.9728 - val_accuracy: 0.1533\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9941 - accuracy: 0.5178\n",
            "Epoch 11: val_accuracy improved from 0.15333 to 0.20000, saving model to /content/drive/MyDrive/Colab Notebooks/case/hybrid1.h5\n",
            "7/7 [==============================] - 9s 1s/step - loss: 0.9941 - accuracy: 0.5178 - val_loss: 0.9236 - val_accuracy: 0.2000\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9731 - accuracy: 0.5279\n",
            "Epoch 12: val_accuracy did not improve from 0.20000\n",
            "7/7 [==============================] - 4s 601ms/step - loss: 0.9731 - accuracy: 0.5279 - val_loss: 0.9430 - val_accuracy: 0.1667\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9693 - accuracy: 0.5431\n",
            "Epoch 13: val_accuracy did not improve from 0.20000\n",
            "7/7 [==============================] - 4s 534ms/step - loss: 0.9693 - accuracy: 0.5431 - val_loss: 0.9317 - val_accuracy: 0.1800\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9528 - accuracy: 0.5381\n",
            "Epoch 14: val_accuracy improved from 0.20000 to 0.28667, saving model to /content/drive/MyDrive/Colab Notebooks/case/hybrid1.h5\n",
            "7/7 [==============================] - 10s 2s/step - loss: 0.9528 - accuracy: 0.5381 - val_loss: 0.9149 - val_accuracy: 0.2867\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9391 - accuracy: 0.5635\n",
            "Epoch 15: val_accuracy improved from 0.28667 to 0.78667, saving model to /content/drive/MyDrive/Colab Notebooks/case/hybrid1.h5\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.9391 - accuracy: 0.5635 - val_loss: 0.8597 - val_accuracy: 0.7867\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9487 - accuracy: 0.5076\n",
            "Epoch 16: val_accuracy did not improve from 0.78667\n",
            "7/7 [==============================] - 4s 553ms/step - loss: 0.9487 - accuracy: 0.5076 - val_loss: 0.8407 - val_accuracy: 0.7867\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9518 - accuracy: 0.5330\n",
            "Epoch 17: val_accuracy improved from 0.78667 to 0.86667, saving model to /content/drive/MyDrive/Colab Notebooks/case/hybrid1.h5\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.9518 - accuracy: 0.5330 - val_loss: 0.8033 - val_accuracy: 0.8667\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9428 - accuracy: 0.4822\n",
            "Epoch 18: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 4s 568ms/step - loss: 0.9428 - accuracy: 0.4822 - val_loss: 0.8615 - val_accuracy: 0.7733\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9316 - accuracy: 0.5787\n",
            "Epoch 19: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 5s 723ms/step - loss: 0.9316 - accuracy: 0.5787 - val_loss: 0.8180 - val_accuracy: 0.8000\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9291 - accuracy: 0.5431\n",
            "Epoch 20: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 5s 717ms/step - loss: 0.9291 - accuracy: 0.5431 - val_loss: 0.7648 - val_accuracy: 0.8333\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9057 - accuracy: 0.5381\n",
            "Epoch 21: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 4s 546ms/step - loss: 0.9057 - accuracy: 0.5381 - val_loss: 0.7586 - val_accuracy: 0.8200\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9159 - accuracy: 0.5482\n",
            "Epoch 22: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 4s 622ms/step - loss: 0.9159 - accuracy: 0.5482 - val_loss: 0.7668 - val_accuracy: 0.8200\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8831 - accuracy: 0.5888\n",
            "Epoch 23: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 4s 566ms/step - loss: 0.8831 - accuracy: 0.5888 - val_loss: 0.7537 - val_accuracy: 0.8067\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9116 - accuracy: 0.5431\n",
            "Epoch 24: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 5s 769ms/step - loss: 0.9116 - accuracy: 0.5431 - val_loss: 0.7338 - val_accuracy: 0.8067\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8526 - accuracy: 0.6193\n",
            "Epoch 25: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 4s 605ms/step - loss: 0.8526 - accuracy: 0.6193 - val_loss: 0.6989 - val_accuracy: 0.8067\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8376 - accuracy: 0.6091\n",
            "Epoch 26: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 4s 563ms/step - loss: 0.8376 - accuracy: 0.6091 - val_loss: 0.5890 - val_accuracy: 0.8533\n",
            "Epoch 27/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8927 - accuracy: 0.5482\n",
            "Epoch 27: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 5s 715ms/step - loss: 0.8927 - accuracy: 0.5482 - val_loss: 0.6416 - val_accuracy: 0.7867\n",
            "Epoch 28/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8147 - accuracy: 0.5787\n",
            "Epoch 28: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 4s 621ms/step - loss: 0.8147 - accuracy: 0.5787 - val_loss: 0.8138 - val_accuracy: 0.7800\n",
            "Epoch 29/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8281 - accuracy: 0.6193\n",
            "Epoch 29: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 4s 546ms/step - loss: 0.8281 - accuracy: 0.6193 - val_loss: 0.6856 - val_accuracy: 0.7800\n",
            "Epoch 30/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7847 - accuracy: 0.6091\n",
            "Epoch 30: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 5s 723ms/step - loss: 0.7847 - accuracy: 0.6091 - val_loss: 0.6820 - val_accuracy: 0.7867\n",
            "Epoch 31/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8127 - accuracy: 0.6091\n",
            "Epoch 31: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 5s 791ms/step - loss: 0.8127 - accuracy: 0.6091 - val_loss: 0.5805 - val_accuracy: 0.8467\n",
            "Epoch 32/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7832 - accuracy: 0.6497\n",
            "Epoch 32: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 5s 712ms/step - loss: 0.7832 - accuracy: 0.6497 - val_loss: 0.6093 - val_accuracy: 0.8200\n",
            "Epoch 33/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7242 - accuracy: 0.6954\n",
            "Epoch 33: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 5s 757ms/step - loss: 0.7242 - accuracy: 0.6954 - val_loss: 0.5810 - val_accuracy: 0.8267\n",
            "Epoch 34/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7583 - accuracy: 0.6599\n",
            "Epoch 34: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 5s 721ms/step - loss: 0.7583 - accuracy: 0.6599 - val_loss: 0.5747 - val_accuracy: 0.8133\n",
            "Epoch 35/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7694 - accuracy: 0.6599\n",
            "Epoch 35: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 5s 720ms/step - loss: 0.7694 - accuracy: 0.6599 - val_loss: 0.5353 - val_accuracy: 0.8000\n",
            "Epoch 36/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7964 - accuracy: 0.6294\n",
            "Epoch 36: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 4s 641ms/step - loss: 0.7964 - accuracy: 0.6294 - val_loss: 0.6521 - val_accuracy: 0.8267\n",
            "Epoch 37/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6889 - accuracy: 0.7056\n",
            "Epoch 37: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 4s 553ms/step - loss: 0.6889 - accuracy: 0.7056 - val_loss: 0.6205 - val_accuracy: 0.8133\n",
            "Epoch 38/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7019 - accuracy: 0.6802\n",
            "Epoch 38: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 4s 550ms/step - loss: 0.7019 - accuracy: 0.6802 - val_loss: 0.6354 - val_accuracy: 0.8000\n",
            "Epoch 39/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7139 - accuracy: 0.6751\n",
            "Epoch 39: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 4s 640ms/step - loss: 0.7139 - accuracy: 0.6751 - val_loss: 0.5947 - val_accuracy: 0.8267\n",
            "Epoch 40/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7807 - accuracy: 0.6599\n",
            "Epoch 40: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 4s 544ms/step - loss: 0.7807 - accuracy: 0.6599 - val_loss: 0.5501 - val_accuracy: 0.8133\n",
            "Epoch 41/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6379 - accuracy: 0.7208\n",
            "Epoch 41: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 4s 550ms/step - loss: 0.6379 - accuracy: 0.7208 - val_loss: 0.6517 - val_accuracy: 0.7933\n",
            "Epoch 42/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6540 - accuracy: 0.7157\n",
            "Epoch 42: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 4s 608ms/step - loss: 0.6540 - accuracy: 0.7157 - val_loss: 0.6441 - val_accuracy: 0.8067\n",
            "Epoch 43/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5974 - accuracy: 0.7563\n",
            "Epoch 43: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 4s 541ms/step - loss: 0.5974 - accuracy: 0.7563 - val_loss: 0.5188 - val_accuracy: 0.8133\n",
            "Epoch 44/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6196 - accuracy: 0.7411\n",
            "Epoch 44: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 4s 544ms/step - loss: 0.6196 - accuracy: 0.7411 - val_loss: 0.5327 - val_accuracy: 0.8067\n",
            "Epoch 45/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5662 - accuracy: 0.7513\n",
            "Epoch 45: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 5s 737ms/step - loss: 0.5662 - accuracy: 0.7513 - val_loss: 0.5893 - val_accuracy: 0.8067\n",
            "Epoch 46/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5983 - accuracy: 0.7208\n",
            "Epoch 46: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 4s 542ms/step - loss: 0.5983 - accuracy: 0.7208 - val_loss: 0.5605 - val_accuracy: 0.7867\n",
            "Epoch 47/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6088 - accuracy: 0.7259\n",
            "Epoch 47: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 4s 538ms/step - loss: 0.6088 - accuracy: 0.7259 - val_loss: 0.6194 - val_accuracy: 0.7800\n",
            "Epoch 48/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6233 - accuracy: 0.7310\n",
            "Epoch 48: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 4s 603ms/step - loss: 0.6233 - accuracy: 0.7310 - val_loss: 0.7329 - val_accuracy: 0.7867\n",
            "Epoch 49/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6814 - accuracy: 0.7157\n",
            "Epoch 49: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 5s 713ms/step - loss: 0.6814 - accuracy: 0.7157 - val_loss: 0.5862 - val_accuracy: 0.7733\n",
            "Epoch 50/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5617 - accuracy: 0.7563\n",
            "Epoch 50: val_accuracy did not improve from 0.86667\n",
            "7/7 [==============================] - 5s 717ms/step - loss: 0.5617 - accuracy: 0.7563 - val_loss: 0.6286 - val_accuracy: 0.7867\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78458f181900>"
            ]
          },
          "execution_count": 179,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2.fit(X_train, y_train, epochs=50, validation_data = (X_valid, y_valid), verbose = 1, callbacks = callback_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDM56QNO2oc7",
        "outputId": "ff4c362b-8802-4484-9e41-b768ba9b293f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 4s 304ms/step - loss: 0.8033 - accuracy: 0.8667\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.8032849431037903, 0.8666666746139526]"
            ]
          },
          "execution_count": 180,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import Layer  # Assuming KerasLayer is a subclass of Layer\n",
        "import tensorflow_hub as hub\n",
        "# Define the custom_objects dictionary\n",
        "custom_objects = {'KerasLayer': hub.KerasLayer}\n",
        "\n",
        "# Load the model with the custom_objects parameter\n",
        "loaded_model = load_model(filepath, custom_objects=custom_objects)\n",
        "\n",
        "# Continue with your evaluation or any other operations\n",
        "loaded_model.evaluate(X_valid, y_valid)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1i0f7U12oc8",
        "outputId": "ddd9f146-772a-42ed-b459-5992c8e23ebe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 3s 260ms/step\n",
            "F1-Score: 54.4191332196911\n",
            "Accuracy: 86.66666666666667\n"
          ]
        }
      ],
      "source": [
        "y_pred = np.argmax(loaded_model.predict(X_valid), axis=-1)\n",
        "\n",
        "print(\"F1-Score:\",f1_score(Bval['enc_label'],y_pred,average='macro')*100)\n",
        "print(\"Accuracy:\",accuracy_score(Bval['enc_label'],y_pred)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIyheL6b2oc8",
        "outputId": "00c37e5d-0229-4179-c6ce-93d09f7b67bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 2s 377ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9328    0.9250    0.9289       120\n",
            "           1     0.6129    0.8261    0.7037        23\n",
            "           2     0.0000    0.0000    0.0000         7\n",
            "\n",
            "    accuracy                         0.8667       150\n",
            "   macro avg     0.5152    0.5837    0.5442       150\n",
            "weighted avg     0.8402    0.8667    0.8510       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(X_valid)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report = classification_report(Bval['enc_label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHUtLU4h2oc9",
        "outputId": "b8c72412-7bc3-4d7d-cff1-dac754b656b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 2s 375ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9262    0.9339    0.9300       121\n",
            "           1     0.5714    0.6957    0.6275        23\n",
            "           2     0.0000    0.0000    0.0000         6\n",
            "\n",
            "    accuracy                         0.8600       150\n",
            "   macro avg     0.4992    0.5432    0.5192       150\n",
            "weighted avg     0.8348    0.8600    0.8464       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report = classification_report(Btest['enc_label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPQujpwO2oc9"
      },
      "source": [
        "## BiLSTM + CNN + mBERT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UpBW3ur2oc-"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Reshape, Bidirectional, LSTM, GlobalAveragePooling1D, GlobalMaxPooling1D, Dense, Dropout, Input, concatenate, Conv1D, MaxPooling1D, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# BERT embeddings\n",
        "bert_embedding = outputs2['pooled_output']  # or 'sequence_output' based on your use case\n",
        "bert_embedding = Dropout(0.2)(bert_embedding)\n",
        "\n",
        "# Reshape BERT embeddings to a 3D tensor\n",
        "bert_embedding = Reshape((-1, 768))(bert_embedding)  # Replace 768 with the actual hidden size\n",
        "\n",
        "# Bidirectional LSTM layer\n",
        "lstm_output = Bidirectional(LSTM(64, return_sequences=True))(bert_embedding)\n",
        "\n",
        "# Convolutional Neural Network (CNN) layer\n",
        "num_filters = 64\n",
        "filter_size = 3\n",
        "conv_output = Conv1D(num_filters, filter_size, activation='relu', padding='same')(lstm_output)\n",
        "pooling_output = GlobalMaxPooling1D()(conv_output)\n",
        "\n",
        "# Pooling layers\n",
        "avg_pooling = GlobalAveragePooling1D()(lstm_output)\n",
        "max_pooling = GlobalMaxPooling1D()(lstm_output)\n",
        "\n",
        "# Concatenate and additional dense layers\n",
        "concat_output = concatenate([avg_pooling, max_pooling, pooling_output])\n",
        "dense_layer = Dense(128, activation='relu')(concat_output)\n",
        "dense_layer = Dropout(0.2)(dense_layer)\n",
        "\n",
        "# Additional Dense layer\n",
        "dense_layer_2 = Dense(64, activation='relu')(dense_layer)\n",
        "dense_layer_2 = Dropout(0.2)(dense_layer_2)\n",
        "\n",
        "# Output layer\n",
        "output_layer = Dense(3, activation='softmax')(dense_layer_2)\n",
        "\n",
        "# Connect the input and output layers to create the model\n",
        "model2 = Model(inputs=text_input, outputs=output_layer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_HXeNaa2oc-",
        "outputId": "810c4546-9fac-4a3f-f64a-c951e378f1ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " cleanText (InputLayer)      [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " keras_layer (KerasLayer)    {'input_type_ids': (None,    0         ['cleanText[0][0]']           \n",
            "                             128),                                                                \n",
            "                              'input_mask': (None, 128)                                           \n",
            "                             , 'input_word_ids': (None,                                           \n",
            "                              128)}                                                               \n",
            "                                                                                                  \n",
            " keras_layer_1 (KerasLayer)  {'encoder_outputs': [(None   1778534   ['keras_layer[0][0]',         \n",
            "                             , 128, 768),                 41         'keras_layer[0][1]',         \n",
            "                              (None, 128, 768),                      'keras_layer[0][2]']         \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768)],                                                  \n",
            "                              'sequence_output': (None,                                           \n",
            "                              128, 768),                                                          \n",
            "                              'default': (None, 768),                                             \n",
            "                              'pooled_output': (None, 7                                           \n",
            "                             68)}                                                                 \n",
            "                                                                                                  \n",
            " dropout_277 (Dropout)       (None, 768)                  0         ['keras_layer_1[0][13]']      \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)         (None, 1, 768)               0         ['dropout_277[0][0]']         \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirecti  (None, 1, 128)               426496    ['reshape_1[0][0]']           \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)             (None, 1, 64)                24640     ['bidirectional_1[0][0]']     \n",
            "                                                                                                  \n",
            " global_average_pooling1d_1  (None, 128)                  0         ['bidirectional_1[0][0]']     \n",
            "  (GlobalAveragePooling1D)                                                                        \n",
            "                                                                                                  \n",
            " global_max_pooling1d_2 (Gl  (None, 128)                  0         ['bidirectional_1[0][0]']     \n",
            " obalMaxPooling1D)                                                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Gl  (None, 64)                   0         ['conv1d[0][0]']              \n",
            " obalMaxPooling1D)                                                                                \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 320)                  0         ['global_average_pooling1d_1[0\n",
            " )                                                                  ][0]',                        \n",
            "                                                                     'global_max_pooling1d_2[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'global_max_pooling1d_1[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 128)                  41088     ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_278 (Dropout)       (None, 128)                  0         ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 64)                   8256      ['dropout_278[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_279 (Dropout)       (None, 64)                   0         ['dense_4[0][0]']             \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 3)                    195       ['dropout_279[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 178354116 (680.37 MB)\n",
            "Trainable params: 500675 (1.91 MB)\n",
            "Non-trainable params: 177853441 (678.46 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENYXnle_2oc_"
      },
      "outputs": [],
      "source": [
        "num_classes = 3            #### change class number\n",
        "\n",
        "accuracy_threshold = 0.99\n",
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy')>accuracy_threshold):\n",
        "        print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
        "        self.model.stop_training = True\n",
        "\n",
        "acc_callback = myCallback()\n",
        "# Saved the Best Model\n",
        "filepath = \"/content/drive/MyDrive/Colab Notebooks/case/\" + \"hybrid2.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "# callback list\n",
        "callback_list = [acc_callback, checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nHBwYsM2oc_",
        "outputId": "5f9fa136-b167-40de-e356-b991c7aabc15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.0605 - accuracy: 0.4924\n",
            "Epoch 1: val_accuracy improved from -inf to 0.15333, saving model to /content/drive/MyDrive/Colab Notebooks/case/hybrid2.h5\n",
            "7/7 [==============================] - 39s 3s/step - loss: 1.0605 - accuracy: 0.4924 - val_loss: 1.2078 - val_accuracy: 0.1533\n",
            "Epoch 2/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.0119 - accuracy: 0.5330\n",
            "Epoch 2: val_accuracy did not improve from 0.15333\n",
            "7/7 [==============================] - 5s 724ms/step - loss: 1.0119 - accuracy: 0.5330 - val_loss: 1.0296 - val_accuracy: 0.1533\n",
            "Epoch 3/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.0120 - accuracy: 0.4873\n",
            "Epoch 3: val_accuracy did not improve from 0.15333\n",
            "7/7 [==============================] - 4s 554ms/step - loss: 1.0120 - accuracy: 0.4873 - val_loss: 1.0530 - val_accuracy: 0.1533\n",
            "Epoch 4/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9839 - accuracy: 0.5228\n",
            "Epoch 4: val_accuracy did not improve from 0.15333\n",
            "7/7 [==============================] - 5s 719ms/step - loss: 0.9839 - accuracy: 0.5228 - val_loss: 1.0174 - val_accuracy: 0.1533\n",
            "Epoch 5/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9881 - accuracy: 0.5330\n",
            "Epoch 5: val_accuracy did not improve from 0.15333\n",
            "7/7 [==============================] - 5s 777ms/step - loss: 0.9881 - accuracy: 0.5330 - val_loss: 1.0204 - val_accuracy: 0.1533\n",
            "Epoch 6/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9791 - accuracy: 0.5431\n",
            "Epoch 6: val_accuracy did not improve from 0.15333\n",
            "7/7 [==============================] - 5s 807ms/step - loss: 0.9791 - accuracy: 0.5431 - val_loss: 1.0645 - val_accuracy: 0.1533\n",
            "Epoch 7/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9981 - accuracy: 0.5279\n",
            "Epoch 7: val_accuracy did not improve from 0.15333\n",
            "7/7 [==============================] - 4s 565ms/step - loss: 0.9981 - accuracy: 0.5279 - val_loss: 1.0810 - val_accuracy: 0.1533\n",
            "Epoch 8/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9776 - accuracy: 0.5381\n",
            "Epoch 8: val_accuracy did not improve from 0.15333\n",
            "7/7 [==============================] - 5s 722ms/step - loss: 0.9776 - accuracy: 0.5381 - val_loss: 1.0528 - val_accuracy: 0.1533\n",
            "Epoch 9/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.0028 - accuracy: 0.4772\n",
            "Epoch 9: val_accuracy did not improve from 0.15333\n",
            "7/7 [==============================] - 5s 718ms/step - loss: 1.0028 - accuracy: 0.4772 - val_loss: 1.0074 - val_accuracy: 0.1533\n",
            "Epoch 10/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 1.0035 - accuracy: 0.5076\n",
            "Epoch 10: val_accuracy did not improve from 0.15333\n",
            "7/7 [==============================] - 5s 715ms/step - loss: 1.0035 - accuracy: 0.5076 - val_loss: 0.9646 - val_accuracy: 0.1533\n",
            "Epoch 11/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9826 - accuracy: 0.5482\n",
            "Epoch 11: val_accuracy did not improve from 0.15333\n",
            "7/7 [==============================] - 5s 752ms/step - loss: 0.9826 - accuracy: 0.5482 - val_loss: 0.9678 - val_accuracy: 0.1533\n",
            "Epoch 12/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9680 - accuracy: 0.5381\n",
            "Epoch 12: val_accuracy did not improve from 0.15333\n",
            "7/7 [==============================] - 5s 713ms/step - loss: 0.9680 - accuracy: 0.5381 - val_loss: 1.0039 - val_accuracy: 0.1533\n",
            "Epoch 13/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9922 - accuracy: 0.5279\n",
            "Epoch 13: val_accuracy did not improve from 0.15333\n",
            "7/7 [==============================] - 4s 539ms/step - loss: 0.9922 - accuracy: 0.5279 - val_loss: 1.0216 - val_accuracy: 0.1533\n",
            "Epoch 14/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9911 - accuracy: 0.5127\n",
            "Epoch 14: val_accuracy did not improve from 0.15333\n",
            "7/7 [==============================] - 4s 614ms/step - loss: 0.9911 - accuracy: 0.5127 - val_loss: 0.9896 - val_accuracy: 0.1533\n",
            "Epoch 15/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9609 - accuracy: 0.5330\n",
            "Epoch 15: val_accuracy did not improve from 0.15333\n",
            "7/7 [==============================] - 4s 543ms/step - loss: 0.9609 - accuracy: 0.5330 - val_loss: 0.9515 - val_accuracy: 0.1533\n",
            "Epoch 16/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9766 - accuracy: 0.5025\n",
            "Epoch 16: val_accuracy did not improve from 0.15333\n",
            "7/7 [==============================] - 4s 544ms/step - loss: 0.9766 - accuracy: 0.5025 - val_loss: 0.9395 - val_accuracy: 0.1533\n",
            "Epoch 17/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9476 - accuracy: 0.5076\n",
            "Epoch 17: val_accuracy did not improve from 0.15333\n",
            "7/7 [==============================] - 4s 578ms/step - loss: 0.9476 - accuracy: 0.5076 - val_loss: 0.9552 - val_accuracy: 0.1533\n",
            "Epoch 18/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9647 - accuracy: 0.4873\n",
            "Epoch 18: val_accuracy improved from 0.15333 to 0.28000, saving model to /content/drive/MyDrive/Colab Notebooks/case/hybrid2.h5\n",
            "7/7 [==============================] - 11s 2s/step - loss: 0.9647 - accuracy: 0.4873 - val_loss: 0.9230 - val_accuracy: 0.2800\n",
            "Epoch 19/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9406 - accuracy: 0.5381\n",
            "Epoch 19: val_accuracy improved from 0.28000 to 0.69333, saving model to /content/drive/MyDrive/Colab Notebooks/case/hybrid2.h5\n",
            "7/7 [==============================] - 10s 2s/step - loss: 0.9406 - accuracy: 0.5381 - val_loss: 0.8841 - val_accuracy: 0.6933\n",
            "Epoch 20/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9217 - accuracy: 0.5431\n",
            "Epoch 20: val_accuracy did not improve from 0.69333\n",
            "7/7 [==============================] - 4s 546ms/step - loss: 0.9217 - accuracy: 0.5431 - val_loss: 0.9610 - val_accuracy: 0.1800\n",
            "Epoch 21/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9177 - accuracy: 0.5990\n",
            "Epoch 21: val_accuracy improved from 0.69333 to 0.80667, saving model to /content/drive/MyDrive/Colab Notebooks/case/hybrid2.h5\n",
            "7/7 [==============================] - 10s 2s/step - loss: 0.9177 - accuracy: 0.5990 - val_loss: 0.8066 - val_accuracy: 0.8067\n",
            "Epoch 22/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9001 - accuracy: 0.5685\n",
            "Epoch 22: val_accuracy did not improve from 0.80667\n",
            "7/7 [==============================] - 4s 541ms/step - loss: 0.9001 - accuracy: 0.5685 - val_loss: 0.8249 - val_accuracy: 0.8000\n",
            "Epoch 23/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9163 - accuracy: 0.5228\n",
            "Epoch 23: val_accuracy improved from 0.80667 to 0.81333, saving model to /content/drive/MyDrive/Colab Notebooks/case/hybrid2.h5\n",
            "7/7 [==============================] - 17s 3s/step - loss: 0.9163 - accuracy: 0.5228 - val_loss: 0.7774 - val_accuracy: 0.8133\n",
            "Epoch 24/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9309 - accuracy: 0.5228\n",
            "Epoch 24: val_accuracy did not improve from 0.81333\n",
            "7/7 [==============================] - 5s 767ms/step - loss: 0.9309 - accuracy: 0.5228 - val_loss: 0.7690 - val_accuracy: 0.8067\n",
            "Epoch 25/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.9070 - accuracy: 0.5635\n",
            "Epoch 25: val_accuracy did not improve from 0.81333\n",
            "7/7 [==============================] - 5s 751ms/step - loss: 0.9070 - accuracy: 0.5635 - val_loss: 0.8599 - val_accuracy: 0.7733\n",
            "Epoch 26/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8437 - accuracy: 0.5838\n",
            "Epoch 26: val_accuracy did not improve from 0.81333\n",
            "7/7 [==============================] - 5s 760ms/step - loss: 0.8437 - accuracy: 0.5838 - val_loss: 0.8018 - val_accuracy: 0.8067\n",
            "Epoch 27/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8708 - accuracy: 0.5685\n",
            "Epoch 27: val_accuracy did not improve from 0.81333\n",
            "7/7 [==============================] - 6s 847ms/step - loss: 0.8708 - accuracy: 0.5685 - val_loss: 0.7094 - val_accuracy: 0.7733\n",
            "Epoch 28/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8139 - accuracy: 0.6497\n",
            "Epoch 28: val_accuracy did not improve from 0.81333\n",
            "7/7 [==============================] - 5s 717ms/step - loss: 0.8139 - accuracy: 0.6497 - val_loss: 0.7235 - val_accuracy: 0.7933\n",
            "Epoch 29/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8463 - accuracy: 0.5990\n",
            "Epoch 29: val_accuracy did not improve from 0.81333\n",
            "7/7 [==============================] - 5s 723ms/step - loss: 0.8463 - accuracy: 0.5990 - val_loss: 0.6332 - val_accuracy: 0.8000\n",
            "Epoch 30/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7822 - accuracy: 0.6345\n",
            "Epoch 30: val_accuracy did not improve from 0.81333\n",
            "7/7 [==============================] - 5s 722ms/step - loss: 0.7822 - accuracy: 0.6345 - val_loss: 0.6465 - val_accuracy: 0.8067\n",
            "Epoch 31/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8196 - accuracy: 0.5787\n",
            "Epoch 31: val_accuracy did not improve from 0.81333\n",
            "7/7 [==============================] - 5s 714ms/step - loss: 0.8196 - accuracy: 0.5787 - val_loss: 0.6694 - val_accuracy: 0.7867\n",
            "Epoch 32/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8459 - accuracy: 0.5888\n",
            "Epoch 32: val_accuracy did not improve from 0.81333\n",
            "7/7 [==============================] - 5s 745ms/step - loss: 0.8459 - accuracy: 0.5888 - val_loss: 0.6868 - val_accuracy: 0.8000\n",
            "Epoch 33/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7476 - accuracy: 0.6701\n",
            "Epoch 33: val_accuracy did not improve from 0.81333\n",
            "7/7 [==============================] - 4s 541ms/step - loss: 0.7476 - accuracy: 0.6701 - val_loss: 0.6987 - val_accuracy: 0.7867\n",
            "Epoch 34/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7564 - accuracy: 0.6701\n",
            "Epoch 34: val_accuracy did not improve from 0.81333\n",
            "7/7 [==============================] - 5s 712ms/step - loss: 0.7564 - accuracy: 0.6701 - val_loss: 0.5831 - val_accuracy: 0.8133\n",
            "Epoch 35/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7720 - accuracy: 0.6396\n",
            "Epoch 35: val_accuracy improved from 0.81333 to 0.82000, saving model to /content/drive/MyDrive/Colab Notebooks/case/hybrid2.h5\n",
            "7/7 [==============================] - 13s 2s/step - loss: 0.7720 - accuracy: 0.6396 - val_loss: 0.5572 - val_accuracy: 0.8200\n",
            "Epoch 36/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7751 - accuracy: 0.6345\n",
            "Epoch 36: val_accuracy did not improve from 0.82000\n",
            "7/7 [==============================] - 5s 710ms/step - loss: 0.7751 - accuracy: 0.6345 - val_loss: 0.7246 - val_accuracy: 0.7933\n",
            "Epoch 37/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7076 - accuracy: 0.6853\n",
            "Epoch 37: val_accuracy did not improve from 0.82000\n",
            "7/7 [==============================] - 4s 536ms/step - loss: 0.7076 - accuracy: 0.6853 - val_loss: 0.6430 - val_accuracy: 0.7733\n",
            "Epoch 38/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7176 - accuracy: 0.7208\n",
            "Epoch 38: val_accuracy did not improve from 0.82000\n",
            "7/7 [==============================] - 4s 589ms/step - loss: 0.7176 - accuracy: 0.7208 - val_loss: 0.5203 - val_accuracy: 0.8133\n",
            "Epoch 39/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7042 - accuracy: 0.6701\n",
            "Epoch 39: val_accuracy did not improve from 0.82000\n",
            "7/7 [==============================] - 4s 539ms/step - loss: 0.7042 - accuracy: 0.6701 - val_loss: 0.5657 - val_accuracy: 0.8133\n",
            "Epoch 40/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.8054 - accuracy: 0.6599\n",
            "Epoch 40: val_accuracy did not improve from 0.82000\n",
            "7/7 [==============================] - 5s 715ms/step - loss: 0.8054 - accuracy: 0.6599 - val_loss: 0.6435 - val_accuracy: 0.7800\n",
            "Epoch 41/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6894 - accuracy: 0.6802\n",
            "Epoch 41: val_accuracy did not improve from 0.82000\n",
            "7/7 [==============================] - 5s 762ms/step - loss: 0.6894 - accuracy: 0.6802 - val_loss: 0.5398 - val_accuracy: 0.8133\n",
            "Epoch 42/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6921 - accuracy: 0.6853\n",
            "Epoch 42: val_accuracy did not improve from 0.82000\n",
            "7/7 [==============================] - 5s 746ms/step - loss: 0.6921 - accuracy: 0.6853 - val_loss: 0.5603 - val_accuracy: 0.8000\n",
            "Epoch 43/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.7006 - accuracy: 0.6954\n",
            "Epoch 43: val_accuracy did not improve from 0.82000\n",
            "7/7 [==============================] - 4s 665ms/step - loss: 0.7006 - accuracy: 0.6954 - val_loss: 0.6071 - val_accuracy: 0.8067\n",
            "Epoch 44/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6184 - accuracy: 0.7360\n",
            "Epoch 44: val_accuracy did not improve from 0.82000\n",
            "7/7 [==============================] - 5s 685ms/step - loss: 0.6184 - accuracy: 0.7360 - val_loss: 0.5681 - val_accuracy: 0.8067\n",
            "Epoch 45/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5939 - accuracy: 0.7513\n",
            "Epoch 45: val_accuracy did not improve from 0.82000\n",
            "7/7 [==============================] - 5s 779ms/step - loss: 0.5939 - accuracy: 0.7513 - val_loss: 0.5547 - val_accuracy: 0.8000\n",
            "Epoch 46/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6698 - accuracy: 0.6853\n",
            "Epoch 46: val_accuracy did not improve from 0.82000\n",
            "7/7 [==============================] - 5s 807ms/step - loss: 0.6698 - accuracy: 0.6853 - val_loss: 0.5890 - val_accuracy: 0.8000\n",
            "Epoch 47/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6117 - accuracy: 0.7208\n",
            "Epoch 47: val_accuracy did not improve from 0.82000\n",
            "7/7 [==============================] - 4s 538ms/step - loss: 0.6117 - accuracy: 0.7208 - val_loss: 0.6705 - val_accuracy: 0.7933\n",
            "Epoch 48/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6418 - accuracy: 0.7411\n",
            "Epoch 48: val_accuracy did not improve from 0.82000\n",
            "7/7 [==============================] - 4s 576ms/step - loss: 0.6418 - accuracy: 0.7411 - val_loss: 0.6351 - val_accuracy: 0.8000\n",
            "Epoch 49/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6868 - accuracy: 0.7056\n",
            "Epoch 49: val_accuracy did not improve from 0.82000\n",
            "7/7 [==============================] - 4s 532ms/step - loss: 0.6868 - accuracy: 0.7056 - val_loss: 0.6109 - val_accuracy: 0.7933\n",
            "Epoch 50/50\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5808 - accuracy: 0.7817\n",
            "Epoch 50: val_accuracy did not improve from 0.82000\n",
            "7/7 [==============================] - 4s 579ms/step - loss: 0.5808 - accuracy: 0.7817 - val_loss: 0.7214 - val_accuracy: 0.7467\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78469a1860e0>"
            ]
          },
          "execution_count": 187,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model2.fit(X_train, y_train, epochs=50, validation_data = (X_valid, y_valid), verbose = 1, callbacks = callback_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvoRf89-2oc_",
        "outputId": "382abbd8-7752-4f67-b32f-aae29cd83a35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 5s 348ms/step - loss: 0.5572 - accuracy: 0.8200\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.557159960269928, 0.8199999928474426]"
            ]
          },
          "execution_count": 192,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import Layer  # Assuming KerasLayer is a subclass of Layer\n",
        "import tensorflow_hub as hub\n",
        "# Define the custom_objects dictionary\n",
        "custom_objects = {'KerasLayer': hub.KerasLayer}\n",
        "\n",
        "# Load the model with the custom_objects parameter\n",
        "loaded_model = load_model(filepath, custom_objects=custom_objects)\n",
        "\n",
        "# Continue with your evaluation or any other operations\n",
        "loaded_model.evaluate(X_valid, y_valid)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Dw1ka592odA",
        "outputId": "52aff0b0-7cb5-41f7-869c-f43cf6a24483"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 4s 355ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8800    0.9167    0.8980       120\n",
            "           1     0.5200    0.5652    0.5417        23\n",
            "           2     0.0000    0.0000    0.0000         7\n",
            "\n",
            "    accuracy                         0.8200       150\n",
            "   macro avg     0.4667    0.4940    0.4799       150\n",
            "weighted avg     0.7837    0.8200    0.8014       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(X_valid)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report = classification_report(Bval['enc_label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yppS8Vu52odB",
        "outputId": "1f7f090d-7c10-4016-d724-558fd771819b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 2s 410ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9120    0.9421    0.9268       121\n",
            "           1     0.6250    0.6522    0.6383        23\n",
            "           2     1.0000    0.1667    0.2857         6\n",
            "\n",
            "    accuracy                         0.8667       150\n",
            "   macro avg     0.8457    0.5870    0.6169       150\n",
            "weighted avg     0.8715    0.8667    0.8569       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report = classification_report(Btest['enc_label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn1BsHIv6BtF"
      },
      "source": [
        "# After Random Oversampling the samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ifO6ZmsYBpw"
      },
      "source": [
        "# Handle Imbalance Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6tMljjQYBpw"
      },
      "source": [
        "## Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "8pQlNCL-YBpw"
      },
      "outputs": [],
      "source": [
        "# Class count\n",
        "count_class_2, count_class_1, class_count_3 = Btrain.label.value_counts()\n",
        "\n",
        "# Divide by class\n",
        "df_class_1 = Btrain[Btrain['label'] == 1]\n",
        "df_class_2 = Btrain[Btrain['label'] == 2]\n",
        "df_class_3 = Btrain[Btrain['label'] == 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8WHYWBxfwdw",
        "outputId": "6bcbbb4f-95b5-4cef-f66f-08f92efdb395"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105, 61, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "count_class_2, count_class_1, class_count_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8-4T0J2-YBpw",
        "outputId": "e4a72e87-477c-477c-d36c-05ad34146fc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random over-sampling:\n",
            "1    105\n",
            "2    105\n",
            "3    105\n",
            "Name: label, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "df_class_1_over = df_class_1.sample(105, replace=True, random_state = 42)\n",
        "df_class_3_over = df_class_3.sample(105, replace=True, random_state = 42)\n",
        "\n",
        "Btrain_over = pd.concat([df_class_1_over, df_class_2, df_class_3_over], axis=0)\n",
        "\n",
        "print('Random over-sampling:')\n",
        "print(Btrain_over.label.value_counts())\n",
        "\n",
        "Btrain_over.label.value_counts().plot(kind='bar', title='Count (label)');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "mx1sO_2XDZlO"
      },
      "outputs": [],
      "source": [
        "# from collections import Counter\n",
        "\n",
        "# # Assuming Btrain['cleanText'] is a list or pandas Series\n",
        "# text_samples = Btrain['cleanText']\n",
        "# labels = Btrain['label']\n",
        "\n",
        "# # Use Counter to count the frequency of each sample\n",
        "# sample_frequency = Counter(zip(text_samples, labels))\n",
        "\n",
        "# # Print the frequency of each sample along with its label\n",
        "# for (sample, label), frequency in sample_frequency.items():\n",
        "#     print(f\"Sample: {sample}, Label: {label}, Frequency: {frequency}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "-igwtfQlYBpx"
      },
      "outputs": [],
      "source": [
        "X_train_over = Btrain_over['cleanText'].tolist()\n",
        "y_train_over = Btrain_over['label'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "JuK_XJy7YBpx"
      },
      "outputs": [],
      "source": [
        "#TF-IDF\n",
        "tfidf = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf.fit_transform(X_train_over)\n",
        "X_val_tfidf = tfidf.transform(X_valid)\n",
        "X_test_tfidf = tfidf.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vM6j60Q7YBpy",
        "outputId": "73873fbb-aa9c-49f4-b121-eb5676e3bda0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNB Accuracy: 0.8866666666666667\n",
            "Classification Report for MNB:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1     0.9412    0.9333    0.9372       120\n",
            "           2     0.8500    0.7391    0.7907        23\n",
            "           3     0.3636    0.5714    0.4444         7\n",
            "\n",
            "    accuracy                         0.8867       150\n",
            "   macro avg     0.7183    0.7480    0.7241       150\n",
            "weighted avg     0.9002    0.8867    0.8918       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "# Multinomial Naive Bayes\n",
        "model_mnb = MultinomialNB()\n",
        "model_mnb.fit(X_train_tfidf, y_train_over)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_pred_mnb = model_mnb.predict(X_val_tfidf)\n",
        "\n",
        "# Evaluation\n",
        "accuracy_mnb = accuracy_score(Bval['label'].tolist(), y_pred_mnb)\n",
        "classification_report_mnb = classification_report(Bval['label'].tolist(), y_pred_mnb, digits = 4)\n",
        "\n",
        "print(f'MNB Accuracy: {accuracy_mnb}')\n",
        "print('Classification Report for MNB:\\n', classification_report_mnb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "GoWmwf5cfwdy"
      },
      "outputs": [],
      "source": [
        "y_pred = model_mnb.predict(X_test_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "ry8neaqLfwdy"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "# import zipfile\n",
        "\n",
        "# # Assuming Btest is your DataFrame with an \"index\" column and y_pred is your predicted labels\n",
        "# # Replace y_pred with your actual predicted labels\n",
        "\n",
        "# # Create a DataFrame with \"index\" and \"prediction\" columns\n",
        "# submission_df = pd.DataFrame({\"index\": Btest[\"index\"].tolist(), \"prediction\": y_pred})\n",
        "\n",
        "# # Sort the DataFrame based on the \"index\" column\n",
        "# submission_df = submission_df.sort_values(by=\"index\")\n",
        "\n",
        "# # Define the path to save the submission file\n",
        "# submission_file_path = \"/content/submission.json\"\n",
        "\n",
        "# # Save the DataFrame to a JSON file\n",
        "# submission_df.to_json(submission_file_path, orient=\"records\", lines=True)\n",
        "\n",
        "# # Zip the JSON file\n",
        "# with zipfile.ZipFile(\"submission.zip\", \"w\") as zipf:\n",
        "#     zipf.write(submission_file_path, arcname=\"submission.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BciJz9qGYBpy",
        "outputId": "531ab31a-66ee-4214-d77c-1fb00ddce098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.8666666666666667\n",
            "Classification Report for SVM:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.96      0.90      0.93       120\n",
            "           2       0.58      0.91      0.71        23\n",
            "           3       0.50      0.14      0.22         7\n",
            "\n",
            "    accuracy                           0.87       150\n",
            "   macro avg       0.68      0.65      0.62       150\n",
            "weighted avg       0.88      0.87      0.86       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Support Vector Machine (SVM)\n",
        "model_svm = SVC(C=1, kernel='linear')\n",
        "model_svm.fit(X_train_tfidf, y_train_over)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model_svm.predict(X_val_tfidf)\n",
        "\n",
        "# Evaluation\n",
        "accuracy_svm = accuracy_score(Bval['label'].tolist(), y_pred)\n",
        "classification_report_svm = classification_report(Bval['label'].tolist(), y_pred)\n",
        "\n",
        "print(f'SVM Accuracy: {accuracy_svm}')\n",
        "print('Classification Report for SVM:\\n', classification_report_svm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btKpPAsRYBpy"
      },
      "source": [
        "## Random Over sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "PeHsX0l5YBpy",
        "outputId": "26a8730a-8040-403c-d99b-1d781b0387ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random over-sampling:\n",
            "1    105\n",
            "2    105\n",
            "3    105\n",
            "Name: label, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGuCAYAAAC6DP3dAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhKElEQVR4nO3de1TUdf7H8dcAOhAB3nKAEwqprZZmii2hpmWsWGZYHMvNzlreWsNKKU221JUsyuMaal6WjqGW1m7bZtkFT6KrXcgLbu5281KknGxGTRmUEg2+vz86fX87gYk2OJ+R5+OcOaf5fD/znTc16fN8mQGHZVmWAAAADBIS6AEAAAB+jkABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAWC08vJyhYeH6/3337fX7rrrLiUmJp7V+RwOhyZMmOCn6aSvvvpKDodDy5Yts9emTp2qlJQUvz0H0BQRKMB54osvvtA999yjSy65ROHh4YqOjlafPn00b948ff/994EeT5K0aNEin7/IGyI3N1cpKSnq06dP4wzVCCZOnKgdO3bo9ddfD/QoQNAKC/QAAH69N998U8OGDZPT6dQf/vAHde3aVSdOnNB7772nyZMn65NPPlFBQUGgx9SiRYvUpk0b3XXXXQ3af/DgQS1fvlzLly9v3MH8LDY2VhkZGZozZ45uvvnmQI8DBCUCBQhyZWVlGj58uNq3b6/169crLi7OPpaVlaU9e/bozTffDOCEZ++FF15QWFiYhgwZEuhRzthtt92mYcOG6csvv9Qll1wS6HGAoMO3eIAgN3v2bB07dkxLly71iZOfdOzYUQ888IB9/4cfftBjjz2mDh06yOl0KjExUX/6059UXV3t8ziHw6E///nPdc6XmJjocwVk2bJlcjgcev/995Wdna2LLrpIkZGRuuWWW3Tw4EGfx33yySfauHGjHA6HHA6Hrr322l/82lavXq2UlBRdeOGFp/33MGfOHPXu3VutW7dWRESEkpOT9Y9//OOU+1euXKnf/OY3Cg8PV3JysjZt2lRnz9dff61Ro0bJ5XLJ6XTq8ssv13PPPXfaWSQpLS1NkvTaa681aD8AXwQKEOTWrFmjSy65RL17927Q/jFjxmj69Onq2bOnnn76afXv3195eXkaPnz4r5rjvvvu044dOzRjxgyNHz9ea9as8Xkzan5+vi6++GJ17txZzz//vJ5//nk98sgjpzzfyZMntXXrVvXs2bNBzz9v3jz16NFDubm5euKJJxQWFqZhw4bVe/Vo48aNmjhxou68807l5ubq22+/1aBBg/Txxx/bezwej66++mqtW7dOEyZM0Lx589SxY0eNHj1a+fn5p50nJiZGHTp08HlzL4AzYAEIWl6v15JkZWRkNGj/Rx99ZEmyxowZ47P+0EMPWZKs9evX22uSrBkzZtQ5R/v27a2RI0fa9wsLCy1JVlpamlVbW2uvT5o0yQoNDbUqKirstcsvv9zq379/g2bds2ePJclasGBBnWMjR4602rdv77P23Xff+dw/ceKE1bVrV2vAgAE+65IsSda2bdvstb1791rh4eHWLbfcYq+NHj3aiouLsw4dOuTz+OHDh1sxMTH285WVlVmSrMLCwjpzDhw40OrSpUuDvl4AvriCAgSxyspKSVJUVFSD9r/11luSpOzsbJ/1Bx98UJJ+1XtVxo0bJ4fDYd+/5pprVFNTo717957V+b799ltJUsuWLRu0PyIiwv7nI0eOyOv16pprrtH27dvr7E1NTVVycrJ9v127dsrIyNDatWtVU1Mjy7L0yiuvaMiQIbIsS4cOHbJv6enp8nq99Z7351q2bKlDhw41aH4AvniTLBDEoqOjJUlHjx5t0P69e/cqJCREHTt29FmPjY1VixYtzjompB//kv9fP4XFkSNHzvqckmRZVoP2vfHGG5o1a5Y++ugjn/fT/G80/aRTp0511i699FJ99913OnjwoEJCQlRRUaGCgoJTfvrpwIEDDZq9vucHcHoEChDEoqOjFR8f7/PeiYb4NX9p1tTU1LseGhpa73pDA+PnWrduLalhgfPuu+/q5ptvVr9+/bRo0SLFxcWpWbNmKiws1KpVq874uWtrayVJd955p0aOHFnvniuuuOK05zly5IjatGlzxs8PgEABgt5NN92kgoIClZSUKDU19Rf3tm/fXrW1tdq9e7e6dOlir3s8HlVUVKh9+/b2WsuWLVVRUeHz+BMnTuibb74561nPJIzatWuniIgIlZWVnXbvK6+8ovDwcK1du1ZOp9NeLywsrHf/7t2766zt2rVLF1xwgS666CJJP37brKamxv40ztkoKytT9+7dz/rxQFPGe1CAIDdlyhRFRkZqzJgx8ng8dY5/8cUXmjdvniTpxhtvlKQ6n0KZO3euJGnw4MH2WocOHep89LagoOCUV1AaIjIysk70nEqzZs3Uq1cvbdu27bR7Q0ND5XA4fGb76quvtHr16nr3l5SU+LyHpLy8XK+99poGDhyo0NBQhYaGKjMzU6+88kq9V6f+9+PTp+L1evXFF180+NNVAHxxBQUIch06dNCqVat0++23q0uXLj4/SfaDDz7Qyy+/bP/cku7du2vkyJEqKChQRUWF+vfvry1btmj58uUaOnSorrvuOvu8Y8aM0R//+EdlZmbqd7/7nXbs2KG1a9f+qm9ZJCcna/HixZo1a5Y6duyotm3basCAAafcn5GRoUceeUSVlZX2+23qM3jwYM2dO1eDBg3SHXfcoQMHDmjhwoXq2LGj/vOf/9TZ37VrV6Wnp+v++++X0+nUokWLJEkzZ8609zz55JPasGGDUlJSNHbsWF122WU6fPiwtm/frnXr1unw4cO/+LWuW7dOlmUpIyPjdP9aANQnkB8hAuA/u3btssaOHWslJiZazZs3t6Kioqw+ffpYCxYssI4fP27vO3nypDVz5kwrKSnJatasmZWQkGDl5OT47LEsy6qpqbEefvhhq02bNtYFF1xgpaenW3v27Dnlx4y3bt3q8/gNGzZYkqwNGzbYa2632xo8eLAVFRVlSTrtR449Ho8VFhZmPf/88z7r9X3MeOnSpVanTp0sp9Npde7c2SosLLRmzJhh/fyPOUlWVlaW9cILL9j7e/To4TPn/z5/VlaWlZCQYDVr1syKjY21rr/+equgoMDec6qPGd9+++1W3759f/HrA3BqDss6y3ewAcA5MHr0aO3atUvvvvtuoEdpMLfbraSkJL300ktcQQHOEoECwGj79u3TpZdequLi4qD5jcZTp07V+vXrtWXLlkCPAgQtAgUAABiHT/EAAADjECgAAMA4BAoAADAOgQIAAIwTlD+orba2Vvv371dUVBS/iAsAgCBhWZaOHj2q+Ph4hYT88jWSoAyU/fv3KyEhIdBjAACAs1BeXq6LL774F/cEZaBERUVJ+vEL/KUffw0AAMxRWVmphIQE++/xXxKUgfLTt3Wio6MJFAAAgkxD3p7Bm2QBAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGCcsEAPcD5LnPpmoEc4b3z15OBAj3De4HXpH7wm/YfXpP+cT69LrqAAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMc8aBsmnTJg0ZMkTx8fFyOBxavXq1z3HLsjR9+nTFxcUpIiJCaWlp2r17t8+ew4cPa8SIEYqOjlaLFi00evRoHTt27Fd9IQAA4PxxxoFSVVWl7t27a+HChfUenz17tubPn68lS5Zo8+bNioyMVHp6uo4fP27vGTFihD755BO98847euONN7Rp0yaNGzfu7L8KAABwXgk70wfccMMNuuGGG+o9ZlmW8vPz9eijjyojI0OStGLFCrlcLq1evVrDhw/XZ599pqKiIm3dulW9evWSJC1YsEA33nij5syZo/j4+F/x5QAAgPOBX9+DUlZWJrfbrbS0NHstJiZGKSkpKikpkSSVlJSoRYsWdpxIUlpamkJCQrR58+Z6z1tdXa3KykqfGwAAOH/5NVDcbrckyeVy+ay7XC77mNvtVtu2bX2Oh4WFqVWrVvaen8vLy1NMTIx9S0hI8OfYAADAMEHxKZ6cnBx5vV77Vl5eHuiRAABAI/JroMTGxkqSPB6Pz7rH47GPxcbG6sCBAz7Hf/jhBx0+fNje83NOp1PR0dE+NwAAcP7ya6AkJSUpNjZWxcXF9lplZaU2b96s1NRUSVJqaqoqKipUWlpq71m/fr1qa2uVkpLiz3EAAECQOuNP8Rw7dkx79uyx75eVlemjjz5Sq1at1K5dO02cOFGzZs1Sp06dlJSUpGnTpik+Pl5Dhw6VJHXp0kWDBg3S2LFjtWTJEp08eVITJkzQ8OHD+QQPAACQdBaBsm3bNl133XX2/ezsbEnSyJEjtWzZMk2ZMkVVVVUaN26cKioq1LdvXxUVFSk8PNx+zMqVKzVhwgRdf/31CgkJUWZmpubPn++HLwcAAJwPzjhQrr32WlmWdcrjDodDubm5ys3NPeWeVq1aadWqVWf61AAAoIkIik/xAACApoVAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcAgUAABiHQAEAAMYhUAAAgHEIFAAAYBwCBQAAGIdAAQAAxiFQAACAcQgUAABgHAIFAAAYh0ABAADGIVAAAIBxCBQAAGAcvwdKTU2Npk2bpqSkJEVERKhDhw567LHHZFmWvceyLE2fPl1xcXGKiIhQWlqadu/e7e9RAABAkPJ7oDz11FNavHixnnnmGX322Wd66qmnNHv2bC1YsMDeM3v2bM2fP19LlizR5s2bFRkZqfT0dB0/ftzf4wAAgCAU5u8TfvDBB8rIyNDgwYMlSYmJiXrxxRe1ZcsWST9ePcnPz9ejjz6qjIwMSdKKFSvkcrm0evVqDR8+3N8jAQCAIOP3Kyi9e/dWcXGxdu3aJUnasWOH3nvvPd1www2SpLKyMrndbqWlpdmPiYmJUUpKikpKSuo9Z3V1tSorK31uAADg/OX3KyhTp05VZWWlOnfurNDQUNXU1Ojxxx/XiBEjJElut1uS5HK5fB7ncrnsYz+Xl5enmTNn+ntUAABgKL9fQfn73/+ulStXatWqVdq+fbuWL1+uOXPmaPny5Wd9zpycHHm9XvtWXl7ux4kBAIBp/H4FZfLkyZo6dar9XpJu3bpp7969ysvL08iRIxUbGytJ8ng8iouLsx/n8Xh05ZVX1ntOp9Mpp9Pp71EBAICh/H4F5bvvvlNIiO9pQ0NDVVtbK0lKSkpSbGysiouL7eOVlZXavHmzUlNT/T0OAAAIQn6/gjJkyBA9/vjjateunS6//HL9+9//1ty5czVq1ChJksPh0MSJEzVr1ix16tRJSUlJmjZtmuLj4zV06FB/jwMAAIKQ3wNlwYIFmjZtmu69914dOHBA8fHxuueeezR9+nR7z5QpU1RVVaVx48apoqJCffv2VVFRkcLDw/09DgAACEJ+D5SoqCjl5+crPz//lHscDodyc3OVm5vr76cHAADnAX4XDwAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4jRIoX3/9te688061bt1aERER6tatm7Zt22YftyxL06dPV1xcnCIiIpSWlqbdu3c3xigAACAI+T1Qjhw5oj59+qhZs2Z6++239emnn+ovf/mLWrZsae+ZPXu25s+fryVLlmjz5s2KjIxUenq6jh8/7u9xAABAEArz9wmfeuopJSQkqLCw0F5LSkqy/9myLOXn5+vRRx9VRkaGJGnFihVyuVxavXq1hg8f7u+RAABAkPH7FZTXX39dvXr10rBhw9S2bVv16NFDzz77rH28rKxMbrdbaWlp9lpMTIxSUlJUUlJS7zmrq6tVWVnpcwMAAOcvvwfKl19+qcWLF6tTp05au3atxo8fr/vvv1/Lly+XJLndbkmSy+XyeZzL5bKP/VxeXp5iYmLsW0JCgr/HBgAABvF7oNTW1qpnz5564okn1KNHD40bN05jx47VkiVLzvqcOTk58nq99q28vNyPEwMAANP4PVDi4uJ02WWX+ax16dJF+/btkyTFxsZKkjwej88ej8djH/s5p9Op6OhonxsAADh/+T1Q+vTpo507d/qs7dq1S+3bt5f04xtmY2NjVVxcbB+vrKzU5s2blZqa6u9xAABAEPL7p3gmTZqk3r1764knntBtt92mLVu2qKCgQAUFBZIkh8OhiRMnatasWerUqZOSkpI0bdo0xcfHa+jQof4eBwAABCG/B8pVV12lV199VTk5OcrNzVVSUpLy8/M1YsQIe8+UKVNUVVWlcePGqaKiQn379lVRUZHCw8P9PQ4AAAhCfg8USbrpppt00003nfK4w+FQbm6ucnNzG+PpAQBAkON38QAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACM0+iB8uSTT8rhcGjixIn22vHjx5WVlaXWrVvrwgsvVGZmpjweT2OPAgAAgkSjBsrWrVv117/+VVdccYXP+qRJk7RmzRq9/PLL2rhxo/bv369bb721MUcBAABBpNEC5dixYxoxYoSeffZZtWzZ0l73er1aunSp5s6dqwEDBig5OVmFhYX64IMP9OGHHzbWOAAAIIg0WqBkZWVp8ODBSktL81kvLS3VyZMnfdY7d+6sdu3aqaSkpN5zVVdXq7Ky0ucGAADOX2GNcdKXXnpJ27dv19atW+scc7vdat68uVq0aOGz7nK55Ha76z1fXl6eZs6c2RijAgAAA/n9Ckp5ebkeeOABrVy5UuHh4X45Z05Ojrxer30rLy/3y3kBAICZ/B4opaWlOnDggHr27KmwsDCFhYVp48aNmj9/vsLCwuRyuXTixAlVVFT4PM7j8Sg2NrbeczqdTkVHR/vcAADA+cvv3+K5/vrr9d///tdn7e6771bnzp318MMPKyEhQc2aNVNxcbEyMzMlSTt37tS+ffuUmprq73EAAEAQ8nugREVFqWvXrj5rkZGRat26tb0+evRoZWdnq1WrVoqOjtZ9992n1NRUXX311f4eBwAABKFGeZPs6Tz99NMKCQlRZmamqqurlZ6erkWLFgViFAAAYKBzEij/+te/fO6Hh4dr4cKFWrhw4bl4egAAEGT4XTwAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4/g9UPLy8nTVVVcpKipKbdu21dChQ7Vz506fPcePH1dWVpZat26tCy+8UJmZmfJ4PP4eBQAABCm/B8rGjRuVlZWlDz/8UO+8845OnjypgQMHqqqqyt4zadIkrVmzRi+//LI2btyo/fv369Zbb/X3KAAAIEiF+fuERUVFPveXLVumtm3bqrS0VP369ZPX69XSpUu1atUqDRgwQJJUWFioLl266MMPP9TVV1/t75EAAECQafT3oHi9XklSq1atJEmlpaU6efKk0tLS7D2dO3dWu3btVFJSUu85qqurVVlZ6XMDAADnr0YNlNraWk2cOFF9+vRR165dJUlut1vNmzdXixYtfPa6XC653e56z5OXl6eYmBj7lpCQ0JhjAwCAAGvUQMnKytLHH3+sl1566VedJycnR16v176Vl5f7aUIAAGAiv78H5ScTJkzQG2+8oU2bNuniiy+212NjY3XixAlVVFT4XEXxeDyKjY2t91xOp1NOp7OxRgUAAIbx+xUUy7I0YcIEvfrqq1q/fr2SkpJ8jicnJ6tZs2YqLi6213bu3Kl9+/YpNTXV3+MAAIAg5PcrKFlZWVq1apVee+01RUVF2e8riYmJUUREhGJiYjR69GhlZ2erVatWio6O1n333afU1FQ+wQMAACQ1QqAsXrxYknTttdf6rBcWFuquu+6SJD399NMKCQlRZmamqqurlZ6erkWLFvl7FAAAEKT8HiiWZZ12T3h4uBYuXKiFCxf6++kBAMB5gN/FAwAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADAOgQIAAIxDoAAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADjECgAAMA4BAoAADBOQANl4cKFSkxMVHh4uFJSUrRly5ZAjgMAAAwRsED529/+puzsbM2YMUPbt29X9+7dlZ6ergMHDgRqJAAAYIiABcrcuXM1duxY3X333brsssu0ZMkSXXDBBXruuecCNRIAADBEWCCe9MSJEyotLVVOTo69FhISorS0NJWUlNTZX11drerqavu+1+uVJFVWVjb+sL9CbfV3gR7hvGH6f+tgwuvSP3hN+g+vSf8x/XX503yWZZ12b0AC5dChQ6qpqZHL5fJZd7lc+vzzz+vsz8vL08yZM+usJyQkNNqMMEtMfqAnAHzxmoSJguV1efToUcXExPzinoAEypnKyclRdna2fb+2tlaHDx9W69at5XA4AjhZ8KusrFRCQoLKy8sVHR0d6HEAXpMwDq9J/7EsS0ePHlV8fPxp9wYkUNq0aaPQ0FB5PB6fdY/Ho9jY2Dr7nU6nnE6nz1qLFi0ac8QmJzo6mv/xYBRekzANr0n/ON2Vk58E5E2yzZs3V3JysoqLi+212tpaFRcXKzU1NRAjAQAAgwTsWzzZ2dkaOXKkevXqpd/+9rfKz89XVVWV7r777kCNBAAADBGwQLn99tt18OBBTZ8+XW63W1deeaWKiorqvHEWjcvpdGrGjBl1voUGBAqvSZiG12RgOKyGfNYHAADgHOJ38QAAAOMQKAAAwDgECgAAMA6BAgAAjEOgAAAA4xAoAADAOAQKgID6/vvv9d577+nTTz+tc+z48eNasWJFAKZCU/bZZ5+psLDQ/uW1n3/+ucaPH69Ro0Zp/fr1AZ6u6SBQYCsvL9eoUaMCPQaakF27dqlLly7q16+funXrpv79++ubb76xj3u9Xn66NM6poqIiXXnllXrooYfUo0cPFRUVqV+/ftqzZ4/27t2rgQMHEinnCIEC2+HDh7V8+fJAj4Em5OGHH1bXrl114MAB7dy5U1FRUerTp4/27dsX6NHQROXm5mry5Mn69ttvVVhYqDvuuENjx47VO++8o+LiYk2ePFlPPvlkoMdsEvhJsk3I66+//ovHv/zySz344IOqqak5RxOhqXO5XFq3bp26desm6cdfxX7vvffqrbfe0oYNGxQZGan4+HhekzhnYmJiVFpaqo4dO6q2tlZOp1NbtmxRjx49JEkff/yx0tLS5Ha7Azzp+S9gv4sH597QoUPlcDj0S03qcDjO4URo6r7//nuFhf3/H0MOh0OLFy/WhAkT1L9/f61atSqA06Gp+unPwZCQEIWHhysmJsY+FhUVJa/XG6jRmhS+xdOExMXF6Z///Kdqa2vrvW3fvj3QI6KJ6dy5s7Zt21Zn/ZlnnlFGRoZuvvnmAEyFpiwxMVG7d++275eUlKhdu3b2/X379ikuLi4QozU5BEoTkpycrNLS0lMeP93VFcDfbrnlFr344ov1HnvmmWf0+9//ntckzqnx48f7fEuxa9euPlf53n77bQ0YMCAQozU5vAelCXn33XdVVVWlQYMG1Xu8qqpK27ZtU//+/c/xZAAA+CJQAACAcfgWDwAAMA6BAgAAjEOgAAAA4xAoAADAOAQKAAAwDoECAACMQ6AAAADj/B9rMD7NVgXR0AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming Btrain is your original dataframe\n",
        "ros = RandomOverSampler()\n",
        "X_ros, y_ros = ros.fit_resample(Btrain[['cleanText']], Btrain['label'])\n",
        "\n",
        "# Create a new dataframe with the resampled data\n",
        "Btrain_over = pd.DataFrame({'cleanText': X_ros['cleanText'], 'label': y_ros})\n",
        "\n",
        "# Check the value counts\n",
        "print('Random over-sampling:')\n",
        "print(Btrain_over.label.value_counts())\n",
        "\n",
        "# Plot the counts\n",
        "Btrain_over.label.value_counts().plot(kind='bar', title='Count (label)');\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2ul0mW7YBpz",
        "outputId": "69dfb381-32b6-4c48-d2e3-c6efd696eaeb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1\n",
              "1      2\n",
              "2      2\n",
              "3      2\n",
              "4      2\n",
              "      ..\n",
              "310    3\n",
              "311    3\n",
              "312    3\n",
              "313    3\n",
              "314    3\n",
              "Name: label, Length: 315, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "y_ros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMZtR9NMYBpz",
        "outputId": "167b52e8-a0ad-47f9-80c3-3b5ac368c657"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.8866666666666667\n",
            "Classification Report for SVM:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.96      0.93      0.94       120\n",
            "           2       0.66      0.91      0.76        23\n",
            "           3       0.50      0.14      0.22         7\n",
            "\n",
            "    accuracy                           0.89       150\n",
            "   macro avg       0.70      0.66      0.64       150\n",
            "weighted avg       0.89      0.89      0.88       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf.fit_transform(X_ros['cleanText'])\n",
        "X_val_tfidf = tfidf.transform(X_valid)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "# Support Vector Machine (SVM)\n",
        "model_svm = SVC(C=1, kernel='linear')\n",
        "model_svm.fit(X_train_tfidf, y_ros)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model_svm.predict(X_val_tfidf)\n",
        "\n",
        "# Evaluation\n",
        "accuracy_svm = accuracy_score(Bval['label'].tolist(), y_pred)\n",
        "classification_report_svm = classification_report(Bval['label'].tolist(), y_pred)\n",
        "\n",
        "print(f'SVM Accuracy: {accuracy_svm}')\n",
        "print('Classification Report for SVM:\\n', classification_report_svm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hc8PjpQZfwd0",
        "outputId": "b3ba4a78-a6bc-40be-db37-f37d0d834c45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNB Accuracy: 0.8733333333333333\n",
            "Classification Report for MNB:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.94      0.93       120\n",
            "           2       0.88      0.61      0.72        23\n",
            "           3       0.36      0.57      0.44         7\n",
            "\n",
            "    accuracy                           0.87       150\n",
            "   macro avg       0.72      0.71      0.70       150\n",
            "weighted avg       0.89      0.87      0.87       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Multinomial Naive Bayes\n",
        "model_mnb = MultinomialNB()\n",
        "model_mnb.fit(X_train_tfidf, y_ros)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_pred_mnb = model_mnb.predict(X_val_tfidf)\n",
        "\n",
        "# Evaluation\n",
        "accuracy_mnb = accuracy_score(Bval['label'].tolist(), y_pred_mnb)\n",
        "classification_report_mnb = classification_report(Bval['label'].tolist(), y_pred_mnb)\n",
        "\n",
        "print(f'MNB Accuracy: {accuracy_mnb}')\n",
        "print('Classification Report for MNB:\\n', classification_report_mnb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "4GQWkL68fwd1"
      },
      "outputs": [],
      "source": [
        "y_pred = model_mnb.predict(X_test_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "vRN1c1ysfwd1"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "# import zipfile\n",
        "\n",
        "# # Assuming Btest is your DataFrame with an \"index\" column and y_pred is your predicted labels\n",
        "# # Replace y_pred with your actual predicted labels\n",
        "\n",
        "# # Create a DataFrame with \"index\" and \"prediction\" columns\n",
        "# submission_df = pd.DataFrame({\"index\": Btest[\"index\"].tolist(), \"prediction\": y_pred})\n",
        "\n",
        "# # Sort the DataFrame based on the \"index\" column\n",
        "# submission_df = submission_df.sort_values(by=\"index\")\n",
        "\n",
        "# # Define the path to save the submission file\n",
        "# submission_file_path = \"/kaggle/working/submission.json\"\n",
        "\n",
        "# # Save the DataFrame to a JSON file\n",
        "# submission_df.to_json(submission_file_path, orient=\"records\", lines=True)\n",
        "\n",
        "# # Zip the JSON file\n",
        "# with zipfile.ZipFile(\"submission.zip\", \"w\") as zipf:\n",
        "#     zipf.write(submission_file_path, arcname=\"submission.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMcbQmIOfwd1"
      },
      "source": [
        "## Oversampling Another Strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbPebCUMfwd1",
        "outputId": "4df55eda-74cc-4c63-d449-067b268dc1d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    105\n",
              "1     61\n",
              "3     31\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "Btrain['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "jIWrzNFvfwd2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Assuming 'cleanText' is the column containing your text data and 'label' is the column containing labels\n",
        "X_minority_1 = Btrain[Btrain['label'] == 1]['cleanText']\n",
        "y_minority_1 = Btrain[Btrain['label'] == 1]['label']\n",
        "oversample_factor_1 = 2\n",
        "\n",
        "X_minority_2 = Btrain[Btrain['label'] == 2]['cleanText']\n",
        "y_minority_2 = Btrain[Btrain['label'] == 2]['label']\n",
        "oversample_factor_2 = 1\n",
        "\n",
        "X_minority_3 = Btrain[Btrain['label'] == 3]['cleanText']\n",
        "y_minority_3 = Btrain[Btrain['label'] == 3]['label']\n",
        "oversample_factor_3 = 3\n",
        "\n",
        "# Oversample each minority class by duplicating each sample\n",
        "X_oversampled_1 = np.repeat(X_minority_1, oversample_factor_1)\n",
        "y_oversampled_1 = np.repeat(y_minority_1, oversample_factor_1)\n",
        "\n",
        "X_oversampled_2 = np.repeat(X_minority_2, oversample_factor_2)\n",
        "y_oversampled_2 = np.repeat(y_minority_2, oversample_factor_2)\n",
        "\n",
        "X_oversampled_3 = np.repeat(X_minority_3, oversample_factor_3)\n",
        "y_oversampled_3 = np.repeat(y_minority_3, oversample_factor_3)\n",
        "\n",
        "# Combine the oversampled minority classes with the majority class\n",
        "X_resampled = pd.concat([pd.Series(X_oversampled_1), pd.Series(X_oversampled_2), pd.Series(X_oversampled_3)])\n",
        "y_resampled = pd.concat([pd.Series(y_oversampled_1), pd.Series(y_oversampled_2), pd.Series(y_oversampled_3)])\n",
        "\n",
        "# Shuffle the data\n",
        "oversampled_df = pd.concat([X_resampled, y_resampled], axis=1)\n",
        "oversampled_df = oversampled_df.sample(frac=1, random_state=42).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-zPSFV_fwd2",
        "outputId": "1062b415-aeb0-4b13-941c-fe0f5cab1f8a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    122\n",
              "2    105\n",
              "3     93\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "oversampled_df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "vIGmx3TDfwd2"
      },
      "outputs": [],
      "source": [
        "X_train_over = oversampled_df['cleanText'].tolist()\n",
        "y_train_over = oversampled_df['label'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "-A4NCuRqfwd3"
      },
      "outputs": [],
      "source": [
        "#TF-IDF\n",
        "tfidf = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf.fit_transform(X_train_over)\n",
        "X_val_tfidf = tfidf.transform(X_valid)\n",
        "X_test_tfidf = tfidf.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ype2UYt-fwd3",
        "outputId": "4c196eb2-b4a0-47fe-90a5-df0e191abe47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNB Accuracy: 0.8666666666666667\n",
            "Classification Report for MNB:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.90      0.96      0.93       120\n",
            "           2       0.72      0.57      0.63        23\n",
            "           3       0.50      0.29      0.36         7\n",
            "\n",
            "    accuracy                           0.87       150\n",
            "   macro avg       0.71      0.60      0.64       150\n",
            "weighted avg       0.85      0.87      0.86       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Multinomial Naive Bayes\n",
        "model_mnb = MultinomialNB()\n",
        "model_mnb.fit(X_train_tfidf, y_train_over)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_pred_mnb = model_mnb.predict(X_val_tfidf)\n",
        "\n",
        "# Evaluation\n",
        "accuracy_mnb = accuracy_score(Bval['label'].tolist(), y_pred_mnb)\n",
        "classification_report_mnb = classification_report(Bval['label'].tolist(), y_pred_mnb)\n",
        "\n",
        "print(f'MNB Accuracy: {accuracy_mnb}')\n",
        "print('Classification Report for MNB:\\n', classification_report_mnb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VU6oM5efwd3",
        "outputId": "79d4d71c-2897-47f1-8d3a-2dc846dd52f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.8866666666666667\n",
            "Classification Report for SVM:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.96      0.93      0.94       120\n",
            "           2       0.66      0.91      0.76        23\n",
            "           3       0.50      0.14      0.22         7\n",
            "\n",
            "    accuracy                           0.89       150\n",
            "   macro avg       0.70      0.66      0.64       150\n",
            "weighted avg       0.89      0.89      0.88       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf.fit_transform(X_ros['cleanText'])\n",
        "X_val_tfidf = tfidf.transform(X_valid)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "# Support Vector Machine (SVM)\n",
        "model_svm = SVC(C=1, kernel='linear')\n",
        "model_svm.fit(X_train_tfidf, y_ros)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model_svm.predict(X_val_tfidf)\n",
        "\n",
        "# Evaluation\n",
        "accuracy_svm = accuracy_score(Bval['label'].tolist(), y_pred)\n",
        "classification_report_svm = classification_report(Bval['label'].tolist(), y_pred)\n",
        "\n",
        "print(f'SVM Accuracy: {accuracy_svm}')\n",
        "print('Classification Report for SVM:\\n', classification_report_svm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA9TZgK65B0C"
      },
      "source": [
        "# ML Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtE4KQlG5B0D"
      },
      "source": [
        "## TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "eq2d7-4w6gAc"
      },
      "outputs": [],
      "source": [
        "X_train_over = X_ros['cleanText'].tolist()\n",
        "y_train_over = y_ros.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "oaVHrtDHZfYJ"
      },
      "outputs": [],
      "source": [
        "y_train_over = [label - 1 for label in y_train_over]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMMaQeju5B0E"
      },
      "outputs": [],
      "source": [
        "#TF-IDF\n",
        "tfidf = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf.fit_transform(X_train_over)\n",
        "X_val_tfidf = tfidf.transform(X_valid)\n",
        "X_test_tfidf = tfidf.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rId5LoqB5B0F"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lwJQN5_85B0G"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# # Define the parameter grid to search\n",
        "# param_grid_rf = {\n",
        "#     'n_estimators': [100, 500, 1000],\n",
        "#     'max_depth': [None, 10, 20, 30],\n",
        "#     'min_samples_split': [2, 5, 10],\n",
        "#     'min_samples_leaf': [1, 2, 4],\n",
        "#     'class_weight': ['balanced', None]\n",
        "# }\n",
        "\n",
        "# # Create a RandomForestClassifier\n",
        "# rf_classifier = RandomForestClassifier()\n",
        "\n",
        "# # Create the GridSearchCV object\n",
        "# grid_search_rf = GridSearchCV(estimator=rf_classifier, param_grid=param_grid_rf,\n",
        "#                                scoring='accuracy', cv=5, n_jobs=-1, verbose=2)\n",
        "\n",
        "# # Fit the grid search to the data\n",
        "# grid_search_rf.fit(X_train_tfidf, X_train_over)\n",
        "\n",
        "# # Print the best parameters and the corresponding accuracy\n",
        "# print(\"Best Parameters: \", grid_search_rf.best_params_)\n",
        "# print(\"Best Accuracy: \", grid_search_rf.best_score_)\n",
        "\n",
        "# # Get the best model\n",
        "# best_rf_model = grid_search_rf.best_estimator_\n",
        "\n",
        "# # Predict on the validation set\n",
        "# y_pred_val = best_rf_model.predict(X_val_tfidf)\n",
        "\n",
        "# # Evaluate the model\n",
        "# accuracy_val = accuracy_score(y_val, y_pred_val)\n",
        "# classification_report_val = classification_report(y_val, y_pred_val)\n",
        "\n",
        "# print(\"Validation Accuracy: \", accuracy_val)\n",
        "# print(\"Classification Report (Validation):\\n\", classification_report_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "3zbJo4rD5B0H",
        "outputId": "66198ea9-8334-4fdc-ed56-5f02a8ee9416"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=1000)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(n_estimators=1000)"
            ]
          },
          "execution_count": 194,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "# Example: Training individual models\n",
        "model_rf = RandomForestClassifier(n_estimators=1000)  #use class_weight='balanced'\n",
        "model_rf.fit(X_train_tfidf, y_train_over)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lX2hQW45B0J",
        "outputId": "83e3ae08-d70e-4777-fe88-c58d9273651a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8466666666666667\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.9469    0.8917    0.9185       120\n",
            "           2     0.5278    0.8261    0.6441        23\n",
            "           3     1.0000    0.1429    0.2500         7\n",
            "\n",
            "    accuracy                         0.8467       150\n",
            "   macro avg     0.8249    0.6202    0.6042       150\n",
            "weighted avg     0.8851    0.8467    0.8452       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = model_rf.predict(X_val_tfidf)\n",
        "\n",
        "accuracy = accuracy_score(y_valid, y_pred)\n",
        "report = classification_report(y_valid, y_pred, digits = 4)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)             #estimator 1000--> 0.58      0.57      0.57"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YpMmSDrlXJ6",
        "outputId": "55c63664-74ae-4e3c-bd6c-0ce0591dd05b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8866666666666667\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.9823    0.9174    0.9487       121\n",
            "           2     0.6061    0.8696    0.7143        23\n",
            "           3     0.5000    0.3333    0.4000         6\n",
            "\n",
            "    accuracy                         0.8867       150\n",
            "   macro avg     0.6961    0.7068    0.6877       150\n",
            "weighted avg     0.9053    0.8867    0.8908       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = model_rf.predict(X_test_tfidf)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, digits = 4)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)             #estimator 1000--> 0.58      0.57      0.57"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1wyz9K25B0J"
      },
      "source": [
        "### LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "lkBJELdX5B0K",
        "outputId": "8a24a5a4-397d-4e01-8e33-1ae65567acad"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(C=1, solver='liblinear')"
            ]
          },
          "execution_count": 197,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Logistic Regression\n",
        "model_lr = LogisticRegression(solver='liblinear', C=1)\n",
        "model_lr.fit(X_train_tfidf, y_train_over)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qWymZFH5B0L",
        "outputId": "9531247c-1f79-4add-b9e9-5277d9f6ab92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy: 0.8733333333333333\n",
            "Classification Report for Logistic Regression:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1     0.9661    0.9421    0.9540       121\n",
            "           2     0.5926    0.6957    0.6400        23\n",
            "           3     0.2000    0.1667    0.1818         6\n",
            "\n",
            "    accuracy                         0.8733       150\n",
            "   macro avg     0.5862    0.6015    0.5919       150\n",
            "weighted avg     0.8782    0.8733    0.8749       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Predict on the test set\n",
        "y_pred_lr = model_lr.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluation\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "classification_report_lr = classification_report(y_test, y_pred_lr, digits = 4)\n",
        "\n",
        "print(f'Logistic Regression Accuracy: {accuracy_lr}')\n",
        "print('Classification Report for Logistic Regression:\\n', classification_report_lr) # 0.63      0.63      0.63"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9cEBnO45B0M"
      },
      "outputs": [],
      "source": [
        "y_pred = model_lr.predict(X_test_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlA9U5AH5B0M"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "# import zipfile\n",
        "\n",
        "# # Assuming Btest is your DataFrame with an \"index\" column and y_pred is your predicted labels\n",
        "# # Replace y_pred with your actual predicted labels\n",
        "\n",
        "# # Create a DataFrame with \"index\" and \"prediction\" columns\n",
        "# submission_df = pd.DataFrame({\"index\": Btest[\"index\"].tolist(), \"prediction\": y_pred})\n",
        "\n",
        "# # Sort the DataFrame based on the \"index\" column\n",
        "# submission_df = submission_df.sort_values(by=\"index\")\n",
        "\n",
        "# # Define the path to save the submission file\n",
        "# submission_file_path = \"/content/submission.json\"\n",
        "\n",
        "# # Save the DataFrame to a JSON file\n",
        "# submission_df.to_json(submission_file_path, orient=\"records\", lines=True)\n",
        "\n",
        "# # Zip the JSON file\n",
        "# with zipfile.ZipFile(\"submission.zip\", \"w\") as zipf:\n",
        "#     zipf.write(submission_file_path, arcname=\"submission.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ealqY9Gn5B0N"
      },
      "source": [
        "### MNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmKyRUHn5B0O",
        "outputId": "86151fb8-c16b-4ece-dd33-4336e2b16673"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multinomial Naive Bayes Accuracy: 0.88\n",
            "Classification Report for Multinomial Naive Bayes:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1     0.9262    0.9417    0.9339       120\n",
            "           2     0.8889    0.6957    0.7805        23\n",
            "           3     0.3000    0.4286    0.3529         7\n",
            "\n",
            "    accuracy                         0.8800       150\n",
            "   macro avg     0.7050    0.6886    0.6891       150\n",
            "weighted avg     0.8913    0.8800    0.8833       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Multinomial Naive Bayes\n",
        "model_nb = MultinomialNB()\n",
        "model_nb.fit(X_train_tfidf, y_train_over)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_nb = model_nb.predict(X_val_tfidf)\n",
        "\n",
        "# Evaluation\n",
        "accuracy_nb = accuracy_score(y_valid, y_pred_nb)\n",
        "classification_report_nb = classification_report(y_valid, y_pred_nb, digits = 4)\n",
        "\n",
        "print(f'Multinomial Naive Bayes Accuracy: {accuracy_nb}')\n",
        "print('Classification Report for Multinomial Naive Bayes:\\n', classification_report_nb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDbWAyrZlngy",
        "outputId": "a546e7a0-ecce-47b1-97f5-f56ad30247c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multinomial Naive Bayes Accuracy: 0.8866666666666667\n",
            "Classification Report for Multinomial Naive Bayes:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1     0.9512    0.9669    0.9590       121\n",
            "           2     0.7647    0.5652    0.6500        23\n",
            "           3     0.3000    0.5000    0.3750         6\n",
            "\n",
            "    accuracy                         0.8867       150\n",
            "   macro avg     0.6720    0.6774    0.6613       150\n",
            "weighted avg     0.8966    0.8867    0.8883       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred_nb = model_nb.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluation\n",
        "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "classification_report_nb = classification_report(y_test, y_pred_nb, digits = 4)\n",
        "\n",
        "print(f'Multinomial Naive Bayes Accuracy: {accuracy_nb}')\n",
        "print('Classification Report for Multinomial Naive Bayes:\\n', classification_report_nb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7ny-Ljw5B0O"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tt97EJV35B0Q",
        "outputId": "9ca7d6f3-36c3-4539-d251-a6fe937e41a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Accuracy: 0.8866666666666667\n",
            "Classification Report for SVM:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1     0.9565    0.9167    0.9362       120\n",
            "           2     0.6562    0.9130    0.7636        23\n",
            "           3     0.6667    0.2857    0.4000         7\n",
            "\n",
            "    accuracy                         0.8867       150\n",
            "   macro avg     0.7598    0.7051    0.6999       150\n",
            "weighted avg     0.8970    0.8867    0.8847       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Support Vector Machine (SVM)\n",
        "model_svm = SVC(C=1, kernel='linear')\n",
        "model_svm.fit(X_train_tfidf, y_train_over)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model_svm.predict(X_val_tfidf)\n",
        "\n",
        "# Evaluation\n",
        "accuracy_svm = accuracy_score(y_valid, y_pred)\n",
        "classification_report_svm = classification_report(y_valid, y_pred, digits = 4)\n",
        "\n",
        "print(f'SVM Accuracy: {accuracy_svm}')\n",
        "print('Classification Report for SVM:\\n', classification_report_svm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_IIX0uhlw27",
        "outputId": "4ec46961-4d3c-4160-cce9-f952d670ce75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Accuracy: 0.8866666666666667\n",
            "Classification Report for SVM:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1     0.9741    0.9339    0.9536       121\n",
            "           2     0.6129    0.8261    0.7037        23\n",
            "           3     0.3333    0.1667    0.2222         6\n",
            "\n",
            "    accuracy                         0.8867       150\n",
            "   macro avg     0.6401    0.6422    0.6265       150\n",
            "weighted avg     0.8931    0.8867    0.8860       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Predict on the test set\n",
        "y_pred = model_svm.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluation\n",
        "accuracy_svm = accuracy_score(y_test, y_pred)\n",
        "classification_report_svm = classification_report(y_test, y_pred, digits = 4)\n",
        "\n",
        "print(f'SVM Accuracy: {accuracy_svm}')\n",
        "print('Classification Report for SVM:\\n', classification_report_svm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFjrGZot5B0R"
      },
      "outputs": [],
      "source": [
        "y_pred = model_svm.predict(X_test_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJqo_KVy5B0S"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "# import zipfile\n",
        "\n",
        "# # Assuming Btest is your DataFrame with an \"index\" column and y_pred is your predicted labels\n",
        "# # Replace y_pred with your actual predicted labels\n",
        "\n",
        "# # Create a DataFrame with \"index\" and \"prediction\" columns\n",
        "# submission_df = pd.DataFrame({\"index\": Btest[\"index\"].tolist(), \"prediction\": y_pred})\n",
        "\n",
        "# # Sort the DataFrame based on the \"index\" column\n",
        "# submission_df = submission_df.sort_values(by=\"index\")\n",
        "\n",
        "# # Define the path to save the submission file\n",
        "# submission_file_path = \"/content/submission.json\"\n",
        "\n",
        "# # Save the DataFrame to a JSON file\n",
        "# submission_df.to_json(submission_file_path, orient=\"records\", lines=True)\n",
        "\n",
        "# # Zip the JSON file\n",
        "# with zipfile.ZipFile(\"submission.zip\", \"w\") as zipf:\n",
        "#     zipf.write(submission_file_path, arcname=\"submission.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ365ukK5B0S"
      },
      "source": [
        "### Ensemble Majority Voting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "FJ9mTtP95B0T",
        "outputId": "1cf591f8-0432-493f-ca75-416d27f00bfb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "DecisionTreeClassifier()"
            ]
          },
          "execution_count": 203,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "# Example: Training individual models\n",
        "model_rf = RandomForestClassifier()  #use class_weight='balanced' if classes are imbalanced\n",
        "model_rf.fit(X_train_tfidf, y_train_over)\n",
        "\n",
        "model_lr = LogisticRegression()\n",
        "model_lr.fit(X_train_tfidf, y_train_over)\n",
        "\n",
        "model_svm = SVC()    #kernel='poly'  kernel='rbf'   kernel='sigmoid'\n",
        "model_svm.fit(X_train_tfidf, y_train_over)\n",
        "\n",
        "model_dt = DecisionTreeClassifier()\n",
        "model_dt.fit(X_train_tfidf, y_train_over)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "PXBMDgMX5B0U",
        "outputId": "a90acdec-b9bb-46c4-d7ba-4410a3ae2f11"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;RandomForest&#x27;, RandomForestClassifier()),\n",
              "                             (&#x27;LogisticRegression&#x27;, LogisticRegression()),\n",
              "                             (&#x27;SVM&#x27;, SVC()),\n",
              "                             (&#x27;DecisionTree&#x27;, DecisionTreeClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;RandomForest&#x27;, RandomForestClassifier()),\n",
              "                             (&#x27;LogisticRegression&#x27;, LogisticRegression()),\n",
              "                             (&#x27;SVM&#x27;, SVC()),\n",
              "                             (&#x27;DecisionTree&#x27;, DecisionTreeClassifier())])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>RandomForest</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>LogisticRegression</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>SVM</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>DecisionTree</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "VotingClassifier(estimators=[('RandomForest', RandomForestClassifier()),\n",
              "                             ('LogisticRegression', LogisticRegression()),\n",
              "                             ('SVM', SVC()),\n",
              "                             ('DecisionTree', DecisionTreeClassifier())])"
            ]
          },
          "execution_count": 204,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Create a list of tuples with model names and trained models\n",
        "models = [\n",
        "    ('RandomForest', model_rf),\n",
        "    ('LogisticRegression', model_lr),\n",
        "    ('SVM', model_svm),\n",
        "    ('DecisionTree', model_dt)\n",
        "]\n",
        "\n",
        "# Create an ensemble model using VotingClassifier\n",
        "ensemble_model = VotingClassifier(estimators=models, voting='hard') # 'hard' voting for majority class\n",
        "ensemble_model.fit(X_train_tfidf, y_train_over)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZDxx6cW5B0U",
        "outputId": "5874401f-9da1-4963-b72d-2c56ed18db5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8533333333333334\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.9554    0.8917    0.9224       120\n",
            "           2     0.5405    0.8696    0.6667        23\n",
            "           3     1.0000    0.1429    0.2500         7\n",
            "\n",
            "    accuracy                         0.8533       150\n",
            "   macro avg     0.8320    0.6347    0.6130       150\n",
            "weighted avg     0.8938    0.8533    0.8518       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Predictions\n",
        "y_pred = ensemble_model.predict(X_val_tfidf)\n",
        "accuracy = accuracy_score(y_valid, y_pred)\n",
        "report = classification_report(y_valid, y_pred, digits = 4)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfsjae9ZmFcS",
        "outputId": "33f9bd1d-7d7d-4da8-de10-121a329cb77c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8866666666666667\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.9911    0.9174    0.9528       121\n",
            "           2     0.5946    0.9565    0.7333        23\n",
            "           3     0.0000    0.0000    0.0000         6\n",
            "\n",
            "    accuracy                         0.8867       150\n",
            "   macro avg     0.5286    0.6246    0.5620       150\n",
            "weighted avg     0.8906    0.8867    0.8810       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Predictions\n",
        "y_pred = ensemble_model.predict(X_test_tfidf)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, digits = 4)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZWfvjGA5B0V"
      },
      "outputs": [],
      "source": [
        "y_pred = ensemble_model.predict(X_test_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elJKPbAP5B0V"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "# import zipfile\n",
        "\n",
        "# # Assuming Btest is your DataFrame with an \"index\" column and y_pred is your predicted labels\n",
        "# # Replace y_pred with your actual predicted labels\n",
        "\n",
        "# # Create a DataFrame with \"index\" and \"prediction\" columns\n",
        "# submission_df = pd.DataFrame({\"index\": Bval[\"index\"].tolist(), \"prediction\": y_pred})\n",
        "\n",
        "# # Sort the DataFrame based on the \"index\" column\n",
        "# submission_df = submission_df.sort_values(by=\"index\")\n",
        "\n",
        "# # Define the path to save the submission file\n",
        "# submission_file_path = \"/content/submissiondev.json\"\n",
        "\n",
        "# # Save the DataFrame to a JSON file\n",
        "# submission_df.to_json(submission_file_path, orient=\"records\", lines=True)\n",
        "\n",
        "# # Zip the JSON file\n",
        "# with zipfile.ZipFile(\"submissiondev.zip\", \"w\") as zipf:\n",
        "#     zipf.write(submission_file_path, arcname=\"submissiondev.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLFUyRsv5B0W"
      },
      "source": [
        "## Word2Vec(spacy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35mDLzId5B0W",
        "outputId": "8593450a-89bd-461b-d0b7-1df14e0d1628"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-01-06 13:30:37.401820: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-06 13:30:37.401872: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-06 13:30:37.403174: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-06 13:30:38.560548: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-md==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.6.0/en_core_web_md-3.6.0-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[91mâ”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/42.8 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Could not install packages due to an OSError: [Errno 28] No space left on device\n",
            "\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBpfu0Mr5B0X"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "# Tokenize and extract word vectors using spaCy\n",
        "def spacy_word_vectors(text):\n",
        "    doc = nlp(text)\n",
        "    return doc.vector\n",
        "\n",
        "# Apply spaCy word vectors extraction to the training set\n",
        "X_train_spacy = [spacy_word_vectors(text) for text in X_train_over]\n",
        "\n",
        "# Apply spaCy word vectors extraction to the validation set\n",
        "X_valid_spacy = [spacy_word_vectors(text) for text in X_valid]\n",
        "\n",
        "# Apply spaCy word vectors extraction to the test set\n",
        "X_test_spacy = [spacy_word_vectors(text) for text in X_test]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0WHi6Jh5B0X"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ5WSXYY5B0X",
        "outputId": "e1b80207-b859-42c6-f058-049ee6b2d652"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Accuracy on Validation Set: 0.88\n",
            "Classification Report for SVM on Validation Set:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1     0.9407    0.9250    0.9328       120\n",
            "           2     0.6923    0.7826    0.7347        23\n",
            "           3     0.5000    0.4286    0.4615         7\n",
            "\n",
            "    accuracy                         0.8800       150\n",
            "   macro avg     0.7110    0.7121    0.7097       150\n",
            "weighted avg     0.8820    0.8800    0.8804       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_svm = SVC(C=1, kernel='linear')\n",
        "model_svm.fit(X_train_spacy, y_train_over)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_pred_valid = model_svm.predict(X_valid_spacy)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_test = model_svm.predict(X_test_spacy)\n",
        "\n",
        "# Evaluation on the validation set\n",
        "accuracy_svm_valid = accuracy_score(y_valid, y_pred_valid)\n",
        "classification_report_svm_valid = classification_report(y_valid, y_pred_valid, digits = 4)\n",
        "\n",
        "print(f'SVM Accuracy on Validation Set: {accuracy_svm_valid}')\n",
        "print('Classification Report for SVM on Validation Set:\\n', classification_report_svm_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaNoc-NFmTOU",
        "outputId": "3a1b36c9-2ca5-4f14-e52e-d4e49d328ae0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Accuracy on Validation Set: 0.8933333333333333\n",
            "Classification Report for SVM on Validation Set:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1     0.9580    0.9421    0.9500       121\n",
            "           2     0.7083    0.7391    0.7234        23\n",
            "           3     0.4286    0.5000    0.4615         6\n",
            "\n",
            "    accuracy                         0.8933       150\n",
            "   macro avg     0.6983    0.7271    0.7116       150\n",
            "weighted avg     0.8985    0.8933    0.8957       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Predict on the test set\n",
        "y_pred_test = model_svm.predict(X_test_spacy)\n",
        "\n",
        "# Evaluation on the validation set\n",
        "accuracy_svm_test = accuracy_score(y_test, y_pred_test)\n",
        "classification_report_svm_test = classification_report(y_test, y_pred_test, digits = 4)\n",
        "\n",
        "print(f'SVM Accuracy on Validation Set: {accuracy_svm_test}')\n",
        "print('Classification Report for SVM on Validation Set:\\n', classification_report_svm_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2wKhUSb5B0Y"
      },
      "source": [
        "### MNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9six5GRd5B0Y"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaled_train_embed = scaler.fit_transform(X_train_spacy)\n",
        "scaled_val_embed = scaler.transform(X_valid_spacy)\n",
        "scaled_test_embed = scaler.transform(X_test_spacy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESNWt4y15B0Y",
        "outputId": "6563aa53-33b3-4a35-8469-c4cb1bd6e90f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MNB Accuracy on Validation Set: 0.84\n",
            "Classification Report for MNB on Validation Set:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1     0.9316    0.9083    0.9198       120\n",
            "           2     0.5833    0.6087    0.5957        23\n",
            "           3     0.3333    0.4286    0.3750         7\n",
            "\n",
            "    accuracy                         0.8400       150\n",
            "   macro avg     0.6161    0.6485    0.6302       150\n",
            "weighted avg     0.8503    0.8400    0.8447       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Multinomial Naive Bayes (MNB)\n",
        "model_mnb = MultinomialNB()\n",
        "model_mnb.fit(scaled_train_embed, y_train_over)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_pred_valid_mnb = model_mnb.predict(scaled_val_embed)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_test_mnb = model_mnb.predict(scaled_test_embed)\n",
        "\n",
        "# Evaluation on the validation set\n",
        "accuracy_mnb_valid = accuracy_score(y_valid, y_pred_valid_mnb)\n",
        "classification_report_mnb_valid = classification_report(y_valid, y_pred_valid_mnb, digits = 4)\n",
        "\n",
        "print(f'MNB Accuracy on Validation Set: {accuracy_mnb_valid}')\n",
        "print('Classification Report for MNB on Validation Set:\\n', classification_report_mnb_valid)\n",
        "\n",
        "# You can use y_pred_test_mnb for predictions on the test set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xf91SM9Jmkiw",
        "outputId": "1dd10d3b-edd2-4d9e-8ced-db56947f92c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mnb Accuracy on Validation Set: 0.05333333333333334\n",
            "Classification Report for mnb on Validation Set:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1     0.9580    0.9421    0.9500       121\n",
            "           2     0.7083    0.7391    0.7234        23\n",
            "           3     0.4286    0.5000    0.4615         6\n",
            "\n",
            "    accuracy                         0.8933       150\n",
            "   macro avg     0.6983    0.7271    0.7116       150\n",
            "weighted avg     0.8985    0.8933    0.8957       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Predict on the test set\n",
        "y_pred_test = model_mnb.predict(X_test_spacy)\n",
        "\n",
        "# Evaluation on the validation set\n",
        "accuracy_mnb_test = accuracy_score(y_test, y_pred_test)\n",
        "classification_report_mnb_test = classification_report(y_test, y_pred_test, digits = 4)\n",
        "\n",
        "print(f'mnb Accuracy on Validation Set: {accuracy_mnb_test}')\n",
        "print('Classification Report for mnb on Validation Set:\\n', classification_report_svm_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGBp3JyW5B0Z"
      },
      "source": [
        "### LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrLU8KsR5B0Z",
        "outputId": "695000e8-f6e1-4746-9017-d765fa7b0592"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LR Accuracy on Validation Set: 0.8733333333333333\n",
            "Classification Report for LR on Validation Set:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1     0.9402    0.9167    0.9283       120\n",
            "           2     0.6667    0.7826    0.7200        23\n",
            "           3     0.5000    0.4286    0.4615         7\n",
            "\n",
            "    accuracy                         0.8733       150\n",
            "   macro avg     0.7023    0.7093    0.7033       150\n",
            "weighted avg     0.8777    0.8733    0.8746       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Logistic Regression (LR)\n",
        "model_lr = LogisticRegression(max_iter=1000)\n",
        "model_lr.fit(X_train_spacy, y_train_over)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_pred_valid_lr = model_lr.predict(X_valid_spacy)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_test_lr = model_lr.predict(X_test_spacy)\n",
        "\n",
        "# Evaluation on the validation set\n",
        "accuracy_lr_valid = accuracy_score(y_valid, y_pred_valid_lr)\n",
        "classification_report_lr_valid = classification_report(y_valid, y_pred_valid_lr, digits = 4)\n",
        "\n",
        "print(f'LR Accuracy on Validation Set: {accuracy_lr_valid}')\n",
        "print('Classification Report for LR on Validation Set:\\n', classification_report_lr_valid)\n",
        "\n",
        "# You can use y_pred_test_lr for predictions on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecATUGVnmwSy",
        "outputId": "1788a14e-cca4-4c0b-f489-f6f57131d976"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lr Accuracy on Validation Set: 0.8866666666666667\n",
            "Classification Report for lr on Validation Set:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1     0.9658    0.9339    0.9496       121\n",
            "           2     0.6538    0.7391    0.6939        23\n",
            "           3     0.4286    0.5000    0.4615         6\n",
            "\n",
            "    accuracy                         0.8867       150\n",
            "   macro avg     0.6827    0.7243    0.7017       150\n",
            "weighted avg     0.8965    0.8867    0.8909       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Predict on the test set\n",
        "y_pred_test = model_lr.predict(X_test_spacy)\n",
        "\n",
        "# Evaluation on the validation set\n",
        "accuracy_lr_test = accuracy_score(y_test, y_pred_test)\n",
        "classification_report_lr_test = classification_report(y_test, y_pred_test, digits = 4)\n",
        "\n",
        "print(f'lr Accuracy on Validation Set: {accuracy_lr_test}')\n",
        "print('Classification Report for lr on Validation Set:\\n', classification_report_lr_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViFsQ9KN-TqL"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkbcqiLQ-aBK",
        "outputId": "91769cda-e504-46c3-a596-3d7006c97131"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.86\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.9640    0.8917    0.9264       120\n",
            "           2     0.5556    0.8696    0.6780        23\n",
            "           3     0.6667    0.2857    0.4000         7\n",
            "\n",
            "    accuracy                         0.8600       150\n",
            "   macro avg     0.7287    0.6823    0.6681       150\n",
            "weighted avg     0.8875    0.8600    0.8637       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "# Example: Training individual models\n",
        "model_rf = RandomForestClassifier(n_estimators=1000)  #use class_weight='balanced'\n",
        "model_rf.fit(X_train_spacy, y_train_over)\n",
        "y_pred = model_rf.predict(X_valid_spacy)\n",
        "\n",
        "accuracy = accuracy_score(y_valid, y_pred)\n",
        "report = classification_report(y_valid, y_pred, digits = 4)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)             #estimator 1000--> 0.58      0.57      0.57"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gc2zRZiDnBnJ",
        "outputId": "4f0275bd-dbb7-4fdc-e2df-6b1975e5ac0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rf Accuracy on Validation Set: 0.8733333333333333\n",
            "Classification Report for rf on Validation Set:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1     0.9649    0.9091    0.9362       121\n",
            "           2     0.5882    0.8696    0.7018        23\n",
            "           3     0.5000    0.1667    0.2500         6\n",
            "\n",
            "    accuracy                         0.8733       150\n",
            "   macro avg     0.6844    0.6484    0.6293       150\n",
            "weighted avg     0.8886    0.8733    0.8728       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Predict on the test set\n",
        "y_pred_test = model_rf.predict(X_test_spacy)\n",
        "\n",
        "# Evaluation on the validation set\n",
        "accuracy_rf_test = accuracy_score(y_test, y_pred_test)\n",
        "classification_report_rf_test = classification_report(y_test, y_pred_test, digits = 4)\n",
        "\n",
        "print(f'rf Accuracy on Validation Set: {accuracy_rf_test}')\n",
        "print('Classification Report for rf on Validation Set:\\n', classification_report_rf_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zc1TD3lY5QY4"
      },
      "source": [
        "# Deep Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6bUcjoB5QY5"
      },
      "source": [
        "## BiGRU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUH3F6Oo5QY5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import LSTM,GRU\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KhT1Bc_5QY6"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words = 116000,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n-',\n",
        "                      split=' ', char_level=False, oov_token='<oov>', document_count=0)     #tokenization\n",
        "tokenizer.fit_on_texts(Btrain_over['cleanText'])\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index)+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B93_v8Kh5QY7",
        "outputId": "b65316b1-da1f-4948-9514-843406e30a13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1826\n"
          ]
        }
      ],
      "source": [
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5F9yZ6bZ5QY7",
        "outputId": "f40ac799-f00f-44a4-a147-8e5a8c3bd7c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1825\n",
            "Number of Training Sequences : (315, 256)\n",
            "Number of Validation Sequences : (150, 256)\n",
            "Number of test Sequences : (150, 256)\n"
          ]
        }
      ],
      "source": [
        "max_len = 256\n",
        "# Training Sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(X_train_over)\n",
        "print(len(tokenizer.word_index))\n",
        "train_pad_sequences =  pad_sequences(train_sequences, value=0.0, padding='post', maxlen= max_len)\n",
        "print(\"Number of Training Sequences :\" ,train_pad_sequences.shape)\n",
        "\n",
        "# Validation Sequences\n",
        "validation_sequences = tokenizer.texts_to_sequences(X_valid)\n",
        "validation_pad_sequences =  pad_sequences(validation_sequences, value=0.0, padding='post', maxlen= max_len)\n",
        "print(\"Number of Validation Sequences :\" ,validation_pad_sequences.shape)\n",
        "\n",
        "# Validation Sequences\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "test_pad_sequences =  pad_sequences(test_sequences, value=0.0, padding='post', maxlen= max_len)\n",
        "print(\"Number of test Sequences :\" ,test_pad_sequences.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PC7CUrvb5QY8",
        "outputId": "ad8cab89-0655-45fe-dce2-7cfaabd24d83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1 2]\n",
            "[0 1 2]\n"
          ]
        }
      ],
      "source": [
        "Bval['enc_label'] = Bval['label'] - 1\n",
        "Btrain_over['enc_label'] = Btrain_over['label'] - 1\n",
        "Btest['enc_label'] = Btest['label'] - 1\n",
        "print(Bval['enc_label'].unique())\n",
        "print(Btrain_over['enc_label'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AfC_g7c5QY8",
        "outputId": "0d686006-2af0-4d6d-b03e-6e7832e3d3c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 256, 300)          547800    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 256, 256)          330240    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 65536)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 196611    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1074651 (4.10 MB)\n",
            "Trainable params: 1074651 (4.10 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "num_classes = 3            #### change class number\n",
        "\n",
        "accuracy_threshold = 0.99\n",
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy')>accuracy_threshold):\n",
        "        print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
        "        self.model.stop_training = True\n",
        "\n",
        "acc_callback = myCallback()\n",
        "# Saved the Best Model\n",
        "filepath = \"/content/drive/MyDrive/Colab Notebooks/case/\" + \"OverTaskB_BiGRU_tf.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "# callback list\n",
        "callback_list = [acc_callback, checkpoint]\n",
        "model = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Embedding(vocab_size, 300, input_length = max_len),\n",
        "#tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
        "#tf.keras.layers.MaxPooling1D(5),\n",
        "tf.keras.layers.Bidirectional(GRU(units = 128,return_sequences=True,dropout = 0.2)),\n",
        "tf.keras.layers.Flatten(),\n",
        "tf.keras.layers.Dense(3, activation='softmax')])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvG4QZ865QY8",
        "outputId": "774399de-544e-47b1-cf76-875e9d4d546a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.1958 - accuracy: 0.3175\n",
            "Epoch 1: val_accuracy improved from -inf to 0.15333, saving model to /content/drive/MyDrive/Colab Notebooks/case/OverTaskB_BiGRU_tf.h5\n",
            "10/10 [==============================] - 15s 769ms/step - loss: 1.1958 - accuracy: 0.3175 - val_loss: 1.2379 - val_accuracy: 0.1533\n",
            "Epoch 2/15\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.0391 - accuracy: 0.4794\n",
            "Epoch 2: val_accuracy improved from 0.15333 to 0.18000, saving model to /content/drive/MyDrive/Colab Notebooks/case/OverTaskB_BiGRU_tf.h5\n",
            "10/10 [==============================] - 3s 307ms/step - loss: 1.0391 - accuracy: 0.4794 - val_loss: 1.0991 - val_accuracy: 0.1800\n",
            "Epoch 3/15\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7389 - accuracy: 0.7841\n",
            "Epoch 3: val_accuracy improved from 0.18000 to 0.78667, saving model to /content/drive/MyDrive/Colab Notebooks/case/OverTaskB_BiGRU_tf.h5\n",
            "10/10 [==============================] - 3s 339ms/step - loss: 0.7389 - accuracy: 0.7841 - val_loss: 0.8710 - val_accuracy: 0.7867\n",
            "Epoch 4/15\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3352 - accuracy: 0.9968\n",
            "Reached 99.00% accuracy so we will stop trianing\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.78667 to 0.85333, saving model to /content/drive/MyDrive/Colab Notebooks/case/OverTaskB_BiGRU_tf.h5\n",
            "10/10 [==============================] - 2s 175ms/step - loss: 0.3352 - accuracy: 0.9968 - val_loss: 0.4452 - val_accuracy: 0.8533\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_pad_sequences,\n",
        "    Btrain_over['enc_label'],\n",
        "    epochs=15,\n",
        "    batch_size=32,\n",
        "    validation_data=(validation_pad_sequences, Bval['enc_label']),\n",
        "    verbose=1,\n",
        "    callbacks=callback_list\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpAwvghq5QY8",
        "outputId": "834e3d39-6dcb-4e9a-9cca-a4913cfef8db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 17ms/step\n",
            "F1-Score: 60.27982365829836\n",
            "Accuracy: 85.33333333333334\n"
          ]
        }
      ],
      "source": [
        "# Load the saved model\n",
        "model = load_model(filepath)\n",
        "# prediction\n",
        "y_pred = np.argmax(model.predict(validation_pad_sequences), axis=-1)\n",
        "\n",
        "print(\"F1-Score:\",f1_score(Bval['enc_label'],y_pred,average='macro')*100)\n",
        "print(\"Accuracy:\",accuracy_score(Bval['enc_label'],y_pred)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0kS7Ob65QY9",
        "outputId": "e551b754-045d-4177-9190-929d7a2b9032"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.89      0.93       120\n",
            "           1       0.53      0.87      0.66        23\n",
            "           2       0.50      0.14      0.22         7\n",
            "\n",
            "    accuracy                           0.85       150\n",
            "   macro avg       0.67      0.63      0.60       150\n",
            "weighted avg       0.88      0.85      0.86       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#Show precision and recall per genre\n",
        "report = classification_report(Bval['enc_label'], y_pred)\n",
        "\n",
        "#print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhb56Yr6odEK",
        "outputId": "f89a1ef1-89cc-470c-d0f1-14c587e4a9e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 26ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.92      0.95       121\n",
            "           1       0.60      0.91      0.72        23\n",
            "           2       0.33      0.17      0.22         6\n",
            "\n",
            "    accuracy                           0.89       150\n",
            "   macro avg       0.64      0.67      0.63       150\n",
            "weighted avg       0.90      0.89      0.89       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = np.argmax(model.predict(test_pad_sequences), axis=-1)\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#Show precision and recall per genre\n",
        "report = classification_report(Btest['enc_label'], y_pred)\n",
        "\n",
        "#print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqjvh0m75QY9"
      },
      "source": [
        "## Glove BiLSTM + CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycPdXgEZ5QY9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Load GloVe embeddings\n",
        "glove_file = '/content/drive/MyDrive/Colab Notebooks/case/glove.twitter.27B.100d.txt'  # Specify the path to your GloVe file\n",
        "word2vec_output_file = '/content/drive/MyDrive/Colab Notebooks/case/glove.twitter.27B.100d.word2vec'\n",
        "glove2word2vec(glove_file, word2vec_output_file)\n",
        "glove_model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-uGK5FL5QY-"
      },
      "outputs": [],
      "source": [
        "# Create an embedding matrix\n",
        "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, 100))  # Assuming GloVe embeddings are 300-dimensional\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in glove_model:\n",
        "        embedding_matrix[i] = glove_model[word]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_kEzJAE5QY-"
      },
      "outputs": [],
      "source": [
        "folderpath = \"/content/drive/MyDrive/Colab Notebooks/case/TaskB\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wC2tKWKo5QY-",
        "outputId": "e857ea16-a4cc-42cc-ea8b-0a9c2b3aaa27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 256, 100)          182600    \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirecti  (None, 256, 128)          84480     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 254, 64)           24640     \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1  (None, 84, 64)            0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 5376)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               688256    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 980363 (3.74 MB)\n",
            "Trainable params: 797763 (3.04 MB)\n",
            "Non-trainable params: 182600 (713.28 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "\n",
        "num_classes = 3            #### change class number\n",
        "\n",
        "accuracy_threshold = 0.99\n",
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy')>accuracy_threshold):\n",
        "        print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
        "        self.model.stop_training = True\n",
        "\n",
        "acc_callback = myCallback()\n",
        "# Saved the Best Model\n",
        "filepath = folderpath + \"Overglovebilstmcnn.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "# callback list\n",
        "callback_list = [acc_callback, checkpoint]\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(tokenizer.word_index) + 1, 100, input_length=max_len, weights=[embedding_matrix], trainable=False))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Conv1D(64, 3, activation='relu'))\n",
        "model.add(MaxPooling1D(3))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(3, activation='softmax'))  # Adjust for binary/multi-class classification\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpl053Ru5QY-"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHiXuiwQ5QY_",
        "outputId": "f0e6d180-2cfd-4b49-e345-b07b786436fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.0919 - accuracy: 0.3302\n",
            "Epoch 1: val_accuracy improved from -inf to 0.72000, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBOverglovebilstmcnn.h5\n",
            "10/10 [==============================] - 18s 412ms/step - loss: 1.0919 - accuracy: 0.3302 - val_loss: 1.0624 - val_accuracy: 0.7200\n",
            "Epoch 2/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 1.0224 - accuracy: 0.4861\n",
            "Epoch 2: val_accuracy improved from 0.72000 to 0.77333, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBOverglovebilstmcnn.h5\n",
            "10/10 [==============================] - 1s 83ms/step - loss: 1.0098 - accuracy: 0.5016 - val_loss: 1.0102 - val_accuracy: 0.7733\n",
            "Epoch 3/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.8144 - accuracy: 0.6840\n",
            "Epoch 3: val_accuracy improved from 0.77333 to 0.78000, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBOverglovebilstmcnn.h5\n",
            "10/10 [==============================] - 1s 79ms/step - loss: 0.8138 - accuracy: 0.6730 - val_loss: 0.8603 - val_accuracy: 0.7800\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5831 - accuracy: 0.7810\n",
            "Epoch 4: val_accuracy improved from 0.78000 to 0.82667, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBOverglovebilstmcnn.h5\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.5831 - accuracy: 0.7810 - val_loss: 0.6943 - val_accuracy: 0.8267\n",
            "Epoch 5/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3907 - accuracy: 0.8542\n",
            "Epoch 5: val_accuracy did not improve from 0.82667\n",
            "10/10 [==============================] - 1s 84ms/step - loss: 0.3805 - accuracy: 0.8635 - val_loss: 0.7189 - val_accuracy: 0.7867\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2490 - accuracy: 0.9111\n",
            "Epoch 6: val_accuracy did not improve from 0.82667\n",
            "10/10 [==============================] - 1s 82ms/step - loss: 0.2490 - accuracy: 0.9111 - val_loss: 0.8100 - val_accuracy: 0.7000\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1794 - accuracy: 0.9397\n",
            "Epoch 7: val_accuracy did not improve from 0.82667\n",
            "10/10 [==============================] - 1s 68ms/step - loss: 0.1794 - accuracy: 0.9397 - val_loss: 0.8430 - val_accuracy: 0.6933\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0920 - accuracy: 0.9714\n",
            "Epoch 8: val_accuracy did not improve from 0.82667\n",
            "10/10 [==============================] - 1s 71ms/step - loss: 0.0920 - accuracy: 0.9714 - val_loss: 0.7603 - val_accuracy: 0.7733\n",
            "Epoch 9/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0614 - accuracy: 0.9931\n",
            "Reached 99.00% accuracy so we will stop trianing\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.82667\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0590 - accuracy: 0.9937 - val_loss: 1.2547 - val_accuracy: 0.5800\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_pad_sequences,\n",
        "    Btrain_over['enc_label'],\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(validation_pad_sequences, Bval['enc_label']),\n",
        "    verbose=1,\n",
        "    callbacks=callback_list\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEHLlPOO5QY_",
        "outputId": "71d6a12e-e677-4674-e2b4-e77c7c0abb74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 2s 18ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9231    0.9000    0.9114       120\n",
            "           1     0.4688    0.6522    0.5455        23\n",
            "           2     1.0000    0.1429    0.2500         7\n",
            "\n",
            "    accuracy                         0.8267       150\n",
            "   macro avg     0.7973    0.5650    0.5689       150\n",
            "weighted avg     0.8570    0.8267    0.8244       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(validation_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Bval['enc_label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1bCBNAio6E7",
        "outputId": "3f8adfb1-6346-4de4-d385-edb29803c785"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 4s 16ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9180    0.9256    0.9218       121\n",
            "           1     0.5833    0.6087    0.5957        23\n",
            "           2     0.2500    0.1667    0.2000         6\n",
            "\n",
            "    accuracy                         0.8467       150\n",
            "   macro avg     0.5838    0.5670    0.5725       150\n",
            "weighted avg     0.8400    0.8467    0.8429       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(test_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Btest['enc_label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mirYQe9y5QY_"
      },
      "source": [
        "## Glove BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzNcyCSn5QY_",
        "outputId": "b9445b65-1986-4661-c544-bbc5bc6b04e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 256, 100)          182600    \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirecti  (None, 256, 128)          84480     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 32768)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               4194432   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4461899 (17.02 MB)\n",
            "Trainable params: 4279299 (16.32 MB)\n",
            "Non-trainable params: 182600 (713.28 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "num_classes = 3            #### change class number\n",
        "\n",
        "accuracy_threshold = 0.99\n",
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy')>accuracy_threshold):\n",
        "        print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
        "        self.model.stop_training = True\n",
        "\n",
        "acc_callback = myCallback()\n",
        "# Saved the Best Model\n",
        "filepath = folderpath + \"Overglovebilstm.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "# callback list\n",
        "callback_list = [acc_callback, checkpoint]\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(tokenizer.word_index) + 1, 100, input_length=max_len, weights=[embedding_matrix], trainable=False))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "# model.add(Conv1D(64, 3, activation='relu'))\n",
        "# model.add(MaxPooling1D(3))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(3, activation='softmax'))  # Adjust for binary/multi-class classification\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rqyrw425QZA",
        "outputId": "813b4871-9fa6-4ed1-db07-aa5825b5ab4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.0340 - accuracy: 0.4698\n",
            "Epoch 1: val_accuracy improved from -inf to 0.65333, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBOverglovebilstm.h5\n",
            "10/10 [==============================] - 14s 486ms/step - loss: 1.0340 - accuracy: 0.4698 - val_loss: 1.0957 - val_accuracy: 0.6533\n",
            "Epoch 2/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.7662 - accuracy: 0.6389\n",
            "Epoch 2: val_accuracy improved from 0.65333 to 0.80000, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBOverglovebilstm.h5\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.7409 - accuracy: 0.6540 - val_loss: 0.8111 - val_accuracy: 0.8000\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4485 - accuracy: 0.8349\n",
            "Epoch 3: val_accuracy improved from 0.80000 to 0.82667, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBOverglovebilstm.h5\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 0.4485 - accuracy: 0.8349 - val_loss: 0.7696 - val_accuracy: 0.8267\n",
            "Epoch 4/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.2873 - accuracy: 0.9132\n",
            "Epoch 4: val_accuracy did not improve from 0.82667\n",
            "10/10 [==============================] - 1s 67ms/step - loss: 0.2917 - accuracy: 0.9079 - val_loss: 0.8054 - val_accuracy: 0.7867\n",
            "Epoch 5/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1612 - accuracy: 0.9583\n",
            "Epoch 5: val_accuracy did not improve from 0.82667\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.1644 - accuracy: 0.9524 - val_loss: 0.8299 - val_accuracy: 0.7400\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1016 - accuracy: 0.9810\n",
            "Epoch 6: val_accuracy did not improve from 0.82667\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.1016 - accuracy: 0.9810 - val_loss: 0.7867 - val_accuracy: 0.8000\n",
            "Epoch 7/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0586 - accuracy: 0.9931\n",
            "Reached 99.00% accuracy so we will stop trianing\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.82667 to 0.83333, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBOverglovebilstm.h5\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.0572 - accuracy: 0.9937 - val_loss: 0.7960 - val_accuracy: 0.8333\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_pad_sequences,\n",
        "    Btrain_over['enc_label'],\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(validation_pad_sequences, Bval['enc_label']),\n",
        "    verbose=1,\n",
        "    callbacks=callback_list\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIAVfN6o5QZA",
        "outputId": "9798c163-a0a2-42e6-f789-527cf54c80ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 15ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9386    0.8917    0.9145       120\n",
            "           1     0.5312    0.7391    0.6182        23\n",
            "           2     0.2500    0.1429    0.1818         7\n",
            "\n",
            "    accuracy                         0.8333       150\n",
            "   macro avg     0.5733    0.5912    0.5715       150\n",
            "weighted avg     0.8440    0.8333    0.8349       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(validation_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Bval['enc_label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am0jVpHWpbHP",
        "outputId": "7906c9da-ac3a-4e02-955d-54a19ea3ecbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 2s 18ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9649    0.9091    0.9362       121\n",
            "           1     0.5862    0.7391    0.6538        23\n",
            "           2     0.2857    0.3333    0.3077         6\n",
            "\n",
            "    accuracy                         0.8600       150\n",
            "   macro avg     0.6123    0.6605    0.6326       150\n",
            "weighted avg     0.8797    0.8600    0.8677       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(test_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Btest['enc_label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIxFsiXV5QZA"
      },
      "source": [
        "## Glove CNN + BiGRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jfKjIpg5QZB",
        "outputId": "ab8fc45b-49a7-46ed-c812-35a6794b56c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 256)]             0         \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 256, 100)          182600    \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 252, 128)          64128     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPoolin  (None, 50, 128)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirecti  (None, 50, 128)           74496     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               819328    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1149003 (4.38 MB)\n",
            "Trainable params: 966403 (3.69 MB)\n",
            "Non-trainable params: 182600 (713.28 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "num_classes = 3            #### change class number\n",
        "\n",
        "accuracy_threshold = 0.99\n",
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy')>accuracy_threshold):\n",
        "        print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
        "        self.model.stop_training = True\n",
        "\n",
        "acc_callback = myCallback()\n",
        "# Saved the Best Model\n",
        "filepath = folderpath + \"OverTaskBglovebigrucnn.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "# callback list\n",
        "callback_list = [acc_callback, checkpoint]\n",
        "\n",
        "# Model Architecture\n",
        "input_layer = Input(shape=(max_len,), dtype=tf.int32)\n",
        "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_len, trainable=False)(input_layer)\n",
        "\n",
        "# Convolutional Neural Network (CNN)\n",
        "conv1 = Conv1D(128, 5, activation='relu')(embedding_layer)\n",
        "max_pooling = MaxPooling1D(5)(conv1)\n",
        "\n",
        "# Recurrent Neural Network (RNN)\n",
        "bi_gru = Bidirectional(GRU(units=64, return_sequences=True, dropout=0.2))(max_pooling)\n",
        "\n",
        "# Flatten and Dense Layers\n",
        "flatten = Flatten()(bi_gru)\n",
        "dense1 = Dense(128, activation='relu')(flatten)\n",
        "dropout1 = Dropout(0.2)(dense1)\n",
        "dense2 = Dense(64, activation='relu')(dropout1)\n",
        "dropout2 = Dropout(0.2)(dense2)\n",
        "\n",
        "# Output Layer\n",
        "output_layer = Dense(3, activation='softmax')(dropout2)\n",
        "\n",
        "# Model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlDe6G4k5QZB",
        "outputId": "9878cb3a-974e-4724-dc41-06620d4cc9dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.1081 - accuracy: 0.3937\n",
            "Epoch 1: val_accuracy improved from -inf to 0.06667, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBOverTaskBglovebigrucnn.h5\n",
            "10/10 [==============================] - 18s 327ms/step - loss: 1.1081 - accuracy: 0.3937 - val_loss: 1.1650 - val_accuracy: 0.0667\n",
            "Epoch 2/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 1.0548 - accuracy: 0.4722\n",
            "Epoch 2: val_accuracy improved from 0.06667 to 0.78667, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBOverTaskBglovebigrucnn.h5\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 1.0512 - accuracy: 0.4667 - val_loss: 0.9667 - val_accuracy: 0.7867\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.8568 - accuracy: 0.6603\n",
            "Epoch 3: val_accuracy did not improve from 0.78667\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.8568 - accuracy: 0.6603 - val_loss: 0.9066 - val_accuracy: 0.7667\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5194 - accuracy: 0.7968\n",
            "Epoch 4: val_accuracy improved from 0.78667 to 0.80667, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBOverTaskBglovebigrucnn.h5\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.5194 - accuracy: 0.7968 - val_loss: 0.7014 - val_accuracy: 0.8067\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2212 - accuracy: 0.9302\n",
            "Epoch 5: val_accuracy improved from 0.80667 to 0.82000, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBOverTaskBglovebigrucnn.h5\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2212 - accuracy: 0.9302 - val_loss: 0.6895 - val_accuracy: 0.8200\n",
            "Epoch 6/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1253 - accuracy: 0.9757\n",
            "Epoch 6: val_accuracy did not improve from 0.82000\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.1262 - accuracy: 0.9746 - val_loss: 0.7591 - val_accuracy: 0.7733\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0541 - accuracy: 0.9841\n",
            "Epoch 7: val_accuracy did not improve from 0.82000\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0541 - accuracy: 0.9841 - val_loss: 0.8418 - val_accuracy: 0.7867\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.9968\n",
            "Reached 99.00% accuracy so we will stop trianing\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.82000\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0317 - accuracy: 0.9968 - val_loss: 1.0044 - val_accuracy: 0.8200\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_pad_sequences,\n",
        "    Btrain_over['enc_label'],\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(validation_pad_sequences, Bval['enc_label']),\n",
        "    verbose=1,\n",
        "    callbacks=callback_list\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGgNMpaJ5QZB",
        "outputId": "504bbaa8-0f0e-4f72-82b6-5fbad2899192"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 2s 15ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9626    0.8583    0.9075       120\n",
            "           1     0.4651    0.8696    0.6061        23\n",
            "           2     0.0000    0.0000    0.0000         7\n",
            "\n",
            "    accuracy                         0.8200       150\n",
            "   macro avg     0.4759    0.5760    0.5045       150\n",
            "weighted avg     0.8414    0.8200    0.8189       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(validation_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Bval['enc_label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGSHjTDQp53-",
        "outputId": "62f04cef-9776-42a7-f049-fe0a35a0702e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 8ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9737    0.9174    0.9447       121\n",
            "           1     0.5556    0.8696    0.6780        23\n",
            "           2     0.0000    0.0000    0.0000         6\n",
            "\n",
            "    accuracy                         0.8733       150\n",
            "   macro avg     0.5097    0.5956    0.5409       150\n",
            "weighted avg     0.8706    0.8733    0.8660       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(test_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Btest['enc_label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYECII205QZB"
      },
      "source": [
        "## FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uF3_uVBM5QZC"
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlopen\n",
        "import gzip\n",
        "\n",
        "# get the vectors\n",
        "file = gzip.open(urlopen('https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ml.300.vec.gz'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gs3tnuEc5QZC"
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlopen\n",
        "import gzip\n",
        "\n",
        "# get the vectors\n",
        "file = gzip.open(urlopen('https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ml.300.vec.gz'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YXcfBaT5QZD"
      },
      "outputs": [],
      "source": [
        "vocab_and_vectors = {}\n",
        "# put words as dict indexes and vectors as words values\n",
        "for line in file:\n",
        "  values = line.split()\n",
        "  word = values [0].decode('utf-8')\n",
        "  vector = np.asarray(values[1:], dtype='float32')\n",
        "  vocab_and_vectors[word] = vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmGCTBjr5QZD"
      },
      "outputs": [],
      "source": [
        "embedding_matrixx = np.zeros((vocab_size, 300))\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = vocab_and_vectors.get(word)\n",
        "  # words that cannot be found will be set to 0\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrixx[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8Bw1KmA5QZD"
      },
      "source": [
        "## FastText CNN + BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrZ6po4o5QZD",
        "outputId": "cdfe9bbb-afd4-45e0-fc0b-8bbd8c278712"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 256, 300)          547800    \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 254, 128)          115328    \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPoolin  (None, 84, 128)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirecti  (None, 84, 512)           788480    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 43008)             0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 3)                 129027    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1580635 (6.03 MB)\n",
            "Trainable params: 1032835 (3.94 MB)\n",
            "Non-trainable params: 547800 (2.09 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "num_classes = 3\n",
        "\n",
        "accuracy_threshold = 0.99\n",
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy')>accuracy_threshold):\n",
        "        print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
        "        self.model.stop_training = True\n",
        "\n",
        "acc_callback = myCallback()\n",
        "# Saved the Best Model\n",
        "filepath = folderpath +\"OverTaskBfasttext_CNNBiLSTMModel.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "# callback list\n",
        "callback_list = [acc_callback, checkpoint]\n",
        "model = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Embedding(vocab_size, 300, weights=[embedding_matrixx],trainable=False, input_length = max_len),\n",
        "tf.keras.layers.Conv1D(128, 3, activation='relu'),\n",
        "tf.keras.layers.MaxPooling1D(3),\n",
        "tf.keras.layers.Bidirectional(LSTM(units = 256,return_sequences=True,dropout = 0.2)),\n",
        "tf.keras.layers.Flatten(),\n",
        "tf.keras.layers.Dense(3, activation='softmax')])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZdeOHmw5QZE",
        "outputId": "821a6f8e-4592-4d01-a5d0-697c7ab09e32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.0900 - accuracy: 0.3619\n",
            "Epoch 1: val_accuracy improved from -inf to 0.17333, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBOverTaskBfasttext_CNNBiLSTMModel.h5\n",
            "10/10 [==============================] - 10s 226ms/step - loss: 1.0900 - accuracy: 0.3619 - val_loss: 1.2296 - val_accuracy: 0.1733\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.9506 - accuracy: 0.4921\n",
            "Epoch 2: val_accuracy did not improve from 0.17333\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.9506 - accuracy: 0.4921 - val_loss: 1.2329 - val_accuracy: 0.1600\n",
            "Epoch 3/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6345 - accuracy: 0.6771\n",
            "Epoch 3: val_accuracy did not improve from 0.17333\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.6301 - accuracy: 0.6857 - val_loss: 1.3338 - val_accuracy: 0.1533\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4504 - accuracy: 0.7778\n",
            "Epoch 4: val_accuracy did not improve from 0.17333\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.4504 - accuracy: 0.7778 - val_loss: 1.1878 - val_accuracy: 0.1533\n",
            "Epoch 5/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3582 - accuracy: 0.8160\n",
            "Epoch 5: val_accuracy improved from 0.17333 to 0.84000, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBOverTaskBfasttext_CNNBiLSTMModel.h5\n",
            "10/10 [==============================] - 1s 94ms/step - loss: 0.3576 - accuracy: 0.8190 - val_loss: 1.0856 - val_accuracy: 0.8400\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2369 - accuracy: 0.9016\n",
            "Epoch 6: val_accuracy did not improve from 0.84000\n",
            "10/10 [==============================] - 1s 71ms/step - loss: 0.2369 - accuracy: 0.9016 - val_loss: 1.0416 - val_accuracy: 0.8400\n",
            "Epoch 7/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1879 - accuracy: 0.9167\n",
            "Epoch 7: val_accuracy improved from 0.84000 to 0.84667, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBOverTaskBfasttext_CNNBiLSTMModel.h5\n",
            "10/10 [==============================] - 1s 87ms/step - loss: 0.1828 - accuracy: 0.9206 - val_loss: 0.8921 - val_accuracy: 0.8467\n",
            "Epoch 8/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0818 - accuracy: 0.9757\n",
            "Epoch 8: val_accuracy did not improve from 0.84667\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.0769 - accuracy: 0.9778 - val_loss: 1.7723 - val_accuracy: 0.1800\n",
            "Epoch 9/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0331 - accuracy: 0.9896\n",
            "Reached 99.00% accuracy so we will stop trianing\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.84667\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.0314 - accuracy: 0.9905 - val_loss: 1.6344 - val_accuracy: 0.6000\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_pad_sequences,\n",
        "    Btrain_over['enc_label'],\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(validation_pad_sequences, Bval['enc_label']),\n",
        "    verbose=1,\n",
        "    callbacks=callback_list\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLGppINY5QZE",
        "outputId": "2e5dc3e1-6261-4e54-a427-268a22da3036"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 2s 12ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8846    0.9583    0.9200       120\n",
            "           1     0.6875    0.4783    0.5641        23\n",
            "           2     0.2500    0.1429    0.1818         7\n",
            "\n",
            "    accuracy                         0.8467       150\n",
            "   macro avg     0.6074    0.5265    0.5553       150\n",
            "weighted avg     0.8248    0.8467    0.8310       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(validation_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Bval['enc_label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foVgHskhqqtR",
        "outputId": "b2f8314c-a3a6-4341-cd91-005416a2938d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 2s 18ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8992    0.9587    0.9280       121\n",
            "           1     0.6875    0.4783    0.5641        23\n",
            "           2     0.6000    0.5000    0.5455         6\n",
            "\n",
            "    accuracy                         0.8667       150\n",
            "   macro avg     0.7289    0.6456    0.6792       150\n",
            "weighted avg     0.8548    0.8667    0.8569       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(test_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Btest['enc_label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qe3VimDM5QZF"
      },
      "source": [
        "## FastText CNN + BiGRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKwufNti5QZF",
        "outputId": "805e7753-c4d4-4311-b9d0-97fd5daeb9d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 256)]             0         \n",
            "                                                                 \n",
            " embedding_7 (Embedding)     (None, 256, 300)          547800    \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 252, 128)          192128    \n",
            "                                                                 \n",
            " max_pooling1d_4 (MaxPoolin  (None, 50, 128)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirecti  (None, 50, 128)           74496     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 128)               819328    \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1642203 (6.26 MB)\n",
            "Trainable params: 1094403 (4.17 MB)\n",
            "Non-trainable params: 547800 (2.09 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "num_classes = 3\n",
        "\n",
        "accuracy_threshold = 0.99\n",
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy')>accuracy_threshold):\n",
        "        print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
        "        self.model.stop_training = True\n",
        "\n",
        "acc_callback = myCallback()\n",
        "# Saved the Best Model\n",
        "filepath = folderpath +\"OverTaskBfasttext_CNNBiGRU.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "# callback list\n",
        "callback_list = [acc_callback, checkpoint]\n",
        "\n",
        "# Model Architecture\n",
        "input_layer = Input(shape=(max_len,), dtype=tf.int32)\n",
        "embedding_layer = Embedding(vocab_size, 300, weights=[embedding_matrixx], input_length=max_len, trainable=False)(input_layer)\n",
        "\n",
        "# Convolutional Neural Network (CNN)\n",
        "conv1 = Conv1D(128, 5, activation='relu')(embedding_layer)\n",
        "max_pooling = MaxPooling1D(5)(conv1)\n",
        "\n",
        "# Recurrent Neural Network (RNN)\n",
        "bi_gru = Bidirectional(GRU(units=64, return_sequences=True, dropout=0.2))(max_pooling)\n",
        "\n",
        "# Flatten and Dense Layers\n",
        "flatten = Flatten()(bi_gru)\n",
        "dense1 = Dense(128, activation='relu')(flatten)\n",
        "# dropout1 = Dropout(0.2)(dense1)\n",
        "dense2 = Dense(64, activation='relu')(dense1)\n",
        "# dropout2 = Dropout(0.2)(dense2)\n",
        "\n",
        "# Output Layer\n",
        "output_layer = Dense(3, activation='softmax')(dense2)\n",
        "\n",
        "# Model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcPfO1OI5QZF",
        "outputId": "7a034111-701c-4398-8f75-4c0ae210fa4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.0903 - accuracy: 0.3778\n",
            "Epoch 1: val_accuracy improved from -inf to 0.15333, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBOverTaskBfasttext_CNNBiGRU.h5\n",
            "10/10 [==============================] - 7s 154ms/step - loss: 1.0903 - accuracy: 0.3778 - val_loss: 1.1039 - val_accuracy: 0.1533\n",
            "Epoch 2/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 1.0013 - accuracy: 0.5000\n",
            "Epoch 2: val_accuracy improved from 0.15333 to 0.18000, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBOverTaskBfasttext_CNNBiGRU.h5\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 0.9905 - accuracy: 0.5238 - val_loss: 1.1672 - val_accuracy: 0.1800\n",
            "Epoch 3/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6656 - accuracy: 0.8125\n",
            "Epoch 3: val_accuracy did not improve from 0.18000\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6485 - accuracy: 0.8159 - val_loss: 1.4258 - val_accuracy: 0.1733\n",
            "Epoch 4/20\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.3092 - accuracy: 0.8945\n",
            "Epoch 4: val_accuracy improved from 0.18000 to 0.19333, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBOverTaskBfasttext_CNNBiGRU.h5\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.3027 - accuracy: 0.9016 - val_loss: 1.3604 - val_accuracy: 0.1933\n",
            "Epoch 5/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1009 - accuracy: 0.9792\n",
            "Epoch 5: val_accuracy did not improve from 0.19333\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.0970 - accuracy: 0.9810 - val_loss: 1.5238 - val_accuracy: 0.1733\n",
            "Epoch 6/20\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.0325 - accuracy: 0.9883\n",
            "Reached 99.00% accuracy so we will stop trianing\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.19333 to 0.20667, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBOverTaskBfasttext_CNNBiGRU.h5\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0326 - accuracy: 0.9905 - val_loss: 1.6265 - val_accuracy: 0.2067\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(\n",
        "    train_pad_sequences,\n",
        "    Btrain_over['enc_label'],\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(validation_pad_sequences, Bval['enc_label']),\n",
        "    verbose=1,\n",
        "    callbacks=callback_list\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_96f7JHn5QZF",
        "outputId": "58ffd148-a5e9-4144-aad2-a44ce39f395b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 7ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6087    0.1167    0.1958       120\n",
            "           1     0.1290    0.6957    0.2177        23\n",
            "           2     0.3333    0.1429    0.2000         7\n",
            "\n",
            "    accuracy                         0.2067       150\n",
            "   macro avg     0.3570    0.3184    0.2045       150\n",
            "weighted avg     0.5223    0.2067    0.1994       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(validation_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Bval['enc_label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uS6gpYoGrOxq",
        "outputId": "d3a5eb9f-b2ff-4ac9-f99f-9f9f507f16b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 7ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5833    0.1157    0.1931       121\n",
            "           1     0.1138    0.6087    0.1918        23\n",
            "           2     0.3333    0.1667    0.2222         6\n",
            "\n",
            "    accuracy                         0.1933       150\n",
            "   macro avg     0.3435    0.2970    0.2024       150\n",
            "weighted avg     0.5013    0.1933    0.1941       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(test_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Btest['enc_label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgQ3UuHg5QZG"
      },
      "source": [
        "## FastText BiGRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALeM5ZxG5QZG",
        "outputId": "d6b70b1c-c98c-4a80-f45c-eab5e19b77ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_8 (Embedding)     (None, 256, 300)          547800    \n",
            "                                                                 \n",
            " bidirectional_8 (Bidirecti  (None, 256, 512)          857088    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 131072)            0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 3)                 393219    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1798107 (6.86 MB)\n",
            "Trainable params: 1250307 (4.77 MB)\n",
            "Non-trainable params: 547800 (2.09 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "num_classes = 3\n",
        "\n",
        "accuracy_threshold = 0.99\n",
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy')>accuracy_threshold):\n",
        "        print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
        "        self.model.stop_training = True\n",
        "\n",
        "acc_callback = myCallback()\n",
        "# Saved the Best Model\n",
        "filepath = folderpath +\"OverTaskBfasttext_BiGRUModel_FastText.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "# callback list\n",
        "callback_list = [acc_callback, checkpoint]\n",
        "model = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Embedding(vocab_size, 300, weights=[embedding_matrixx],trainable=False, input_length = max_len),\n",
        "# tf.keras.layers.Conv1D(128, 2, activation='relu'),\n",
        "# tf.keras.layers.MaxPooling1D(2),\n",
        "tf.keras.layers.Bidirectional(GRU(units = 256,return_sequences=True,dropout = 0.2)),\n",
        "tf.keras.layers.Flatten(),\n",
        "tf.keras.layers.Dense(3, activation='softmax')])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJImWmKi5QZG",
        "outputId": "affbf601-560b-424c-a602-c27a81358e3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 1.0642 - accuracy: 0.4062\n",
            "Epoch 1: val_accuracy improved from -inf to 0.16667, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBOverTaskBfasttext_BiGRUModel_FastText.h5\n",
            "10/10 [==============================] - 6s 222ms/step - loss: 1.0571 - accuracy: 0.4317 - val_loss: 1.4895 - val_accuracy: 0.1667\n",
            "Epoch 2/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.8917 - accuracy: 0.6042\n",
            "Epoch 2: val_accuracy did not improve from 0.16667\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8769 - accuracy: 0.6127 - val_loss: 1.1176 - val_accuracy: 0.1400\n",
            "Epoch 3/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6622 - accuracy: 0.7326\n",
            "Epoch 3: val_accuracy did not improve from 0.16667\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.6526 - accuracy: 0.7397 - val_loss: 1.3723 - val_accuracy: 0.1333\n",
            "Epoch 4/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4338 - accuracy: 0.8368\n",
            "Epoch 4: val_accuracy improved from 0.16667 to 0.19333, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBOverTaskBfasttext_BiGRUModel_FastText.h5\n",
            "10/10 [==============================] - 1s 69ms/step - loss: 0.4377 - accuracy: 0.8317 - val_loss: 1.1369 - val_accuracy: 0.1933\n",
            "Epoch 5/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3259 - accuracy: 0.8681\n",
            "Epoch 5: val_accuracy improved from 0.19333 to 0.84667, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBOverTaskBfasttext_BiGRUModel_FastText.h5\n",
            "10/10 [==============================] - 1s 78ms/step - loss: 0.3219 - accuracy: 0.8667 - val_loss: 0.8904 - val_accuracy: 0.8467\n",
            "Epoch 6/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.2153 - accuracy: 0.9444\n",
            "Epoch 6: val_accuracy did not improve from 0.84667\n",
            "10/10 [==============================] - 1s 67ms/step - loss: 0.2162 - accuracy: 0.9397 - val_loss: 1.0085 - val_accuracy: 0.7000\n",
            "Epoch 7/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1402 - accuracy: 0.9618\n",
            "Epoch 7: val_accuracy did not improve from 0.84667\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.1388 - accuracy: 0.9619 - val_loss: 1.0290 - val_accuracy: 0.7133\n",
            "Epoch 8/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1072 - accuracy: 0.9583\n",
            "Epoch 8: val_accuracy did not improve from 0.84667\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.1183 - accuracy: 0.9524 - val_loss: 1.4400 - val_accuracy: 0.1800\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1352 - accuracy: 0.9651\n",
            "Epoch 9: val_accuracy did not improve from 0.84667\n",
            "10/10 [==============================] - 1s 68ms/step - loss: 0.1352 - accuracy: 0.9651 - val_loss: 1.7238 - val_accuracy: 0.1533\n",
            "Epoch 10/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1032 - accuracy: 0.9792\n",
            "Epoch 10: val_accuracy did not improve from 0.84667\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.1075 - accuracy: 0.9746 - val_loss: 1.0749 - val_accuracy: 0.5533\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 0.9810\n",
            "Epoch 11: val_accuracy did not improve from 0.84667\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 0.0838 - accuracy: 0.9810 - val_loss: 1.0188 - val_accuracy: 0.8200\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9841\n",
            "Epoch 12: val_accuracy did not improve from 0.84667\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.0561 - accuracy: 0.9841 - val_loss: 1.3705 - val_accuracy: 0.1867\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 0.9905\n",
            "Reached 99.00% accuracy so we will stop trianing\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.84667\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 0.0394 - accuracy: 0.9905 - val_loss: 1.4811 - val_accuracy: 0.1933\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_pad_sequences,\n",
        "    Btrain_over['enc_label'],\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(validation_pad_sequences, Bval['enc_label']),\n",
        "    verbose=1,\n",
        "    callbacks=callback_list\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L31ppMhx5QZG",
        "outputId": "2ec7999a-3caf-40e1-8b1c-d2358c5f912f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 23ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9237    0.9083    0.9160       120\n",
            "           1     0.6000    0.6522    0.6250        23\n",
            "           2     0.4286    0.4286    0.4286         7\n",
            "\n",
            "    accuracy                         0.8467       150\n",
            "   macro avg     0.6508    0.6630    0.6565       150\n",
            "weighted avg     0.8510    0.8467    0.8486       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(validation_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Bval['enc_label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZojrXXIrn0S",
        "outputId": "b022804c-29e9-45d4-f367-d081a5ef0986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 23ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9200    0.9504    0.9350       121\n",
            "           1     0.6667    0.6087    0.6364        23\n",
            "           2     0.2500    0.1667    0.2000         6\n",
            "\n",
            "    accuracy                         0.8667       150\n",
            "   macro avg     0.6122    0.5753    0.5904       150\n",
            "weighted avg     0.8544    0.8667    0.8598       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(test_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Btest['enc_label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXYVw1Zo5QZH"
      },
      "source": [
        "## FastText BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3NB3rgl5QZI",
        "outputId": "240fd968-de06-4f2f-bff6-5681ccf027a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, 256, 300)          547800    \n",
            "                                                                 \n",
            " bidirectional_9 (Bidirecti  (None, 256, 128)          186880    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 32768)             0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 128)               4194432   \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4929499 (18.80 MB)\n",
            "Trainable params: 4381699 (16.71 MB)\n",
            "Non-trainable params: 547800 (2.09 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "num_classes = 3            #### change class number\n",
        "\n",
        "accuracy_threshold = 0.99\n",
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy')>accuracy_threshold):\n",
        "        print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
        "        self.model.stop_training = True\n",
        "\n",
        "acc_callback = myCallback()\n",
        "# Saved the Best Model\n",
        "filepath = folderpath + \"OverFastTextglovebilstm.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "# callback list\n",
        "callback_list = [acc_callback, checkpoint]\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 300, weights=[embedding_matrixx],trainable=False, input_length = max_len))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "# model.add(Conv1D(64, 3, activation='relu'))\n",
        "# model.add(MaxPooling1D(3))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(3, activation='softmax'))  # Adjust for binary/multi-class classification\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQzpGpfe5QZI",
        "outputId": "6ab64c63-e3bd-4260-cee3-cdfbd76ccfa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.0662 - accuracy: 0.4222\n",
            "Epoch 1: val_accuracy improved from -inf to 0.18000, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBOverFastTextglovebilstm.h5\n",
            "10/10 [==============================] - 17s 360ms/step - loss: 1.0662 - accuracy: 0.4222 - val_loss: 1.1599 - val_accuracy: 0.1800\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.9088 - accuracy: 0.5524\n",
            "Epoch 2: val_accuracy did not improve from 0.18000\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.9088 - accuracy: 0.5524 - val_loss: 1.0901 - val_accuracy: 0.1400\n",
            "Epoch 3/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6727 - accuracy: 0.7326\n",
            "Epoch 3: val_accuracy improved from 0.18000 to 0.81333, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBOverFastTextglovebilstm.h5\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.6584 - accuracy: 0.7397 - val_loss: 0.9929 - val_accuracy: 0.8133\n",
            "Epoch 4/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4432 - accuracy: 0.8368\n",
            "Epoch 4: val_accuracy improved from 0.81333 to 0.82667, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBOverFastTextglovebilstm.h5\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.4544 - accuracy: 0.8190 - val_loss: 0.9681 - val_accuracy: 0.8267\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3669 - accuracy: 0.8571\n",
            "Epoch 5: val_accuracy improved from 0.82667 to 0.85333, saving model to /content/drive/MyDrive/Colab Notebooks/case/TaskBOverFastTextglovebilstm.h5\n",
            "10/10 [==============================] - 1s 157ms/step - loss: 0.3669 - accuracy: 0.8571 - val_loss: 0.9665 - val_accuracy: 0.8533\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2484 - accuracy: 0.9111\n",
            "Epoch 6: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 1s 91ms/step - loss: 0.2484 - accuracy: 0.9111 - val_loss: 0.9419 - val_accuracy: 0.8267\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2057 - accuracy: 0.9270\n",
            "Epoch 7: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.2057 - accuracy: 0.9270 - val_loss: 1.0725 - val_accuracy: 0.8400\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.1405 - accuracy: 0.9587\n",
            "Epoch 8: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 1s 83ms/step - loss: 0.1405 - accuracy: 0.9587 - val_loss: 1.0819 - val_accuracy: 0.8400\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0870 - accuracy: 0.9714\n",
            "Epoch 9: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 0.0870 - accuracy: 0.9714 - val_loss: 1.4731 - val_accuracy: 0.2000\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0576 - accuracy: 0.9841\n",
            "Epoch 10: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.0576 - accuracy: 0.9841 - val_loss: 1.6049 - val_accuracy: 0.1867\n",
            "Epoch 11/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0612 - accuracy: 0.9792\n",
            "Epoch 11: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 1s 83ms/step - loss: 0.1017 - accuracy: 0.9714 - val_loss: 1.5259 - val_accuracy: 0.1933\n",
            "Epoch 12/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1380 - accuracy: 0.9583\n",
            "Epoch 12: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.1351 - accuracy: 0.9619 - val_loss: 2.4783 - val_accuracy: 0.1533\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.0672 - accuracy: 0.9841\n",
            "Epoch 13: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 0.0672 - accuracy: 0.9841 - val_loss: 1.2312 - val_accuracy: 0.5667\n",
            "Epoch 14/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0458 - accuracy: 0.9896\n",
            "Epoch 14: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0481 - accuracy: 0.9873 - val_loss: 1.6563 - val_accuracy: 0.1867\n",
            "Epoch 15/20\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0335 - accuracy: 0.9931\n",
            "Reached 99.00% accuracy so we will stop trianing\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0311 - accuracy: 0.9937 - val_loss: 1.5762 - val_accuracy: 0.1933\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_pad_sequences,\n",
        "    Btrain_over['enc_label'],\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(validation_pad_sequences, Bval['enc_label']),\n",
        "    verbose=1,\n",
        "    callbacks=callback_list\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsHU3mp35QZI",
        "outputId": "2457d327-2ae1-4684-f592-c5f6251b3a09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 3s 23ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9244    0.9167    0.9205       120\n",
            "           1     0.6400    0.6957    0.6667        23\n",
            "           2     0.3333    0.2857    0.3077         7\n",
            "\n",
            "    accuracy                         0.8533       150\n",
            "   macro avg     0.6326    0.6327    0.6316       150\n",
            "weighted avg     0.8532    0.8533    0.8530       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(validation_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Bval['enc_label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGgZATSrsb9s",
        "outputId": "00302561-9f2d-4389-db67-475ea920dd43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 16ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9206    0.9587    0.9393       121\n",
            "           1     0.6316    0.5217    0.5714        23\n",
            "           2     0.2000    0.1667    0.1818         6\n",
            "\n",
            "    accuracy                         0.8600       150\n",
            "   macro avg     0.5841    0.5490    0.5642       150\n",
            "weighted avg     0.8475    0.8600    0.8526       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "loaded_model = load_model(filepath)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(test_pad_sequences)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_loaded_model = classification_report(Btest['enc_label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report_loaded_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjjS8O-F5rLr"
      },
      "source": [
        "# ktrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhOZBo8t5rLs",
        "outputId": "0410145c-800c-4f7d-ad18-59316705655f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ktrain\n",
            "  Downloading ktrain-0.39.0.tar.gz (25.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m25.3/25.3 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from ktrain) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.5.3)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ktrain) (2.31.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.3.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ktrain) (23.2)\n",
            "Collecting langdetect (from ktrain)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from ktrain) (0.42.1)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.10/dist-packages (from ktrain) (3.3.2)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from ktrain) (5.2.0)\n",
            "Collecting syntok>1.3.3 (from ktrain)\n",
            "  Downloading syntok-1.4.4-py3-none-any.whl (24 kB)\n",
            "Collecting tika (from ktrain)\n",
            "  Downloading tika-2.6.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers>=4.17.0 in /usr/local/lib/python3.10/dist-packages (from ktrain) (4.35.2)\n",
            "Collecting sentencepiece (from ktrain)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras_bert>=0.86.0 (from ktrain)\n",
            "  Downloading keras-bert-0.89.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting whoosh (from ktrain)\n",
            "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m468.8/468.8 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras_bert>=0.86.0->ktrain) (1.23.5)\n",
            "Collecting keras-transformer==0.40.0 (from keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-transformer-0.40.0.tar.gz (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-pos-embd==0.13.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-multi-head==0.29.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-layer-normalization==0.16.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-position-wise-feed-forward==0.8.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-embed-sim==0.10.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras-self-attention==0.51.0 (from keras-multi-head==0.29.0->keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->ktrain) (2023.3.post1)\n",
            "Requirement already satisfied: regex>2016 in /usr/local/lib/python3.10/dist-packages (from syntok>1.3.3->ktrain) (2023.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (0.20.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.17.0->ktrain) (4.66.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->ktrain) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (2023.11.17)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (3.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tika->ktrain) (67.7.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers>=4.17.0->ktrain) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers>=4.17.0->ktrain) (4.5.0)\n",
            "Building wheels for collected packages: ktrain, keras_bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, langdetect, tika\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ktrain: filename=ktrain-0.39.0-py3-none-any.whl size=25319737 sha256=bf0f2bf18ecc7d85068cb12d557bf7c5cb81b386a9e4e9c0e3ce456d06e6ea58\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/fd/0a/ef6252223f3d2c49b06d18e71c74caa43bbf4c64a8c183a46e\n",
            "  Building wheel for keras_bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras_bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33499 sha256=4e00077eb0fa84c78f38acda496d38a491a3f4f6451ef865bfd8223e194a3b8c\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/0c/04/646b6fdf6375911b42c8d540a8a3fda8d5d77634e5dcbe7b26\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12286 sha256=cda141ef63fbe754d0065f446f8a3e034e0449b449391c3f3215840f6efbe7b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/cb/22/75a0ad376129177f7c95c0d91331a18f5368fd657f4035ba7c\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3943 sha256=d1d2f0e53b28be17bf91a2a297c1beaa6f055a12bedc57b21b5a0cf5bc6ddadc\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/32/c7/fd35d0d1b840a6c7cbd4343f808d10d0f7b87d271a4dbe796f\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4653 sha256=7369dca854711a19d183da3582ce694bb26de795ff8eda74fe7e24540bc7584a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/3a/4b/21db23c0cc56c4b219616e181f258eb7c57d36cc5d056fae9a\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14975 sha256=b8e2b861970bcf3a053f1d5217236efc5432ddd33f947a6a5248311470624c3a\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/23/4b/06d7ae21714f70fcc25b48f972cc8e5e7f4b6b764a038b509d\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6946 sha256=465f7b70d37607afeee51ac7024150fd936f6e3076b27d0746df0fb6b693986a\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/07/1b/b1ca47b6ac338554b75c8f52c54e6a2bfbe1b07d79579979a4\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4968 sha256=220515b7e1976a127deee1b0cb0274b539190c6d44510ada22b27d5441ba6378\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/6a/04/d1706a53b23b2cb5f9a0a76269bf87925daa1bca09eac01b21\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18895 sha256=b4d464444806610b796be014bf6d8e0fe2b803e9ec77ee1decd46a859e883e73\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/f7/24/607b483144fb9c47b4ba2c5fba6b68e54aeee2d5bf6c05302e\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993225 sha256=16f1090b0e5df51f7b06e07b322b4e85232fc52e54f3fc1836557f40abe1332c\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32622 sha256=d35508a5c6170d7d451accd4e775f0126b105bc2df711eafec70c79d0f594003\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/71/c7/b757709531121b1700cffda5b6b0d4aad095fb507ec84316d0\n",
            "Successfully built ktrain keras_bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention langdetect tika\n",
            "Installing collected packages: whoosh, sentencepiece, syntok, langdetect, keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-layer-normalization, keras-embed-sim, tika, keras-multi-head, keras-transformer, keras_bert, ktrain\n",
            "Successfully installed keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0 keras_bert-0.89.0 ktrain-0.39.0 langdetect-1.0.9 sentencepiece-0.1.99 syntok-1.4.4 tika-2.6.0 whoosh-2.7.4\n"
          ]
        }
      ],
      "source": [
        "!pip install ktrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "h-Qx7txe5rLt"
      },
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "B21wrN8a5rLu"
      },
      "outputs": [],
      "source": [
        "import ktrain\n",
        "from ktrain import text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "aFjgHkIZ5rLu"
      },
      "outputs": [],
      "source": [
        "categories=['1', '2', '3']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svY9aM4q5rLw",
        "outputId": "2b25f9ec-b1ea-44a5-f7b2-824cd76e6045"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2}"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "set(y_train_over)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53ZG5cGp5rLw"
      },
      "source": [
        "## Ktrain mBert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "9fCxTGnz5rLx",
        "outputId": "6d4570a0-e7c4-42d6-f89b-2220676aeb40"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca008aa3be174abe99cb07bdf303183c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a63af63162d946fa80e19199da85503f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_name = 'bert-base-multilingual-cased'\n",
        "trans = text.Transformer(model_name,maxlen=256,class_names=categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "GRM54PQR5rLx",
        "outputId": "3774ebcb-a29a-40f8-80d0-e95f41263b7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 20\n",
            "\t95percentile : 28\n",
            "\t99percentile : 30\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 15\n",
            "\t95percentile : 27\n",
            "\t99percentile : 29\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n"
          ]
        }
      ],
      "source": [
        "train = trans.preprocess_train(X_train_over, y_train_over)\n",
        "valid = trans.preprocess_train(X_valid, y_valid)\n",
        "model = trans.get_classifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3l8ssEzUCCj"
      },
      "outputs": [],
      "source": [
        "CasedmBertlearner = ktrain.get_learner(model, train_data=train,val_data=valid, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81xM8Ulg5rLy",
        "outputId": "4c879775-4957-4f2f-97ae-30a95d5d5f05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 3e-05...\n",
            "Epoch 1/8\n",
            "20/20 [==============================] - 47s 1s/step - loss: 1.1061 - accuracy: 0.3206 - val_loss: 1.1419 - val_accuracy: 0.1533\n",
            "Epoch 2/8\n",
            "20/20 [==============================] - 20s 994ms/step - loss: 1.0867 - accuracy: 0.3714 - val_loss: 1.1969 - val_accuracy: 0.1867\n",
            "Epoch 3/8\n",
            "20/20 [==============================] - 20s 988ms/step - loss: 0.9278 - accuracy: 0.5365 - val_loss: 1.2216 - val_accuracy: 0.2400\n",
            "Epoch 4/8\n",
            "20/20 [==============================] - 20s 990ms/step - loss: 0.4946 - accuracy: 0.8254 - val_loss: 0.4845 - val_accuracy: 0.8467\n",
            "Epoch 5/8\n",
            "20/20 [==============================] - 20s 990ms/step - loss: 0.2446 - accuracy: 0.9111 - val_loss: 0.2984 - val_accuracy: 0.9133\n",
            "Epoch 6/8\n",
            "20/20 [==============================] - 20s 990ms/step - loss: 0.1237 - accuracy: 0.9714 - val_loss: 0.4200 - val_accuracy: 0.8800\n",
            "Epoch 7/8\n",
            "20/20 [==============================] - 20s 995ms/step - loss: 0.0388 - accuracy: 0.9968 - val_loss: 0.4342 - val_accuracy: 0.8733\n",
            "Epoch 8/8\n",
            "20/20 [==============================] - 20s 988ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.4364 - val_accuracy: 0.9000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78074118ba90>"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CasedmBertlearner.fit_onecycle(3e-5, 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ER9ZEUh5rLy",
        "outputId": "f64243ad-e188-4f2c-bb5f-adff38716883"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 10s 736ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.94      0.94      0.94       120\n",
            "           2       0.72      0.78      0.75        23\n",
            "           3       0.80      0.57      0.67         7\n",
            "\n",
            "    accuracy                           0.90       150\n",
            "   macro avg       0.82      0.77      0.79       150\n",
            "weighted avg       0.90      0.90      0.90       150\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[113,   6,   1],\n",
              "       [  5,  18,   0],\n",
              "       [  2,   1,   4]])"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CasedmBertlearner.validate(class_names=categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ycMsGXl5rLy"
      },
      "outputs": [],
      "source": [
        "predictor = ktrain.get_predictor(CasedmBertlearner.model, preproc=trans)\n",
        "y_pred = predictor.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYRfQjEg5rLz"
      },
      "outputs": [],
      "source": [
        "y_pred = np.array(y_pred).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slsgNbwiTJT6",
        "outputId": "3e8d1988-e824-42a3-9cd8-9e8984767996"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mBERT Accuracy: 0.8866666666666667\n",
            "Classification Report for mBERT:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.97      0.91      0.94       121\n",
            "           2       0.62      0.87      0.73        23\n",
            "           3       0.60      0.50      0.55         6\n",
            "\n",
            "    accuracy                           0.89       150\n",
            "   macro avg       0.73      0.76      0.74       150\n",
            "weighted avg       0.91      0.89      0.89       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "accuracy_mbert = accuracy_score(Btest['label'], y_pred)\n",
        "classification_report_mbert = classification_report(Btest['label'], y_pred)\n",
        "\n",
        "print(f'mBERT Accuracy: {accuracy_mbert}')\n",
        "print('Classification Report for mBERT:\\n', classification_report_mbert) # 0.63      0.63      0.63"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwY0si-T5rLz"
      },
      "outputs": [],
      "source": [
        "predictor.save('/content/drive/MyDrive/Colab Notebooks/case/'+'TaskB'+'/OvertaskbmBERTCasedOver')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69w65PlJ5rL0"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "# import zipfile\n",
        "\n",
        "# # Assuming Btest is your DataFrame with an \"index\" column and y_pred is your predicted labels\n",
        "# # Replace y_pred with your actual predicted labels\n",
        "\n",
        "# # Create a DataFrame with \"index\" and \"prediction\" columns\n",
        "# submission_df = pd.DataFrame({\"index\": Btest[\"index\"].tolist(), \"prediction\": y_pred})\n",
        "\n",
        "# # Sort the DataFrame based on the \"index\" column\n",
        "# submission_df = submission_df.sort_values(by=\"index\")\n",
        "\n",
        "# # Define the path to save the submission file\n",
        "# submission_file_path = \"/content/submission.json\"\n",
        "\n",
        "# # Save the DataFrame to a JSON file\n",
        "# submission_df.to_json(submission_file_path, orient=\"records\", lines=True)\n",
        "\n",
        "# # Zip the JSON file\n",
        "# with zipfile.ZipFile(\"ref.zip\", \"w\") as zipf:\n",
        "#     zipf.write(submission_file_path, arcname=\"submission.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpOVn9It5rL0"
      },
      "source": [
        "## Ktrain DistilmBert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "q4xtJxjr5rL0",
        "outputId": "ef30c79c-29c5-49a9-b655-cf4ea82205cf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90425ef12f2d49c5adf17beea7d1e3b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/466 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30e098dc7eaa4d31951d57cdb7cb1679",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/542M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 20\n",
            "\t95percentile : 28\n",
            "\t99percentile : 30\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "379ae2cf4b9c4fd395de218a305d4e7c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "118061cff730476d8730368fc5b53eb4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ac2f85b63144a12ae0bf4be31e0d1f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 15\n",
            "\t95percentile : 27\n",
            "\t99percentile : 29\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n"
          ]
        }
      ],
      "source": [
        "model_name = 'distilbert-base-multilingual-cased'\n",
        "trans = text.Transformer(model_name,maxlen=256,class_names=categories)\n",
        "train = trans.preprocess_train(X_train_over, y_train_over)\n",
        "valid = trans.preprocess_train(X_valid, y_valid)\n",
        "model = trans.get_classifier()\n",
        "Distillearner = ktrain.get_learner(model, train_data=train,val_data=valid, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bj_RbL5R5rL1",
        "outputId": "dead226f-54bd-4584-a7ab-af99be519654"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 3e-05...\n",
            "Epoch 1/8\n",
            "20/20 [==============================] - 34s 743ms/step - loss: 1.0969 - accuracy: 0.3714 - val_loss: 1.0950 - val_accuracy: 0.1933\n",
            "Epoch 2/8\n",
            "20/20 [==============================] - 11s 539ms/step - loss: 0.9702 - accuracy: 0.5873 - val_loss: 1.0084 - val_accuracy: 0.3800\n",
            "Epoch 3/8\n",
            "20/20 [==============================] - 12s 589ms/step - loss: 0.5893 - accuracy: 0.7746 - val_loss: 0.5554 - val_accuracy: 0.8533\n",
            "Epoch 4/8\n",
            "20/20 [==============================] - 10s 513ms/step - loss: 0.2122 - accuracy: 0.9333 - val_loss: 0.4166 - val_accuracy: 0.8867\n",
            "Epoch 5/8\n",
            "20/20 [==============================] - 10s 528ms/step - loss: 0.0513 - accuracy: 0.9968 - val_loss: 0.6240 - val_accuracy: 0.8333\n",
            "Epoch 6/8\n",
            "20/20 [==============================] - 11s 574ms/step - loss: 0.0551 - accuracy: 0.9873 - val_loss: 0.4939 - val_accuracy: 0.8667\n",
            "Epoch 7/8\n",
            "20/20 [==============================] - 10s 508ms/step - loss: 0.0266 - accuracy: 0.9968 - val_loss: 0.4328 - val_accuracy: 0.8800\n",
            "Epoch 8/8\n",
            "20/20 [==============================] - 10s 514ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.4302 - val_accuracy: 0.8800\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x780736d6fca0>"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Distillearner.fit_onecycle(3e-5,8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJGU493h5rL2",
        "outputId": "6917d4dd-e706-4c07-e49d-38d37018ebe8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 3s 290ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      0.95      0.94       120\n",
            "           2       0.70      0.70      0.70        23\n",
            "           3       0.50      0.29      0.36         7\n",
            "\n",
            "    accuracy                           0.88       150\n",
            "   macro avg       0.71      0.64      0.67       150\n",
            "weighted avg       0.87      0.88      0.87       150\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[114,   4,   2],\n",
              "       [  7,  16,   0],\n",
              "       [  2,   3,   2]])"
            ]
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Distillearner.validate(class_names=categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmWDrfgf5rL3"
      },
      "outputs": [],
      "source": [
        "predictor = ktrain.get_predictor(Distillearner.model, preproc=trans)\n",
        "y_pred = predictor.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EHQ8OyS5rL3"
      },
      "outputs": [],
      "source": [
        "y_pred = np.array(y_pred).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUxkz5cOVlse",
        "outputId": "812f7b15-cb08-4ae8-bf55-3d6cbe1c9240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DistilBERT Accuracy: 0.8866666666666667\n",
            "Classification Report for DistilBERT:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.94      0.93      0.94       121\n",
            "           2       0.65      0.74      0.69        23\n",
            "           3       0.75      0.50      0.60         6\n",
            "\n",
            "    accuracy                           0.89       150\n",
            "   macro avg       0.78      0.72      0.74       150\n",
            "weighted avg       0.89      0.89      0.89       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "accuracy_DistilBERT = accuracy_score(Btest['label'], y_pred)\n",
        "classification_report_DistilBERT = classification_report(Btest['label'], y_pred)\n",
        "\n",
        "print(f'DistilBERT Accuracy: {accuracy_DistilBERT}')\n",
        "print('Classification Report for DistilBERT:\\n', classification_report_DistilBERT) # 0.63      0.63      0.63"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkwAUEfw5rL4"
      },
      "outputs": [],
      "source": [
        "predictor.save('/content/drive/MyDrive/Colab Notebooks/case/'+'TaskB'+'/OvertaskbDistilmBERT')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_nTvW355rL4"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "# import zipfile\n",
        "\n",
        "# # Assuming Btest is your DataFrame with an \"index\" column and y_pred is your predicted labels\n",
        "# # Replace y_pred with your actual predicted labels\n",
        "\n",
        "# # Create a DataFrame with \"index\" and \"prediction\" columns\n",
        "# submission_df = pd.DataFrame({\"index\": Btest[\"index\"].tolist(), \"prediction\": y_pred})\n",
        "\n",
        "# # Sort the DataFrame based on the \"index\" column\n",
        "# submission_df = submission_df.sort_values(by=\"index\")\n",
        "\n",
        "# # Define the path to save the submission file\n",
        "# submission_file_path = \"/content/submissiondistil.json\"\n",
        "\n",
        "# # Save the DataFrame to a JSON file\n",
        "# submission_df.to_json(submission_file_path, orient=\"records\", lines=True)\n",
        "\n",
        "# # Zip the JSON file\n",
        "# with zipfile.ZipFile(\"distilmBERTTaskB.zip\", \"w\") as zipf:\n",
        "#     zipf.write(submission_file_path, arcname=\"submissiondistil.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rO81N3g5rL5"
      },
      "source": [
        "## Ktrain XLMR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "0a92e7ad8ac740e5ab055eb02baf8b6b",
            "52950c63249949a7bcc98cf360c248c6",
            "431db3556785477e9d1c708f16512441",
            "196c23b0e2cd4253a83069c00bd17bcc",
            "6931445872194c7ebfe59b47a54dee87",
            "b45d540c115d4603af07ab3916b86cd0",
            "185c6b0f026f4538b449ad285f7ab7d8",
            "89fe343d5f78472982d4de4b7aa84a9c",
            "d623d31b27784b348ef8b2b4cce1c681",
            "3309c667077645f6a7ea8c5d897f48e9",
            "c3b7317072e349b2849619a37bbea690",
            "53fd621359b64a11bfab64e360a488ae",
            "269b506b1c974e9baa0da47948d23aed",
            "4d57de7deeeb4c6db3b3c18a7f1e6d18",
            "760e3a7f0d334411bfe1c7bcc1acfb50",
            "86b70bbb82c44cd4b0fc22f8db47d3ab",
            "20b27d752ed649d395a2b364fdec03be",
            "108242f64b694086be43bf3a4618206f",
            "422c67f3b7ab419eba2eea67b2586a15",
            "08c50640bb0c4089918171db5a7df2f7",
            "dc2d6d8ffebb47a082bfb7b77641898b",
            "febc024bdde2499b8f9ec9e5c986c6e2",
            "8502fcada018495c9c153941d4b03b5c",
            "ca4e12f6e5d341cf8e1791d9aa124052",
            "2ee532219f9e4c3aafab1aebe868860d",
            "15a8d5b4815045acb6323389786029c2",
            "fcc068d095fe4820bc45f771117ea3e7",
            "f108be086092482c930f51b2f9febf88",
            "6b4ef73ab17547e3b7de922102665c7c",
            "73ce1ea65f264559943433ac0fd1a34a",
            "761e4b54a8e24077bc9c0454ba128a60",
            "6c3348a382dc41808cb86e7e12b93ce0",
            "7cb9091384e14c0bbc334f1ee3a9fa84",
            "c6c8674714b545c2b3c748348df9d3ef",
            "ba7a2b3ae5bb48329e7e75d47ed195c5",
            "192be83e01d54ea0acc63e551787024e",
            "77343e89ab7444898db43e61049f053a",
            "3b2692a2171e40f38ee1e61b0647a8bf",
            "3eea82d64e434036bd8f536627b1ff7b",
            "0b8852b98d0d4d53aa511df9c55aa456",
            "a64060c582f94966a5157fbd8e698aa5",
            "f8505b24218b49608f8a4d023a456100",
            "9f51321aa8ec4d51ba3ed5d5b1784c8d",
            "33b0a474954b42b9b6b9bbbd602db037"
          ]
        },
        "id": "cDm2fI-T5rL5",
        "outputId": "6c698774-fce4-49a6-d5fb-95091faea048"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a92e7ad8ac740e5ab055eb02baf8b6b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/512 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53fd621359b64a11bfab64e360a488ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tf_model.h5:   0%|          | 0.00/1.89G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8502fcada018495c9c153941d4b03b5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 20\n",
            "\t95percentile : 28\n",
            "\t99percentile : 30\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6c8674714b545c2b3c748348df9d3ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 15\n",
            "\t95percentile : 27\n",
            "\t99percentile : 29\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n"
          ]
        }
      ],
      "source": [
        "model_name = 'xlm-roberta-base'\n",
        "trans = text.Transformer(model_name,maxlen=256,class_names=categories)\n",
        "train = trans.preprocess_train(X_train_over, y_train_over)\n",
        "valid = trans.preprocess_train(X_valid, y_valid)\n",
        "model = trans.get_classifier()\n",
        "XLlearner = ktrain.get_learner(model, train_data=train,val_data=valid, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUla9iwu5rL5",
        "outputId": "df9b97e5-910e-4918-ef2c-e50dd4881652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 2e-05...\n",
            "Epoch 1/10\n",
            "20/20 [==============================] - 50s 1s/step - loss: 1.1024 - accuracy: 0.3238 - val_loss: 1.1406 - val_accuracy: 0.1533\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 19s 970ms/step - loss: 1.0989 - accuracy: 0.3429 - val_loss: 1.1229 - val_accuracy: 0.1533\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 20s 993ms/step - loss: 1.0903 - accuracy: 0.3683 - val_loss: 1.1560 - val_accuracy: 0.1867\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 20s 1s/step - loss: 1.0284 - accuracy: 0.5302 - val_loss: 0.8752 - val_accuracy: 0.8533\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.7867 - accuracy: 0.7143 - val_loss: 0.6873 - val_accuracy: 0.8133\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.5604 - accuracy: 0.8222 - val_loss: 0.4018 - val_accuracy: 0.8733\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.3426 - accuracy: 0.8762 - val_loss: 0.4241 - val_accuracy: 0.8600\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.1880 - accuracy: 0.9524 - val_loss: 0.3422 - val_accuracy: 0.8800\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.1318 - accuracy: 0.9810 - val_loss: 0.3583 - val_accuracy: 0.8867\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0884 - accuracy: 0.9873 - val_loss: 0.3545 - val_accuracy: 0.8800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e2141593070>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "XLlearner.fit_onecycle(2e-5,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3_YZ9jy5rL6",
        "outputId": "7748c7f9-0cc9-43d4-f287-701fd7663d3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 7s 569ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.94      0.94      0.94       120\n",
            "           2       0.61      0.74      0.67        23\n",
            "           3       1.00      0.29      0.44         7\n",
            "\n",
            "    accuracy                           0.88       150\n",
            "   macro avg       0.85      0.66      0.68       150\n",
            "weighted avg       0.89      0.88      0.88       150\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[113,   7,   0],\n",
              "       [  6,  17,   0],\n",
              "       [  1,   4,   2]])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "XLlearner.validate(class_names=categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "x8MCPass5rL6"
      },
      "outputs": [],
      "source": [
        "predictor = ktrain.get_predictor(XLlearner.model, preproc=trans)\n",
        "y_pred = predictor.predict(X_test)\n",
        "# y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "ofatmdR8v06a"
      },
      "outputs": [],
      "source": [
        "y_pred = np.array(y_pred).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = y_pred - 1"
      ],
      "metadata": {
        "id": "CsiPlmONt5qq"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgT3-Wydt1Gq",
        "outputId": "bfa8441e-ddb0-4c25-8fb4-51f7837af39e"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2}"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWGN_ueI5YWn",
        "outputId": "96d58465-20ce-4d36-dc19-76ed97a5e6c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XLMR Accuracy: 0.8733333333333333\n",
            "Classification Report for XLMR:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.94      0.94       121\n",
            "           1       0.62      0.70      0.65        23\n",
            "           2       0.50      0.17      0.25         6\n",
            "\n",
            "    accuracy                           0.87       150\n",
            "   macro avg       0.68      0.60      0.61       150\n",
            "weighted avg       0.87      0.87      0.87       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "accuracy_XLMR = accuracy_score(y_test, y_pred)\n",
        "classification_report_XLMR = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'XLMR Accuracy: {accuracy_XLMR}')\n",
        "print('Classification Report for XLMR:\\n', classification_report_XLMR) # 0.63      0.63      0.63"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGsbg4Ng5rL6"
      },
      "outputs": [],
      "source": [
        "y_pred = np.array(y_pred).astype(int)\n",
        "predictor.save('/content/drive/MyDrive/Colab Notebooks/case/'+'TaskB'+'/Overtaskbxlmr')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9DIKs5X5rL6"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import zipfile\n",
        "\n",
        "# Assuming Btest is your DataFrame with an \"index\" column and y_pred is your predicted labels\n",
        "# Replace y_pred with your actual predicted labels\n",
        "\n",
        "# Create a DataFrame with \"index\" and \"prediction\" columns\n",
        "submission_df = pd.DataFrame({\"index\": Btest[\"index\"].tolist(), \"prediction\": y_pred})\n",
        "\n",
        "# Sort the DataFrame based on the \"index\" column\n",
        "submission_df = submission_df.sort_values(by=\"index\")\n",
        "\n",
        "# Define the path to save the submission file\n",
        "submission_file_path = \"/content/submissionxlmr.json\"\n",
        "\n",
        "# Save the DataFrame to a JSON file\n",
        "submission_df.to_json(submission_file_path, orient=\"records\", lines=True)\n",
        "\n",
        "# Zip the JSON file\n",
        "with zipfile.ZipFile(\"TaskBXLMR.zip\", \"w\") as zipf:\n",
        "    zipf.write(submission_file_path, arcname=\"submissionxlmr.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9nJ3gUM5rL7"
      },
      "source": [
        "## Ktrain ClimateBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "JUN7c-Oe5rL7",
        "outputId": "8f5012cd-a376-4c88-b613-60da349ebc48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 20\n",
            "\t95percentile : 28\n",
            "\t99percentile : 30\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 15\n",
            "\t95percentile : 27\n",
            "\t99percentile : 29\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n"
          ]
        }
      ],
      "source": [
        "model_name = 'climatebert/distilroberta-base-climate-f'\n",
        "trans = text.Transformer(model_name,maxlen=256,class_names=categories)\n",
        "train = trans.preprocess_train(X_train_over, y_train_over)\n",
        "valid = trans.preprocess_train(X_valid, y_valid)\n",
        "model = trans.get_classifier()\n",
        "AlbertLearner = ktrain.get_learner(model, train_data=train,val_data=valid, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMu2wVEh5rL7",
        "outputId": "cc3aaeb8-e976-4acd-aec6-8004651f2b17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 3e-05...\n",
            "Epoch 1/8\n",
            "20/20 [==============================] - 35s 779ms/step - loss: 1.1035 - accuracy: 0.3365 - val_loss: 1.1069 - val_accuracy: 0.1533\n",
            "Epoch 2/8\n",
            "20/20 [==============================] - 10s 515ms/step - loss: 0.9844 - accuracy: 0.5302 - val_loss: 0.5798 - val_accuracy: 0.8800\n",
            "Epoch 3/8\n",
            "20/20 [==============================] - 10s 510ms/step - loss: 0.7018 - accuracy: 0.7206 - val_loss: 0.4721 - val_accuracy: 0.8400\n",
            "Epoch 4/8\n",
            "20/20 [==============================] - 10s 504ms/step - loss: 0.2376 - accuracy: 0.9333 - val_loss: 0.3452 - val_accuracy: 0.8933\n",
            "Epoch 5/8\n",
            "20/20 [==============================] - 10s 490ms/step - loss: 0.0778 - accuracy: 0.9810 - val_loss: 0.4393 - val_accuracy: 0.8800\n",
            "Epoch 6/8\n",
            "20/20 [==============================] - 10s 486ms/step - loss: 0.0202 - accuracy: 0.9968 - val_loss: 0.5263 - val_accuracy: 0.8867\n",
            "Epoch 7/8\n",
            "20/20 [==============================] - 10s 489ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.5483 - val_accuracy: 0.8867\n",
            "Epoch 8/8\n",
            "20/20 [==============================] - 11s 555ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.5516 - val_accuracy: 0.8867\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78458d1b7cd0>"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "AlbertLearner.fit_onecycle(3e-5,8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNfwVE6W5rL7",
        "outputId": "7f92e5ac-48c2-4523-dfa2-0b2e3a3397fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 3s 289ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.95      0.93      0.94       120\n",
            "           2       0.64      0.78      0.71        23\n",
            "           3       0.75      0.43      0.55         7\n",
            "\n",
            "    accuracy                           0.89       150\n",
            "   macro avg       0.78      0.71      0.73       150\n",
            "weighted avg       0.89      0.89      0.89       150\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[112,   7,   1],\n",
              "       [  5,  18,   0],\n",
              "       [  1,   3,   3]])"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "AlbertLearner.validate(class_names=categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgG1X8y35rL8"
      },
      "outputs": [],
      "source": [
        "predictor = ktrain.get_predictor(AlbertLearner.model, preproc=trans)\n",
        "y_pred = predictor.predict(X_test)\n",
        "# y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3TLO-tE5rL8"
      },
      "outputs": [],
      "source": [
        "y_pred = np.array(y_pred).astype(int)\n",
        "# predictor.save('/content/drive/MyDrive/Colab Notebooks/case/'+'TaskB'+'/OvertaskbAlbert')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCG75mkeyVI2"
      },
      "outputs": [],
      "source": [
        "y_pred = y_pred - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMGM3InNwzLO",
        "outputId": "1d7be848-01e3-4819-cae0-6338aa1274a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "climatebert Accuracy: 0.88\n",
            "Classification Report for climatebert:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93       121\n",
            "           1       0.73      0.70      0.71        23\n",
            "           2       0.50      0.50      0.50         6\n",
            "\n",
            "    accuracy                           0.88       150\n",
            "   macro avg       0.72      0.71      0.71       150\n",
            "weighted avg       0.88      0.88      0.88       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "accuracy_climatebert = accuracy_score(y_test, y_pred)\n",
        "classification_report_climatebert = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'climatebert Accuracy: {accuracy_climatebert}')\n",
        "print('Classification Report for climatebert:\\n', classification_report_climatebert) # 0.63      0.63      0.63"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2Akt6VN5rL8"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import zipfile\n",
        "\n",
        "# Assuming Btest is your DataFrame with an \"index\" column and y_pred is your predicted labels\n",
        "# Replace y_pred with your actual predicted labels\n",
        "\n",
        "# Create a DataFrame with \"index\" and \"prediction\" columns\n",
        "submission_df = pd.DataFrame({\"index\": Btest[\"index\"].tolist(), \"prediction\": y_pred})\n",
        "\n",
        "# Sort the DataFrame based on the \"index\" column\n",
        "submission_df = submission_df.sort_values(by=\"index\")\n",
        "\n",
        "# Define the path to save the submission file\n",
        "submission_file_path = \"/content/submissionalbert.json\"\n",
        "\n",
        "# Save the DataFrame to a JSON file\n",
        "submission_df.to_json(submission_file_path, orient=\"records\", lines=True)\n",
        "\n",
        "# Zip the JSON file\n",
        "with zipfile.ZipFile(\"submission.zip\", \"w\") as zipf:\n",
        "    zipf.write(submission_file_path, arcname=\"submissionalbert.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LH-Mgdk5rL9"
      },
      "source": [
        "## Ktrain mBert Uncased"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "h_29BuQb5rL9",
        "outputId": "e82e0ff7-bf55-40b8-d0f3-e0edffb17b7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 18\n",
            "\t95percentile : 27\n",
            "\t99percentile : 33\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 15\n",
            "\t95percentile : 27\n",
            "\t99percentile : 29\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n"
          ]
        }
      ],
      "source": [
        "model_name = 'bert-base-multilingual-uncased'\n",
        "trans = text.Transformer(model_name,maxlen=256,class_names=categories)\n",
        "train = trans.preprocess_train(X_train_over, X_train_over)\n",
        "valid = trans.preprocess_train(X_valid, y_valid)\n",
        "model = trans.get_classifier()\n",
        "mBertUncasedLearner = ktrain.get_learner(model, train_data=train,val_data=valid, batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qjaxjnnf5rL9",
        "outputId": "51dd7467-925c-4194-ec91-3aefe25b8cc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 3e-05...\n",
            "Epoch 1/15\n",
            "16/16 [==============================] - 64s 1s/step - loss: 1.0754 - accuracy: 0.2734 - val_loss: 0.8603 - val_accuracy: 0.7667\n",
            "Epoch 2/15\n",
            "16/16 [==============================] - 16s 991ms/step - loss: 1.0158 - accuracy: 0.3555 - val_loss: 0.8554 - val_accuracy: 0.6933\n",
            "Epoch 3/15\n",
            "16/16 [==============================] - 16s 1s/step - loss: 0.9386 - accuracy: 0.4766 - val_loss: 0.6905 - val_accuracy: 0.8133\n",
            "Epoch 4/15\n",
            "16/16 [==============================] - 16s 1s/step - loss: 0.9315 - accuracy: 0.5664 - val_loss: 0.6666 - val_accuracy: 0.7800\n",
            "Epoch 5/15\n",
            "16/16 [==============================] - 19s 1s/step - loss: 0.7629 - accuracy: 0.6836 - val_loss: 0.5602 - val_accuracy: 0.8333\n",
            "Epoch 6/15\n",
            "16/16 [==============================] - 17s 1s/step - loss: 0.7932 - accuracy: 0.6172 - val_loss: 0.6061 - val_accuracy: 0.7600\n",
            "Epoch 7/15\n",
            "16/16 [==============================] - 19s 1s/step - loss: 0.5816 - accuracy: 0.7969 - val_loss: 0.4302 - val_accuracy: 0.8733\n",
            "Epoch 8/15\n",
            "16/16 [==============================] - 17s 1s/step - loss: 0.3523 - accuracy: 0.8750 - val_loss: 0.3824 - val_accuracy: 0.9000\n",
            "Epoch 9/15\n",
            "16/16 [==============================] - 17s 1s/step - loss: 0.2448 - accuracy: 0.9219 - val_loss: 0.3535 - val_accuracy: 0.8933\n",
            "Epoch 10/15\n",
            "16/16 [==============================] - 19s 1s/step - loss: 0.2169 - accuracy: 0.9531 - val_loss: 0.3514 - val_accuracy: 0.9000\n",
            "Epoch 11/15\n",
            "16/16 [==============================] - 17s 1s/step - loss: 0.1397 - accuracy: 0.9766 - val_loss: 0.3380 - val_accuracy: 0.8933\n",
            "Epoch 12/15\n",
            "16/16 [==============================] - 17s 1s/step - loss: 0.1063 - accuracy: 0.9844 - val_loss: 0.3638 - val_accuracy: 0.8933\n",
            "Epoch 13/15\n",
            "16/16 [==============================] - 17s 1s/step - loss: 0.0671 - accuracy: 0.9961 - val_loss: 0.3615 - val_accuracy: 0.9000\n",
            "Epoch 14/15\n",
            "16/16 [==============================] - 17s 1s/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.3669 - val_accuracy: 0.9133\n",
            "Epoch 15/15\n",
            "16/16 [==============================] - 20s 1s/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.3710 - val_accuracy: 0.9067\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7abcd9683070>"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mBertUncasedLearner.fit_onecycle(3e-5,15, class_weight = weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Cp9BRCz5rL-",
        "outputId": "ad37ef1c-e6f0-45f7-9781-364bcf2f8022"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 7s 622ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.97      0.94      0.96       120\n",
            "           2       0.68      0.83      0.75        23\n",
            "           3       0.67      0.57      0.62         7\n",
            "\n",
            "    accuracy                           0.91       150\n",
            "   macro avg       0.77      0.78      0.77       150\n",
            "weighted avg       0.91      0.91      0.91       150\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[113,   7,   0],\n",
              "       [  2,  19,   2],\n",
              "       [  1,   2,   4]])"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mBertUncasedLearner.validate(class_names=categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHpgPk745rL-"
      },
      "outputs": [],
      "source": [
        "predictor = ktrain.get_predictor(mBertUncasedLearner.model, preproc=trans)\n",
        "y_pred = predictor.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjTvZAqG5rL-"
      },
      "outputs": [],
      "source": [
        "y_pred = np.array(y_pred).astype(int)\n",
        "predictor.save('/content/drive/MyDrive/Colab Notebooks/case/'+'TaskB'+'/OvertaskbmBertUncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7X_bsdZV5rL-"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import zipfile\n",
        "\n",
        "# Assuming Btest is your DataFrame with an \"index\" column and y_pred is your predicted labels\n",
        "# Replace y_pred with your actual predicted labels\n",
        "\n",
        "# Create a DataFrame with \"index\" and \"prediction\" columns\n",
        "submission_df = pd.DataFrame({\"index\": Btest[\"index\"].tolist(), \"prediction\": y_pred})\n",
        "\n",
        "# Sort the DataFrame based on the \"index\" column\n",
        "submission_df = submission_df.sort_values(by=\"index\")\n",
        "\n",
        "# Define the path to save the submission file\n",
        "submission_file_path = \"/content/submissionuncased.json\"\n",
        "\n",
        "# Save the DataFrame to a JSON file\n",
        "submission_df.to_json(submission_file_path, orient=\"records\", lines=True)\n",
        "\n",
        "# Zip the JSON file\n",
        "with zipfile.ZipFile(\"submission.zip\", \"w\") as zipf:\n",
        "    zipf.write(submission_file_path, arcname=\"submissionuncased.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IY-Je1y1am96"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIpyqcK-anpn"
      },
      "source": [
        "# Hybrid Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFZrai4Nanpp"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVCa5u5danpp",
        "outputId": "fe3bfc78-bb8c-482c-9473-ccd3dc832fbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.10/dist-packages (0.6.2)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (1.23.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (1.34.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (4.66.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (2023.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (2.1.0)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.15 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch_pretrained_bert) (1.34.15)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch_pretrained_bert) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.15->boto3->pytorch_pretrained_bert) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.1->pytorch_pretrained_bert) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.1->pytorch_pretrained_bert) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.15->boto3->pytorch_pretrained_bert) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pytorch_pretrained_bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTLXyEqianpr",
        "outputId": "05806a76-f952-440a-f19d-af5926e7d5af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_text in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (0.15.0)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9K22GsPanpw"
      },
      "source": [
        "## mBert + BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyjIvQgoanpx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from tensorflow.keras.layers import Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvK6eToKanpy"
      },
      "outputs": [],
      "source": [
        "bert_preprocess2 = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3\")\n",
        "bert_encoder2 = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puJNvjSDanpz"
      },
      "outputs": [],
      "source": [
        "#BERT Layers\n",
        "text_input = Input(shape=(), dtype=tf.string, name='cleanText')\n",
        "preprocessed_text2 = bert_preprocess2(text_input)\n",
        "outputs2 = bert_encoder2(preprocessed_text2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLlKqtWBanp0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Reshape, Bidirectional, LSTM, GlobalAveragePooling1D, GlobalMaxPooling1D, Dense, Dropout, Input, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "# BERT embeddings\n",
        "bert_embedding = outputs2['pooled_output']  # or 'sequence_output' based on your use case\n",
        "bert_embedding = Dropout(0.2)(bert_embedding)\n",
        "\n",
        "# Reshape BERT embeddings to a 3D tensor\n",
        "bert_embedding = Reshape((-1, 768))(bert_embedding)  # Replace 768 with the actual hidden size\n",
        "\n",
        "# Bidirectional LSTM layer\n",
        "lstm_output = Bidirectional(LSTM(64, return_sequences=True))(bert_embedding)\n",
        "\n",
        "# Pooling layers\n",
        "avg_pooling = GlobalAveragePooling1D()(lstm_output)\n",
        "max_pooling = GlobalMaxPooling1D()(lstm_output)\n",
        "\n",
        "# Concatenate and additional dense layers\n",
        "concat_output = concatenate([avg_pooling, max_pooling])\n",
        "dense_layer = Dense(128, activation='relu')(concat_output)\n",
        "dense_layer = Dropout(0.2)(dense_layer)\n",
        "\n",
        "# Additional Dense layer\n",
        "dense_layer_2 = Dense(64, activation='relu')(dense_layer)\n",
        "dense_layer_2 = Dropout(0.2)(dense_layer_2)\n",
        "\n",
        "# Output layer\n",
        "output_layer = Dense(3, activation='softmax')(dense_layer_2)\n",
        "\n",
        "# Connect the input and output layers to create the model\n",
        "model2 = Model(inputs=text_input, outputs=output_layer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfuanwI_eARk"
      },
      "outputs": [],
      "source": [
        "num_classes = 3            #### change class number\n",
        "\n",
        "accuracy_threshold = 0.99\n",
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy')>accuracy_threshold):\n",
        "        print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
        "        self.model.stop_training = True\n",
        "\n",
        "acc_callback = myCallback()\n",
        "# Saved the Best Model\n",
        "filepath = \"/content/drive/MyDrive/Colab Notebooks/case/\" + \"Overhybrid1.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "# callback list\n",
        "callback_list = [acc_callback, checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNIdeDz1anp1",
        "outputId": "0e81862b-ed84-4582-f874-2ff017e10473"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " cleanText (InputLayer)      [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " keras_layer_2 (KerasLayer)  {'input_type_ids': (None,    0         ['cleanText[0][0]']           \n",
            "                             128),                                                                \n",
            "                              'input_mask': (None, 128)                                           \n",
            "                             , 'input_word_ids': (None,                                           \n",
            "                              128)}                                                               \n",
            "                                                                                                  \n",
            " keras_layer_3 (KerasLayer)  {'sequence_output': (None,   1778534   ['keras_layer_2[0][0]',       \n",
            "                              128, 768),                  41         'keras_layer_2[0][1]',       \n",
            "                              'pooled_output': (None, 7              'keras_layer_2[0][2]']       \n",
            "                             68),                                                                 \n",
            "                              'encoder_outputs': [(None                                           \n",
            "                             , 128, 768),                                                         \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768)],                                                  \n",
            "                              'default': (None, 768)}                                             \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 768)                  0         ['keras_layer_3[0][13]']      \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)         (None, 1, 768)               0         ['dropout_6[0][0]']           \n",
            "                                                                                                  \n",
            " bidirectional_2 (Bidirecti  (None, 1, 128)               426496    ['reshape_2[0][0]']           \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " global_average_pooling1d_2  (None, 128)                  0         ['bidirectional_2[0][0]']     \n",
            "  (GlobalAveragePooling1D)                                                                        \n",
            "                                                                                                  \n",
            " global_max_pooling1d_2 (Gl  (None, 128)                  0         ['bidirectional_2[0][0]']     \n",
            " obalMaxPooling1D)                                                                                \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 256)                  0         ['global_average_pooling1d_2[0\n",
            " )                                                                  ][0]',                        \n",
            "                                                                     'global_max_pooling1d_2[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 128)                  32896     ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)         (None, 128)                  0         ['dense_6[0][0]']             \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 64)                   8256      ['dropout_7[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)         (None, 64)                   0         ['dense_7[0][0]']             \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 3)                    195       ['dropout_8[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 178321284 (680.24 MB)\n",
            "Trainable params: 467843 (1.78 MB)\n",
            "Non-trainable params: 177853441 (678.46 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb3lYVddanp2"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.optimizers import AdamW\n",
        "# METRICS = [\n",
        "#       tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "#       tf.keras.metrics.Precision(name='precision'),\n",
        "#       tf.keras.metrics.Recall(name='recall')\n",
        "# ]\n",
        "\n",
        "# model2.compile(optimizer='adam',\n",
        "#               loss='sparse_categorical_crossentropy',\n",
        "#               metrics=METRICS)\n",
        "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AFHPMF8anp4",
        "outputId": "9f8b16a3-d12d-4871-c98c-44c1cecfbecd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.1173 - accuracy: 0.3683\n",
            "Epoch 1: val_accuracy improved from -inf to 0.80000, saving model to /content/drive/MyDrive/Colab Notebooks/case/Overhybrid1.h5\n",
            "10/10 [==============================] - 24s 1s/step - loss: 1.1173 - accuracy: 0.3683 - val_loss: 0.9915 - val_accuracy: 0.8000\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.0964 - accuracy: 0.3524\n",
            "Epoch 2: val_accuracy improved from 0.80000 to 0.82000, saving model to /content/drive/MyDrive/Colab Notebooks/case/Overhybrid1.h5\n",
            "10/10 [==============================] - 8s 876ms/step - loss: 1.0964 - accuracy: 0.3524 - val_loss: 1.0604 - val_accuracy: 0.8200\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.0932 - accuracy: 0.3778\n",
            "Epoch 3: val_accuracy improved from 0.82000 to 0.82667, saving model to /content/drive/MyDrive/Colab Notebooks/case/Overhybrid1.h5\n",
            "10/10 [==============================] - 9s 963ms/step - loss: 1.0932 - accuracy: 0.3778 - val_loss: 1.0269 - val_accuracy: 0.8267\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.0915 - accuracy: 0.3524\n",
            "Epoch 4: val_accuracy did not improve from 0.82667\n",
            "10/10 [==============================] - 5s 531ms/step - loss: 1.0915 - accuracy: 0.3524 - val_loss: 1.0756 - val_accuracy: 0.7000\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.0612 - accuracy: 0.4476\n",
            "Epoch 5: val_accuracy did not improve from 0.82667\n",
            "10/10 [==============================] - 6s 617ms/step - loss: 1.0612 - accuracy: 0.4476 - val_loss: 1.0331 - val_accuracy: 0.8267\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.0533 - accuracy: 0.4286\n",
            "Epoch 6: val_accuracy did not improve from 0.82667\n",
            "10/10 [==============================] - 7s 676ms/step - loss: 1.0533 - accuracy: 0.4286 - val_loss: 0.9530 - val_accuracy: 0.8133\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.0344 - accuracy: 0.4762\n",
            "Epoch 7: val_accuracy improved from 0.82667 to 0.84000, saving model to /content/drive/MyDrive/Colab Notebooks/case/Overhybrid1.h5\n",
            "10/10 [==============================] - 14s 1s/step - loss: 1.0344 - accuracy: 0.4762 - val_loss: 0.9602 - val_accuracy: 0.8400\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.0232 - accuracy: 0.4603\n",
            "Epoch 8: val_accuracy did not improve from 0.84000\n",
            "10/10 [==============================] - 7s 727ms/step - loss: 1.0232 - accuracy: 0.4603 - val_loss: 0.9320 - val_accuracy: 0.8200\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.0094 - accuracy: 0.5016\n",
            "Epoch 9: val_accuracy improved from 0.84000 to 0.84667, saving model to /content/drive/MyDrive/Colab Notebooks/case/Overhybrid1.h5\n",
            "10/10 [==============================] - 18s 2s/step - loss: 1.0094 - accuracy: 0.5016 - val_loss: 0.9183 - val_accuracy: 0.8467\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.9859 - accuracy: 0.5270\n",
            "Epoch 10: val_accuracy did not improve from 0.84667\n",
            "10/10 [==============================] - 6s 596ms/step - loss: 0.9859 - accuracy: 0.5270 - val_loss: 0.8678 - val_accuracy: 0.8067\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.9338 - accuracy: 0.5365\n",
            "Epoch 11: val_accuracy did not improve from 0.84667\n",
            "10/10 [==============================] - 6s 571ms/step - loss: 0.9338 - accuracy: 0.5365 - val_loss: 0.9255 - val_accuracy: 0.8000\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.8806 - accuracy: 0.5746\n",
            "Epoch 12: val_accuracy did not improve from 0.84667\n",
            "10/10 [==============================] - 7s 746ms/step - loss: 0.8806 - accuracy: 0.5746 - val_loss: 1.1553 - val_accuracy: 0.3400\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.8855 - accuracy: 0.5683\n",
            "Epoch 13: val_accuracy did not improve from 0.84667\n",
            "10/10 [==============================] - 6s 598ms/step - loss: 0.8855 - accuracy: 0.5683 - val_loss: 0.9634 - val_accuracy: 0.5800\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.8468 - accuracy: 0.5873\n",
            "Epoch 14: val_accuracy did not improve from 0.84667\n",
            "10/10 [==============================] - 6s 598ms/step - loss: 0.8468 - accuracy: 0.5873 - val_loss: 0.8320 - val_accuracy: 0.7533\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.8710 - accuracy: 0.5746\n",
            "Epoch 15: val_accuracy did not improve from 0.84667\n",
            "10/10 [==============================] - 5s 529ms/step - loss: 0.8710 - accuracy: 0.5746 - val_loss: 0.9508 - val_accuracy: 0.4733\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7900 - accuracy: 0.6095\n",
            "Epoch 16: val_accuracy did not improve from 0.84667\n",
            "10/10 [==============================] - 5s 475ms/step - loss: 0.7900 - accuracy: 0.6095 - val_loss: 0.8667 - val_accuracy: 0.6800\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7712 - accuracy: 0.6444\n",
            "Epoch 17: val_accuracy did not improve from 0.84667\n",
            "10/10 [==============================] - 6s 596ms/step - loss: 0.7712 - accuracy: 0.6444 - val_loss: 1.0266 - val_accuracy: 0.4933\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7607 - accuracy: 0.6317\n",
            "Epoch 18: val_accuracy did not improve from 0.84667\n",
            "10/10 [==============================] - 5s 510ms/step - loss: 0.7607 - accuracy: 0.6317 - val_loss: 0.6668 - val_accuracy: 0.7867\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.8200 - accuracy: 0.6095\n",
            "Epoch 19: val_accuracy did not improve from 0.84667\n",
            "10/10 [==============================] - 6s 600ms/step - loss: 0.8200 - accuracy: 0.6095 - val_loss: 0.6922 - val_accuracy: 0.8333\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7542 - accuracy: 0.6762\n",
            "Epoch 20: val_accuracy improved from 0.84667 to 0.86000, saving model to /content/drive/MyDrive/Colab Notebooks/case/Overhybrid1.h5\n",
            "10/10 [==============================] - 14s 2s/step - loss: 0.7542 - accuracy: 0.6762 - val_loss: 0.6372 - val_accuracy: 0.8600\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7461 - accuracy: 0.6698\n",
            "Epoch 21: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 6s 600ms/step - loss: 0.7461 - accuracy: 0.6698 - val_loss: 0.8179 - val_accuracy: 0.7733\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7411 - accuracy: 0.6476\n",
            "Epoch 22: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 6s 628ms/step - loss: 0.7411 - accuracy: 0.6476 - val_loss: 0.5892 - val_accuracy: 0.8200\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6791 - accuracy: 0.7079\n",
            "Epoch 23: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 5s 524ms/step - loss: 0.6791 - accuracy: 0.7079 - val_loss: 0.6418 - val_accuracy: 0.8333\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7135 - accuracy: 0.7111\n",
            "Epoch 24: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 5s 478ms/step - loss: 0.7135 - accuracy: 0.7111 - val_loss: 0.8001 - val_accuracy: 0.6667\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7344 - accuracy: 0.6984\n",
            "Epoch 25: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 6s 637ms/step - loss: 0.7344 - accuracy: 0.6984 - val_loss: 0.7425 - val_accuracy: 0.7933\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6869 - accuracy: 0.6857\n",
            "Epoch 26: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 5s 480ms/step - loss: 0.6869 - accuracy: 0.6857 - val_loss: 0.5240 - val_accuracy: 0.8400\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6660 - accuracy: 0.7175\n",
            "Epoch 27: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 6s 601ms/step - loss: 0.6660 - accuracy: 0.7175 - val_loss: 0.6948 - val_accuracy: 0.7733\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6499 - accuracy: 0.7397\n",
            "Epoch 28: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 6s 670ms/step - loss: 0.6499 - accuracy: 0.7397 - val_loss: 0.4764 - val_accuracy: 0.8400\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6448 - accuracy: 0.7175\n",
            "Epoch 29: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 10s 1s/step - loss: 0.6448 - accuracy: 0.7175 - val_loss: 0.7295 - val_accuracy: 0.7000\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6249 - accuracy: 0.7143\n",
            "Epoch 30: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 8s 770ms/step - loss: 0.6249 - accuracy: 0.7143 - val_loss: 0.6472 - val_accuracy: 0.7067\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5054 - accuracy: 0.8127\n",
            "Epoch 31: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 7s 673ms/step - loss: 0.5054 - accuracy: 0.8127 - val_loss: 0.6274 - val_accuracy: 0.7667\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5507 - accuracy: 0.7651\n",
            "Epoch 32: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 7s 682ms/step - loss: 0.5507 - accuracy: 0.7651 - val_loss: 0.5367 - val_accuracy: 0.7800\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5601 - accuracy: 0.7651\n",
            "Epoch 33: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 7s 688ms/step - loss: 0.5601 - accuracy: 0.7651 - val_loss: 0.5545 - val_accuracy: 0.8267\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4886 - accuracy: 0.7905\n",
            "Epoch 34: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 6s 615ms/step - loss: 0.4886 - accuracy: 0.7905 - val_loss: 0.5018 - val_accuracy: 0.8067\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4993 - accuracy: 0.8032\n",
            "Epoch 35: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 7s 733ms/step - loss: 0.4993 - accuracy: 0.8032 - val_loss: 0.6105 - val_accuracy: 0.8067\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4943 - accuracy: 0.7619\n",
            "Epoch 36: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 6s 668ms/step - loss: 0.4943 - accuracy: 0.7619 - val_loss: 0.5649 - val_accuracy: 0.7600\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4894 - accuracy: 0.7968\n",
            "Epoch 37: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 7s 663ms/step - loss: 0.4894 - accuracy: 0.7968 - val_loss: 0.5196 - val_accuracy: 0.8067\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5632 - accuracy: 0.7460\n",
            "Epoch 38: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 6s 655ms/step - loss: 0.5632 - accuracy: 0.7460 - val_loss: 0.5351 - val_accuracy: 0.8133\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5890 - accuracy: 0.7365\n",
            "Epoch 39: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 6s 638ms/step - loss: 0.5890 - accuracy: 0.7365 - val_loss: 0.5346 - val_accuracy: 0.8333\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5082 - accuracy: 0.8159\n",
            "Epoch 40: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 6s 594ms/step - loss: 0.5082 - accuracy: 0.8159 - val_loss: 0.5720 - val_accuracy: 0.7867\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4610 - accuracy: 0.7968\n",
            "Epoch 41: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 7s 776ms/step - loss: 0.4610 - accuracy: 0.7968 - val_loss: 0.7183 - val_accuracy: 0.7533\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5086 - accuracy: 0.7810\n",
            "Epoch 42: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 7s 692ms/step - loss: 0.5086 - accuracy: 0.7810 - val_loss: 0.5056 - val_accuracy: 0.8133\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4688 - accuracy: 0.7937\n",
            "Epoch 43: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 7s 698ms/step - loss: 0.4688 - accuracy: 0.7937 - val_loss: 0.5824 - val_accuracy: 0.8067\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4897 - accuracy: 0.7810\n",
            "Epoch 44: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 7s 692ms/step - loss: 0.4897 - accuracy: 0.7810 - val_loss: 0.5543 - val_accuracy: 0.7933\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4920 - accuracy: 0.7619\n",
            "Epoch 45: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 7s 683ms/step - loss: 0.4920 - accuracy: 0.7619 - val_loss: 0.7762 - val_accuracy: 0.7000\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4053 - accuracy: 0.8127\n",
            "Epoch 46: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 6s 611ms/step - loss: 0.4053 - accuracy: 0.8127 - val_loss: 0.7518 - val_accuracy: 0.7733\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3865 - accuracy: 0.8476\n",
            "Epoch 47: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 7s 718ms/step - loss: 0.3865 - accuracy: 0.8476 - val_loss: 0.7961 - val_accuracy: 0.7467\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4101 - accuracy: 0.8159\n",
            "Epoch 48: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 7s 685ms/step - loss: 0.4101 - accuracy: 0.8159 - val_loss: 0.6793 - val_accuracy: 0.7667\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4103 - accuracy: 0.8159\n",
            "Epoch 49: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 7s 697ms/step - loss: 0.4103 - accuracy: 0.8159 - val_loss: 0.8151 - val_accuracy: 0.6867\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3777 - accuracy: 0.8286\n",
            "Epoch 50: val_accuracy did not improve from 0.86000\n",
            "10/10 [==============================] - 7s 712ms/step - loss: 0.3777 - accuracy: 0.8286 - val_loss: 0.7259 - val_accuracy: 0.7400\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e4d6f2b9bd0>"
            ]
          },
          "execution_count": 189,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2.fit(X_train_over, y_train_over, epochs=50, validation_data = (X_valid, y_valid), verbose = 1, callbacks = callback_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRTG-GOwanp5",
        "outputId": "9ae022bb-8b70-4ed8-8f61-1012051f87cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 4s 304ms/step - loss: 0.6372 - accuracy: 0.8600\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.6372477412223816, 0.8600000143051147]"
            ]
          },
          "execution_count": 190,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import Layer  # Assuming KerasLayer is a subclass of Layer\n",
        "import tensorflow_hub as hub\n",
        "# Define the custom_objects dictionary\n",
        "custom_objects = {'KerasLayer': hub.KerasLayer}\n",
        "\n",
        "# Load the model with the custom_objects parameter\n",
        "loaded_model = load_model(filepath, custom_objects=custom_objects)\n",
        "\n",
        "# Continue with your evaluation or any other operations\n",
        "loaded_model.evaluate(X_valid, y_valid)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONJ9ZLlxanp5",
        "outputId": "ae0c7c87-e3b8-462b-b4de-66c4a0f5a28e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 3s 257ms/step\n",
            "F1-Score: 52.46280991735537\n",
            "Accuracy: 86.0\n"
          ]
        }
      ],
      "source": [
        "y_pred = np.argmax(loaded_model.predict(X_valid), axis=-1)\n",
        "\n",
        "print(\"F1-Score:\",f1_score(Bval['enc_label'],y_pred,average='macro')*100)\n",
        "print(\"Accuracy:\",accuracy_score(Bval['enc_label'],y_pred)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9LlSZmXanp6",
        "outputId": "63ed18cc-429a-4b40-87e7-38adcb0c7ea1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 342ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9262    0.9417    0.9339       120\n",
            "           1     0.5926    0.6957    0.6400        23\n",
            "           2     0.0000    0.0000    0.0000         7\n",
            "\n",
            "    accuracy                         0.8600       150\n",
            "   macro avg     0.5063    0.5458    0.5246       150\n",
            "weighted avg     0.8318    0.8600    0.8452       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(X_valid)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report = classification_report(Bval['enc_label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6QO34MXanp6",
        "outputId": "5a3d5624-292a-4066-908d-8c577ba66fde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 2s 416ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9113    0.9339    0.9224       121\n",
            "           1     0.5600    0.6087    0.5833        23\n",
            "           2     1.0000    0.1667    0.2857         6\n",
            "\n",
            "    accuracy                         0.8533       150\n",
            "   macro avg     0.8238    0.5697    0.5972       150\n",
            "weighted avg     0.8610    0.8533    0.8450       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report = classification_report(Btest['enc_label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ICOpXPpanp7"
      },
      "source": [
        "## BiLSTM + CNN + mBERT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9Zf-vGfanp8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Reshape, Bidirectional, LSTM, GlobalAveragePooling1D, GlobalMaxPooling1D, Dense, Dropout, Input, concatenate, Conv1D, MaxPooling1D, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# BERT embeddings\n",
        "bert_embedding = outputs2['pooled_output']  # or 'sequence_output' based on your use case\n",
        "bert_embedding = Dropout(0.2)(bert_embedding)\n",
        "\n",
        "# Reshape BERT embeddings to a 3D tensor\n",
        "bert_embedding = Reshape((-1, 768))(bert_embedding)  # Replace 768 with the actual hidden size\n",
        "\n",
        "# Bidirectional LSTM layer\n",
        "lstm_output = Bidirectional(LSTM(64, return_sequences=True))(bert_embedding)\n",
        "\n",
        "# Convolutional Neural Network (CNN) layer\n",
        "num_filters = 64\n",
        "filter_size = 3\n",
        "conv_output = Conv1D(num_filters, filter_size, activation='relu', padding='same')(lstm_output)\n",
        "pooling_output = GlobalMaxPooling1D()(conv_output)\n",
        "\n",
        "# Pooling layers\n",
        "avg_pooling = GlobalAveragePooling1D()(lstm_output)\n",
        "max_pooling = GlobalMaxPooling1D()(lstm_output)\n",
        "\n",
        "# Concatenate and additional dense layers\n",
        "concat_output = concatenate([avg_pooling, max_pooling, pooling_output])\n",
        "dense_layer = Dense(128, activation='relu')(concat_output)\n",
        "dense_layer = Dropout(0.2)(dense_layer)\n",
        "\n",
        "# Additional Dense layer\n",
        "dense_layer_2 = Dense(64, activation='relu')(dense_layer)\n",
        "dense_layer_2 = Dropout(0.2)(dense_layer_2)\n",
        "\n",
        "# Output layer\n",
        "output_layer = Dense(3, activation='softmax')(dense_layer_2)\n",
        "\n",
        "# Connect the input and output layers to create the model\n",
        "model2 = Model(inputs=text_input, outputs=output_layer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vEjqjEUbhUN",
        "outputId": "82941a6a-7ed2-4649-84ca-6ed10b348a15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " cleanText (InputLayer)      [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " keras_layer_2 (KerasLayer)  {'input_type_ids': (None,    0         ['cleanText[0][0]']           \n",
            "                             128),                                                                \n",
            "                              'input_mask': (None, 128)                                           \n",
            "                             , 'input_word_ids': (None,                                           \n",
            "                              128)}                                                               \n",
            "                                                                                                  \n",
            " keras_layer_3 (KerasLayer)  {'sequence_output': (None,   1778534   ['keras_layer_2[0][0]',       \n",
            "                              128, 768),                  41         'keras_layer_2[0][1]',       \n",
            "                              'pooled_output': (None, 7              'keras_layer_2[0][2]']       \n",
            "                             68),                                                                 \n",
            "                              'encoder_outputs': [(None                                           \n",
            "                             , 128, 768),                                                         \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768),                                                   \n",
            "                              (None, 128, 768)],                                                  \n",
            "                              'default': (None, 768)}                                             \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)        (None, 768)                  0         ['keras_layer_3[0][13]']      \n",
            "                                                                                                  \n",
            " reshape_5 (Reshape)         (None, 1, 768)               0         ['dropout_10[0][0]']          \n",
            "                                                                                                  \n",
            " bidirectional_6 (Bidirecti  (None, 1, 128)               426496    ['reshape_5[0][0]']           \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)           (None, 1, 64)                24640     ['bidirectional_6[0][0]']     \n",
            "                                                                                                  \n",
            " global_average_pooling1d_3  (None, 128)                  0         ['bidirectional_6[0][0]']     \n",
            "  (GlobalAveragePooling1D)                                                                        \n",
            "                                                                                                  \n",
            " global_max_pooling1d_4 (Gl  (None, 128)                  0         ['bidirectional_6[0][0]']     \n",
            " obalMaxPooling1D)                                                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_3 (Gl  (None, 64)                   0         ['conv1d_2[0][0]']            \n",
            " obalMaxPooling1D)                                                                                \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 320)                  0         ['global_average_pooling1d_3[0\n",
            " )                                                                  ][0]',                        \n",
            "                                                                     'global_max_pooling1d_4[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'global_max_pooling1d_3[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_9 (Dense)             (None, 128)                  41088     ['concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)        (None, 128)                  0         ['dense_9[0][0]']             \n",
            "                                                                                                  \n",
            " dense_10 (Dense)            (None, 64)                   8256      ['dropout_11[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)        (None, 64)                   0         ['dense_10[0][0]']            \n",
            "                                                                                                  \n",
            " dense_11 (Dense)            (None, 3)                    195       ['dropout_12[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 178354116 (680.37 MB)\n",
            "Trainable params: 500675 (1.91 MB)\n",
            "Non-trainable params: 177853441 (678.46 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyvwoqnNblVR"
      },
      "outputs": [],
      "source": [
        "num_classes = 3            #### change class number\n",
        "\n",
        "accuracy_threshold = 0.99\n",
        "\n",
        "class myCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "      if(logs.get('accuracy')>accuracy_threshold):\n",
        "        print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
        "        self.model.stop_training = True\n",
        "\n",
        "acc_callback = myCallback()\n",
        "# Saved the Best Model\n",
        "filepath = \"/content/drive/MyDrive/Colab Notebooks/case/\" + \"Overhybrid2.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "# callback list\n",
        "callback_list = [acc_callback, checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BjoduC2anp8",
        "outputId": "f48dce92-cdfa-4c1a-f907-f638c37a1c47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.1143 - accuracy: 0.3143\n",
            "Epoch 1: val_accuracy improved from -inf to 0.85333, saving model to /content/drive/MyDrive/Colab Notebooks/case/Overhybrid2.h5\n",
            "10/10 [==============================] - 31s 1s/step - loss: 1.1143 - accuracy: 0.3143 - val_loss: 1.0325 - val_accuracy: 0.8533\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.1066 - accuracy: 0.3429\n",
            "Epoch 2: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 629ms/step - loss: 1.1066 - accuracy: 0.3429 - val_loss: 1.0986 - val_accuracy: 0.0467\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.0915 - accuracy: 0.3683\n",
            "Epoch 3: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 670ms/step - loss: 1.0915 - accuracy: 0.3683 - val_loss: 1.0812 - val_accuracy: 0.7400\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.0923 - accuracy: 0.3841\n",
            "Epoch 4: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 592ms/step - loss: 1.0923 - accuracy: 0.3841 - val_loss: 1.1113 - val_accuracy: 0.1533\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.0841 - accuracy: 0.4032\n",
            "Epoch 5: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 7s 672ms/step - loss: 1.0841 - accuracy: 0.4032 - val_loss: 1.0351 - val_accuracy: 0.7400\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.0729 - accuracy: 0.3968\n",
            "Epoch 6: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 7s 730ms/step - loss: 1.0729 - accuracy: 0.3968 - val_loss: 1.1578 - val_accuracy: 0.1067\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.0501 - accuracy: 0.4635\n",
            "Epoch 7: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 7s 679ms/step - loss: 1.0501 - accuracy: 0.4635 - val_loss: 1.0510 - val_accuracy: 0.3867\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.0232 - accuracy: 0.4571\n",
            "Epoch 8: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 7s 702ms/step - loss: 1.0232 - accuracy: 0.4571 - val_loss: 1.0557 - val_accuracy: 0.2133\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.9639 - accuracy: 0.5079\n",
            "Epoch 9: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 7s 686ms/step - loss: 0.9639 - accuracy: 0.5079 - val_loss: 1.0106 - val_accuracy: 0.4400\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.9646 - accuracy: 0.4984\n",
            "Epoch 10: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 633ms/step - loss: 0.9646 - accuracy: 0.4984 - val_loss: 1.0625 - val_accuracy: 0.1933\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.9164 - accuracy: 0.5429\n",
            "Epoch 11: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 620ms/step - loss: 0.9164 - accuracy: 0.5429 - val_loss: 0.8464 - val_accuracy: 0.8133\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.8762 - accuracy: 0.5429\n",
            "Epoch 12: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 8s 783ms/step - loss: 0.8762 - accuracy: 0.5429 - val_loss: 0.9229 - val_accuracy: 0.5667\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.8186 - accuracy: 0.6317\n",
            "Epoch 13: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 590ms/step - loss: 0.8186 - accuracy: 0.6317 - val_loss: 0.7765 - val_accuracy: 0.8133\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.8754 - accuracy: 0.5873\n",
            "Epoch 14: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 619ms/step - loss: 0.8754 - accuracy: 0.5873 - val_loss: 0.7398 - val_accuracy: 0.8400\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.8802 - accuracy: 0.5587\n",
            "Epoch 15: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 647ms/step - loss: 0.8802 - accuracy: 0.5587 - val_loss: 0.7357 - val_accuracy: 0.8333\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.8062 - accuracy: 0.6571\n",
            "Epoch 16: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 7s 690ms/step - loss: 0.8062 - accuracy: 0.6571 - val_loss: 0.8581 - val_accuracy: 0.6600\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7778 - accuracy: 0.6603\n",
            "Epoch 17: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 7s 727ms/step - loss: 0.7778 - accuracy: 0.6603 - val_loss: 0.7905 - val_accuracy: 0.7267\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7618 - accuracy: 0.6349\n",
            "Epoch 18: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 7s 688ms/step - loss: 0.7618 - accuracy: 0.6349 - val_loss: 0.6301 - val_accuracy: 0.8333\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.8138 - accuracy: 0.6063\n",
            "Epoch 19: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 7s 720ms/step - loss: 0.8138 - accuracy: 0.6063 - val_loss: 0.8177 - val_accuracy: 0.7000\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7313 - accuracy: 0.6667\n",
            "Epoch 20: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 7s 679ms/step - loss: 0.7313 - accuracy: 0.6667 - val_loss: 0.6961 - val_accuracy: 0.7667\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6233 - accuracy: 0.7460\n",
            "Epoch 21: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 7s 670ms/step - loss: 0.6233 - accuracy: 0.7460 - val_loss: 1.0260 - val_accuracy: 0.5467\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6165 - accuracy: 0.7302\n",
            "Epoch 22: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 611ms/step - loss: 0.6165 - accuracy: 0.7302 - val_loss: 0.9329 - val_accuracy: 0.4333\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7438 - accuracy: 0.6635\n",
            "Epoch 23: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 644ms/step - loss: 0.7438 - accuracy: 0.6635 - val_loss: 0.8031 - val_accuracy: 0.7667\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7492 - accuracy: 0.6762\n",
            "Epoch 24: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 7s 714ms/step - loss: 0.7492 - accuracy: 0.6762 - val_loss: 0.6614 - val_accuracy: 0.8200\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6445 - accuracy: 0.7302\n",
            "Epoch 25: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 7s 738ms/step - loss: 0.6445 - accuracy: 0.7302 - val_loss: 0.5964 - val_accuracy: 0.8333\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6588 - accuracy: 0.7016\n",
            "Epoch 26: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 603ms/step - loss: 0.6588 - accuracy: 0.7016 - val_loss: 0.7992 - val_accuracy: 0.6733\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6149 - accuracy: 0.7587\n",
            "Epoch 27: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 618ms/step - loss: 0.6149 - accuracy: 0.7587 - val_loss: 0.4712 - val_accuracy: 0.8467\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6525 - accuracy: 0.7175\n",
            "Epoch 28: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 618ms/step - loss: 0.6525 - accuracy: 0.7175 - val_loss: 0.5164 - val_accuracy: 0.8067\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6644 - accuracy: 0.7111\n",
            "Epoch 29: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 5s 521ms/step - loss: 0.6644 - accuracy: 0.7111 - val_loss: 0.7000 - val_accuracy: 0.7933\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6360 - accuracy: 0.7492\n",
            "Epoch 30: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 5s 535ms/step - loss: 0.6360 - accuracy: 0.7492 - val_loss: 0.6063 - val_accuracy: 0.8133\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6842 - accuracy: 0.6762\n",
            "Epoch 31: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 569ms/step - loss: 0.6842 - accuracy: 0.6762 - val_loss: 0.6222 - val_accuracy: 0.7800\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6886 - accuracy: 0.6730\n",
            "Epoch 32: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 623ms/step - loss: 0.6886 - accuracy: 0.6730 - val_loss: 0.6773 - val_accuracy: 0.7800\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6518 - accuracy: 0.6889\n",
            "Epoch 33: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 671ms/step - loss: 0.6518 - accuracy: 0.6889 - val_loss: 0.4675 - val_accuracy: 0.8267\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5598 - accuracy: 0.7968\n",
            "Epoch 34: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 5s 536ms/step - loss: 0.5598 - accuracy: 0.7968 - val_loss: 0.6417 - val_accuracy: 0.8067\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5473 - accuracy: 0.7587\n",
            "Epoch 35: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 5s 519ms/step - loss: 0.5473 - accuracy: 0.7587 - val_loss: 0.4811 - val_accuracy: 0.8000\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5323 - accuracy: 0.7778\n",
            "Epoch 36: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 647ms/step - loss: 0.5323 - accuracy: 0.7778 - val_loss: 0.6069 - val_accuracy: 0.7867\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5142 - accuracy: 0.7810\n",
            "Epoch 37: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 5s 518ms/step - loss: 0.5142 - accuracy: 0.7810 - val_loss: 0.5624 - val_accuracy: 0.7867\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4867 - accuracy: 0.7778\n",
            "Epoch 38: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 648ms/step - loss: 0.4867 - accuracy: 0.7778 - val_loss: 0.5020 - val_accuracy: 0.8067\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5070 - accuracy: 0.8063\n",
            "Epoch 39: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 663ms/step - loss: 0.5070 - accuracy: 0.8063 - val_loss: 0.5484 - val_accuracy: 0.8333\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4920 - accuracy: 0.8032\n",
            "Epoch 40: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 579ms/step - loss: 0.4920 - accuracy: 0.8032 - val_loss: 0.4685 - val_accuracy: 0.8133\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4267 - accuracy: 0.8254\n",
            "Epoch 41: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 617ms/step - loss: 0.4267 - accuracy: 0.8254 - val_loss: 0.6872 - val_accuracy: 0.7933\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5251 - accuracy: 0.7619\n",
            "Epoch 42: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 624ms/step - loss: 0.5251 - accuracy: 0.7619 - val_loss: 0.5091 - val_accuracy: 0.8067\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4442 - accuracy: 0.8222\n",
            "Epoch 43: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 670ms/step - loss: 0.4442 - accuracy: 0.8222 - val_loss: 0.7267 - val_accuracy: 0.7800\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4188 - accuracy: 0.8317\n",
            "Epoch 44: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 622ms/step - loss: 0.4188 - accuracy: 0.8317 - val_loss: 0.6118 - val_accuracy: 0.7800\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4525 - accuracy: 0.8190\n",
            "Epoch 45: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 625ms/step - loss: 0.4525 - accuracy: 0.8190 - val_loss: 0.5802 - val_accuracy: 0.7933\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4690 - accuracy: 0.7905\n",
            "Epoch 46: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 628ms/step - loss: 0.4690 - accuracy: 0.7905 - val_loss: 0.7888 - val_accuracy: 0.7467\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4507 - accuracy: 0.8190\n",
            "Epoch 47: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 5s 556ms/step - loss: 0.4507 - accuracy: 0.8190 - val_loss: 0.7996 - val_accuracy: 0.7733\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4547 - accuracy: 0.8063\n",
            "Epoch 48: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 628ms/step - loss: 0.4547 - accuracy: 0.8063 - val_loss: 0.5990 - val_accuracy: 0.7800\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4313 - accuracy: 0.8159\n",
            "Epoch 49: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 673ms/step - loss: 0.4313 - accuracy: 0.8159 - val_loss: 1.5775 - val_accuracy: 0.5333\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4401 - accuracy: 0.8032\n",
            "Epoch 50: val_accuracy did not improve from 0.85333\n",
            "10/10 [==============================] - 6s 616ms/step - loss: 0.4401 - accuracy: 0.8032 - val_loss: 0.5821 - val_accuracy: 0.7733\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e4d6023fca0>"
            ]
          },
          "execution_count": 200,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model2.fit(X_train_over, y_train_over, epochs=50, validation_data = (X_valid, y_valid), verbose = 1, callbacks = callback_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99nSkPBNanp9",
        "outputId": "77783393-ef0d-4ed4-c932-e0fb2c015112"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 3s 382ms/step - loss: 1.0325 - accuracy: 0.8533\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.0325453281402588, 0.8533333539962769]"
            ]
          },
          "execution_count": 201,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import Layer  # Assuming KerasLayer is a subclass of Layer\n",
        "import tensorflow_hub as hub\n",
        "# Define the custom_objects dictionary\n",
        "custom_objects = {'KerasLayer': hub.KerasLayer}\n",
        "\n",
        "# Load the model with the custom_objects parameter\n",
        "loaded_model = load_model(filepath, custom_objects=custom_objects)\n",
        "\n",
        "# Continue with your evaluation or any other operations\n",
        "loaded_model.evaluate(X_valid, y_valid)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PV4uoZ2anp9",
        "outputId": "347b0ce8-5c77-4b41-f8e0-dc23187461fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 6s 296ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9127    0.9583    0.9350       120\n",
            "           1     0.5417    0.5652    0.5532        23\n",
            "           2     0.0000    0.0000    0.0000         7\n",
            "\n",
            "    accuracy                         0.8533       150\n",
            "   macro avg     0.4848    0.5079    0.4961       150\n",
            "weighted avg     0.8132    0.8533    0.8328       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(X_valid)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report = classification_report(Bval['enc_label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieNEap2lcK_E",
        "outputId": "3f999f0d-ae8c-4856-9be5-2800e0606bed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 2s 407ms/step\n",
            "Classification Report for Loaded Model:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8722    0.9587    0.9134       121\n",
            "           1     0.5294    0.3913    0.4500        23\n",
            "           2     0.0000    0.0000    0.0000         6\n",
            "\n",
            "    accuracy                         0.8333       150\n",
            "   macro avg     0.4672    0.4500    0.4545       150\n",
            "weighted avg     0.7847    0.8333    0.8058       150\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming y_pred is a 2D array of predicted probabilities for each class\n",
        "# Adjust axis parameter if needed based on the shape of your y_pred array\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report = classification_report(Btest['enc_label'], y_pred_classes, digits=4)\n",
        "print('Classification Report for Loaded Model:\\n', classification_report)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "mzMw4q9pAljq",
        "tn3ZdEkqwFuf",
        "cRU1aKz253-Q",
        "hphD1uHEv9_0",
        "zdSqmUkvYBpk",
        "H1WjlCul53-f",
        "tgzH4ATOSOny",
        "gufiQOxQA4w_",
        "f_6NB5_6wPbb",
        "6uGKlKfM53--",
        "C9-2bOoIg-ER",
        "sd-CAe8Ibyxb",
        "dtl_Lbo453_e",
        "nkJ0caVu53_k",
        "6paYwL3y53_i",
        "64F6_rRR53_o",
        "Uw6EOtBr2ocs",
        "7ifO6ZmsYBpw",
        "jA9TZgK65B0C",
        "FtE4KQlG5B0D",
        "zc1TD3lY5QY4",
        "-6bUcjoB5QY5",
        "yqjvh0m75QY9",
        "mirYQe9y5QY_",
        "YIxFsiXV5QZA",
        "PYECII205QZB",
        "q8Bw1KmA5QZD",
        "Qe3VimDM5QZF",
        "LgQ3UuHg5QZG",
        "sXYVw1Zo5QZH",
        "53ZG5cGp5rLw",
        "LpOVn9It5rL0",
        "I9nJ3gUM5rL7",
        "8LH-Mgdk5rL9",
        "sIpyqcK-anpn",
        "BFZrai4Nanpp",
        "m9K22GsPanpw",
        "3ICOpXPpanp7"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 4217916,
          "sourceId": 7275497,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4237171,
          "sourceId": 7303276,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30627,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a92e7ad8ac740e5ab055eb02baf8b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52950c63249949a7bcc98cf360c248c6",
              "IPY_MODEL_431db3556785477e9d1c708f16512441",
              "IPY_MODEL_196c23b0e2cd4253a83069c00bd17bcc"
            ],
            "layout": "IPY_MODEL_6931445872194c7ebfe59b47a54dee87"
          }
        },
        "52950c63249949a7bcc98cf360c248c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b45d540c115d4603af07ab3916b86cd0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_185c6b0f026f4538b449ad285f7ab7d8",
            "value": "config.json: 100%"
          }
        },
        "431db3556785477e9d1c708f16512441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89fe343d5f78472982d4de4b7aa84a9c",
            "max": 615,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d623d31b27784b348ef8b2b4cce1c681",
            "value": 615
          }
        },
        "196c23b0e2cd4253a83069c00bd17bcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3309c667077645f6a7ea8c5d897f48e9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c3b7317072e349b2849619a37bbea690",
            "value": " 615/615 [00:00&lt;00:00, 13.9kB/s]"
          }
        },
        "6931445872194c7ebfe59b47a54dee87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b45d540c115d4603af07ab3916b86cd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "185c6b0f026f4538b449ad285f7ab7d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89fe343d5f78472982d4de4b7aa84a9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d623d31b27784b348ef8b2b4cce1c681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3309c667077645f6a7ea8c5d897f48e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3b7317072e349b2849619a37bbea690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53fd621359b64a11bfab64e360a488ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_269b506b1c974e9baa0da47948d23aed",
              "IPY_MODEL_4d57de7deeeb4c6db3b3c18a7f1e6d18",
              "IPY_MODEL_760e3a7f0d334411bfe1c7bcc1acfb50"
            ],
            "layout": "IPY_MODEL_86b70bbb82c44cd4b0fc22f8db47d3ab"
          }
        },
        "269b506b1c974e9baa0da47948d23aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20b27d752ed649d395a2b364fdec03be",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_108242f64b694086be43bf3a4618206f",
            "value": "config.json: 100%"
          }
        },
        "4d57de7deeeb4c6db3b3c18a7f1e6d18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_422c67f3b7ab419eba2eea67b2586a15",
            "max": 512,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08c50640bb0c4089918171db5a7df2f7",
            "value": 512
          }
        },
        "760e3a7f0d334411bfe1c7bcc1acfb50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc2d6d8ffebb47a082bfb7b77641898b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_febc024bdde2499b8f9ec9e5c986c6e2",
            "value": " 512/512 [00:00&lt;00:00, 12.8kB/s]"
          }
        },
        "86b70bbb82c44cd4b0fc22f8db47d3ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20b27d752ed649d395a2b364fdec03be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "108242f64b694086be43bf3a4618206f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "422c67f3b7ab419eba2eea67b2586a15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08c50640bb0c4089918171db5a7df2f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc2d6d8ffebb47a082bfb7b77641898b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "febc024bdde2499b8f9ec9e5c986c6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8502fcada018495c9c153941d4b03b5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca4e12f6e5d341cf8e1791d9aa124052",
              "IPY_MODEL_2ee532219f9e4c3aafab1aebe868860d",
              "IPY_MODEL_15a8d5b4815045acb6323389786029c2"
            ],
            "layout": "IPY_MODEL_fcc068d095fe4820bc45f771117ea3e7"
          }
        },
        "ca4e12f6e5d341cf8e1791d9aa124052": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f108be086092482c930f51b2f9febf88",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6b4ef73ab17547e3b7de922102665c7c",
            "value": "tf_model.h5: 100%"
          }
        },
        "2ee532219f9e4c3aafab1aebe868860d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73ce1ea65f264559943433ac0fd1a34a",
            "max": 1885418496,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_761e4b54a8e24077bc9c0454ba128a60",
            "value": 1885418496
          }
        },
        "15a8d5b4815045acb6323389786029c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c3348a382dc41808cb86e7e12b93ce0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7cb9091384e14c0bbc334f1ee3a9fa84",
            "value": " 1.89G/1.89G [01:43&lt;00:00, 25.1MB/s]"
          }
        },
        "fcc068d095fe4820bc45f771117ea3e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f108be086092482c930f51b2f9febf88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b4ef73ab17547e3b7de922102665c7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73ce1ea65f264559943433ac0fd1a34a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "761e4b54a8e24077bc9c0454ba128a60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c3348a382dc41808cb86e7e12b93ce0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cb9091384e14c0bbc334f1ee3a9fa84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6c8674714b545c2b3c748348df9d3ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba7a2b3ae5bb48329e7e75d47ed195c5",
              "IPY_MODEL_192be83e01d54ea0acc63e551787024e",
              "IPY_MODEL_77343e89ab7444898db43e61049f053a"
            ],
            "layout": "IPY_MODEL_3b2692a2171e40f38ee1e61b0647a8bf"
          }
        },
        "ba7a2b3ae5bb48329e7e75d47ed195c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3eea82d64e434036bd8f536627b1ff7b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0b8852b98d0d4d53aa511df9c55aa456",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "192be83e01d54ea0acc63e551787024e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a64060c582f94966a5157fbd8e698aa5",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8505b24218b49608f8a4d023a456100",
            "value": 5069051
          }
        },
        "77343e89ab7444898db43e61049f053a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f51321aa8ec4d51ba3ed5d5b1784c8d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_33b0a474954b42b9b6b9bbbd602db037",
            "value": " 5.07M/5.07M [00:00&lt;00:00, 8.94MB/s]"
          }
        },
        "3b2692a2171e40f38ee1e61b0647a8bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3eea82d64e434036bd8f536627b1ff7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b8852b98d0d4d53aa511df9c55aa456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a64060c582f94966a5157fbd8e698aa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8505b24218b49608f8a4d023a456100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f51321aa8ec4d51ba3ed5d5b1784c8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33b0a474954b42b9b6b9bbbd602db037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}